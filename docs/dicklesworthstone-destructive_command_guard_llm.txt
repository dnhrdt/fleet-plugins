Directory structure:
â””â”€â”€ docs/
    â”œâ”€â”€ adr-001-heredoc-scanning.md
    â”œâ”€â”€ adr-002-robot-mode-api.md
    â”œâ”€â”€ agents.md
    â”œâ”€â”€ allow-once-usage.md
    â”œâ”€â”€ canonical-corpus-invariants.md
    â”œâ”€â”€ cli-versions.yaml
    â”œâ”€â”€ configuration.md
    â”œâ”€â”€ coverage-audit-baseline.md
    â”œâ”€â”€ coverage_audit.md
    â”œâ”€â”€ custom-packs.md
    â”œâ”€â”€ decision-dfa-backend.md
    â”œâ”€â”€ design-2cu-false-positive-reduction.md
    â”œâ”€â”€ design-allow-once-short-code.md
    â”œâ”€â”€ design-lazy-pack-registry.md
    â”œâ”€â”€ graduated-response.md
    â”œâ”€â”€ heredoc-error-messages.md
    â”œâ”€â”€ pack-expansion-guide.md
    â”œâ”€â”€ pack-expansion-index.md
    â”œâ”€â”€ pack-implementation-checklist.md
    â”œâ”€â”€ pack-maintenance.md
    â”œâ”€â”€ pack-task-template.md
    â”œâ”€â”€ pack-testing-guide.md
    â”œâ”€â”€ pack.schema.yaml
    â”œâ”€â”€ pattern-library-design.md
    â”œâ”€â”€ pattern_audit.md
    â”œâ”€â”€ patterns.md
    â”œâ”€â”€ regex-automata-decision-memo.md
    â”œâ”€â”€ regex-automata-feasibility-report.md
    â”œâ”€â”€ rich-rust-integration-plan.md
    â”œâ”€â”€ scan-precommit-guide.md
    â”œâ”€â”€ security-model.md
    â”œâ”€â”€ security.md
    â”œâ”€â”€ tier-dependency-strategy.md
    â”œâ”€â”€ troubleshooting.md
    â”œâ”€â”€ architecture/
    â”‚   â””â”€â”€ pack-design.md
    â”œâ”€â”€ design/
    â”‚   â””â”€â”€ rule-metrics-struct-mapping.md
    â”œâ”€â”€ json-schema/
    â”‚   â”œâ”€â”€ error.json
    â”‚   â”œâ”€â”€ hook-output.json
    â”‚   â”œâ”€â”€ scan-results.json
    â”‚   â””â”€â”€ stats-output.json
    â”œâ”€â”€ packs/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ apigateway.md
    â”‚   â”œâ”€â”€ backup.md
    â”‚   â”œâ”€â”€ cdn.md
    â”‚   â”œâ”€â”€ cicd.md
    â”‚   â”œâ”€â”€ cloud.md
    â”‚   â”œâ”€â”€ containers.md
    â”‚   â”œâ”€â”€ core.md
    â”‚   â”œâ”€â”€ database.md
    â”‚   â”œâ”€â”€ dns.md
    â”‚   â”œâ”€â”€ email.md
    â”‚   â”œâ”€â”€ featureflags.md
    â”‚   â”œâ”€â”€ infrastructure.md
    â”‚   â”œâ”€â”€ kubernetes.md
    â”‚   â”œâ”€â”€ loadbalancer.md
    â”‚   â”œâ”€â”€ messaging.md
    â”‚   â”œâ”€â”€ monitoring.md
    â”‚   â”œâ”€â”€ package_managers.md
    â”‚   â”œâ”€â”€ payment.md
    â”‚   â”œâ”€â”€ platform.md
    â”‚   â”œâ”€â”€ remote.md
    â”‚   â”œâ”€â”€ search.md
    â”‚   â”œâ”€â”€ secrets.md
    â”‚   â”œâ”€â”€ storage.md
    â”‚   â”œâ”€â”€ strict_git.md
    â”‚   â””â”€â”€ system.md
    â””â”€â”€ scan/
        â”œâ”€â”€ dockerfile-extractor-v1-spec.md
        â”œâ”€â”€ github-actions-extractor-v1-spec.md
        â””â”€â”€ makefile-extractor-v1-spec.md

================================================
FILE: docs/adr-001-heredoc-scanning.md
================================================
# ADR-001: Heredoc Scanning Architecture

## Status

**Accepted** (2026-01-08)

## Context

### Problem Statement

dcg currently blocks destructive commands via regex pattern matching on the raw command string. However, attackers or accidental misuse can embed destructive code inside heredocs, here-strings, or inline interpreter flags (`python -c`, `bash -c`), bypassing pattern detection.

Example bypass:
```bash
cat <<EOF | bash
rm -rf /important
EOF
```

The outer command (`cat <<EOF | bash`) doesn't match any destructive pattern, but the embedded code is dangerous.

### Constraints

1. **Performance**: dcg runs on EVERY bash command. Total latency budget: <10ms typical, <50ms worst-case
2. **False Positives**: Must not block legitimate heredocs (deployment scripts, SQL migrations, config generation)
3. **Dependencies**: Minimize binary size impact; avoid external process dependencies
4. **Maintenance**: Pattern library must be extensible without core code changes
5. **Fail-Open**: In hook mode, timeouts/parse errors must ALLOW (not block) to avoid breaking user workflows

### Options Considered

| Option | Latency | Binary Size | Maintenance | FP Control |
|--------|---------|-------------|-------------|------------|
| A. External ast-grep CLI | 10-50ms | 0 | Low | High |
| B. ast-grep-core (embedded) | <5ms | +2-4MB | Medium | High |
| C. tree-sitter direct | <5ms | +1-2MB/grammar | High | Medium |
| D. Regex-only | <1ms | 0 | Low | Low |

## Decision

**Use ast-grep-core (embedded) with a tiered detection architecture.**

### Architecture: Three-Tier Detection

```
Command Input
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 0: Pack Gate   â”‚ â”€â”€â”€ No keywords â”€â”€â–º ALLOW (fast path, <10Î¼s)
â”‚ (pack_aware_quick_  â”‚
â”‚  reject)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Keywords found
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Trigger     â”‚ â”€â”€â”€ No match â”€â”€â–º Continue to pack patterns
â”‚ (RegexSet, <100Î¼s)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Heredoc/inline detected
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 2: Extract     â”‚ â”€â”€â”€ Error/Timeout â”€â”€â–º ALLOW + diagnostic
â”‚ (<1ms, bounded)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Content + language
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 3: AST Scan    â”‚ â”€â”€â”€ No match â”€â”€â–º Continue to pack patterns
â”‚ (ast-grep-core,     â”‚ â”€â”€â”€ Match â”€â”€â–º BLOCK
â”‚  <5ms, timeout 20ms)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tier Details

#### Tier 0: Pack-Aware Quick Reject (existing)

- Uses `pack_aware_quick_reject()` with SIMD-accelerated keyword search
- If no enabled pack keywords found â†’ early return
- Budget: <10Î¼s

#### Tier 1: Heredoc/Inline Trigger Detection

Triggers (RegexSet):
- `<<-?\s*['\"]?\w+['\"]?` (heredoc operators)
- `<<<` (here-strings)
- `\b(python3?|ruby|perl|node)\s+-[ce]\s` (inline scripts)
- `\b(sh|bash|zsh)\s+-c\s` (shell inline)
- `\|\s*(python3?|ruby|perl|node|sh|bash|zsh)\b` (pipe to interpreter)

Budget: <100Î¼s
Guarantees: ZERO false negatives for supported forms

#### Tier 2: Content Extraction

Bounded extraction with hard limits:
- `max_body_bytes`: 1MB per heredoc
- `max_body_lines`: 10,000 per heredoc
- `max_heredocs`: 10 per command
- `timeout_ms`: 50ms total

Language detection priority (from git_safety_guard-jfj):
1. Inline interpreter flag (`python -c` â†’ Python, High confidence)
2. Receiving command (`python <<EOF` â†’ Python, High confidence)
3. Delimiter hints (`<<SQL`, `<<PY` â†’ SQL/Python, Medium)
4. Content heuristics (shebang, imports â†’ Medium/Low)

Budget: <1ms typical

#### Tier 3: AST Pattern Matching

Uses ast-grep-core for structural pattern matching:
- Language-specific patterns from pattern library
- Composite matchers: regex trigger + AST validation
- Timeout protection: 20ms hard limit

Budget: <5ms typical, 20ms max

### Pattern Library

Format defined in `docs/pattern-library-design.md`:

```rust
pub struct HeredocPattern {
    pub id: &'static str,        // Stable rule ID
    pub language: Language,
    pub matcher: PatternMatcher,
    pub reason: &'static str,
    pub suggestion: Option<&'static str>,  // Safe alternative
    pub severity: Severity,
    pub fp_notes: Option<&'static str>,    // FP risk documentation
}
```

Severity taxonomy:
- **Critical**: Always block (e.g., `shutil.rmtree`, `fs.rmSync({recursive:true})`)
- **High**: Block by default, allowlistable
- **Medium**: Warn by default
- **Low**: Log only

Pack integration:
- New `heredoc.*` category (heredoc.python, heredoc.bash, heredoc.javascript, etc.)
- Patterns only evaluated when Tier 1/2 trigger
- Stable rule IDs for allowlisting: `heredoc.{language}.{operation}`

### Integration Points

#### With Existing Pack System

Heredoc detection runs AFTER pack-aware quick reject but BEFORE regular pack pattern matching:

```
Command â†’ Quick Reject â†’ Heredoc Detection â†’ Pack Patterns â†’ Default Allow
```

If heredoc detection blocks, skip pack patterns (already decided).

#### With Execution Context Classification (git_safety_guard-t8x)

Heredoc patterns should respect execution context:
- Code in comments â†’ Lower severity
- Code in strings â†’ Lower severity
- Code being echoed â†’ Lower severity

#### With Config Overrides

Users can allowlist by stable rule ID:
```toml
[allow]
rules = ["heredoc.python.subprocess_rm_rf"]
```

### Performance Budgets

| Component | Target | Panic Threshold |
|-----------|--------|-----------------|
| Quick reject | <10Î¼s | >100Î¼s |
| Tier 1 trigger | <10Î¼s match, <100Î¼s total | >500Î¼s |
| Tier 2 extract | <500Î¼s | >2ms |
| Tier 3 AST | <5ms | >20ms |
| **Total heredoc path** | <10ms | >50ms |

### Error Handling

**All tiers follow fail-open semantics in hook mode:**

| Error | Behavior | Diagnostic |
|-------|----------|------------|
| Tier 1 regex error | ALLOW | Log + mark for review |
| Tier 2 extraction timeout | ALLOW | Emit `heredoc_extraction_timeout` marker |
| Tier 2 malformed heredoc | ALLOW | Emit `heredoc_parse_error` marker |
| Tier 3 AST parse error | ALLOW | Emit `ast_parse_error` marker |
| Tier 3 timeout | ALLOW | Emit `ast_timeout` marker |
| Unknown language | ALLOW | Emit `unknown_language` marker |

Rationale: A hung or crashed hook is worse than a missed detection. Diagnostics enable `dcg explain` to surface issues for review.

## Consequences

### Benefits

1. **No process spawn overhead**: ast-grep-core is embedded, avoiding 10-50ms CLI latency
2. **Structural matching**: AST patterns avoid false positives from comments/strings
3. **Extensible**: Pattern library can grow without core code changes
4. **Fail-safe**: Fail-open design prevents blocking legitimate workflows
5. **Explainable**: Stable rule IDs enable precise allowlisting

### Drawbacks

1. **Binary size increase**: +2-4MB for ast-grep-core + grammars
2. **Compile time increase**: +20-30s for grammar compilation
3. **Maintenance burden**: Pattern library requires ongoing curation
4. **Complexity**: Three-tier architecture is more complex than regex-only

### Mitigations

- Feature flags for language grammars (compile only what's needed)
- Pattern library validation in CI
- Comprehensive test fixtures for each pattern
- Documentation of all supported heredoc forms

## Technical Details

### Cargo.toml Changes

```toml
[dependencies]
ast-grep-core = { version = "0.40", optional = true }

[features]
default = ["heredoc"]
heredoc = ["ast-grep-core"]
```

### New Modules

- `src/heredoc/mod.rs` - Tier orchestration
- `src/heredoc/trigger.rs` - Tier 1 RegexSet triggers
- `src/heredoc/extract.rs` - Tier 2 content extraction
- `src/heredoc/language.rs` - Language detection
- `src/heredoc/patterns/` - Per-language pattern definitions

### Data Flow

```
HookInput {command}
    â†“
pack_aware_quick_reject(command, keywords) == false?
    â†“ (if false = keywords present, proceed)
HeredocTrigger::check(command)
    â†“ (if triggered)
HeredocExtractor::extract(command)
    â†“
LanguageDetector::detect(payload, context)
    â†“
AstMatcher::find_matches(content, language)
    â†“
CheckResult {blocked, reason, rule_id}
```

Note: `pack_aware_quick_reject()` returns `true` if safe to skip (no keywords),
`false` if keywords present and further checking is needed.

## Developer Notes

### Integration Points

- `src/main.rs`: evaluates heredoc settings once and passes them into the main
  evaluation pipeline.
- `src/cli.rs`: CLI overrides (`--heredoc-scan`, `--heredoc-timeout`,
  `--heredoc-languages`) feed into the effective config.
- `src/config.rs`: parses `[heredoc]` config and merges overrides.

### Error Handling Patterns

- All heredoc parse/timeouts are **fail-open** in hook mode.
- Diagnostics should be emitted with enough context for `dcg explain` or logs.

### Testing

```
cargo test heredoc
cargo test ast_matcher
```

## References

- `docs/pattern-library-design.md` - Pattern metadata schema
- `git_safety_guard-o15` - Heredoc detection strategy (GreenHarbor)
- `git_safety_guard-jfj` - Language detection heuristics (GreenHarbor)
- `git_safety_guard-2j3` - Tree-sitter research (SilverCreek)
- `git_safety_guard-boy` - Embedded vs external evaluation (SilverCreek)
- `git_safety_guard-6sg` - Pattern library design (SilverCreek)

## Decision Record

| Date | Author | Change |
|------|--------|--------|
| 2026-01-08 | SilverCreek | Initial ADR created |



================================================
FILE: docs/adr-002-robot-mode-api.md
================================================
# ADR-002: Unified Robot Mode API for AI Agent Integration

## Status

Proposed

## Context

dcg (Destructive Command Guard) is used as a hook by AI coding agents like Claude Code, Gemini CLI, and others. These agents need to parse dcg's output programmatically. Currently, the CLI has several inconsistencies that make agent integration more complex than necessary:

### Current Problems

1. **Inconsistent format flags**: Commands use `-f`, `-F`, `-o`, or `--json` boolean flags
2. **Inconsistent defaults**: Some commands default to `pretty`, others to `json` or `text`
3. **No unified robot mode**: Each command must be configured individually for machine output
4. **Inconsistent exit codes**: No documented, standardized exit codes across commands
5. **Mixed stderr behavior**: Some commands emit decorative output even in CI environments
6. **JSON field naming**: Hook output uses camelCase (protocol requirement), others use snake_case

### Agent Requirements

AI agents need:
- Pure JSON on stdout (no ANSI codes, no decorative text)
- Silent stderr (or at minimum, no interference with stdout parsing)
- Predictable exit codes for decision-making
- Stable JSON schema that doesn't break between versions
- Single flag to enable "machine mode" across all commands

## Decision

We will implement a unified **robot mode** that provides a consistent, agent-friendly interface across all dcg commands.

### 1. Global `--robot` Flag

```rust
#[derive(Parser)]
pub struct Cli {
    /// Enable robot/machine mode for AI agent integration
    ///
    /// When enabled:
    /// - All output is JSON on stdout
    /// - stderr is completely silent
    /// - Exit codes follow standardized values
    /// - Human-friendly decorations are suppressed
    #[arg(long, global = true, env = "DCG_ROBOT")]
    pub robot: bool,

    // ... existing fields
}
```

### 2. Standardized Exit Codes

Create `src/exit_codes.rs`:

```rust
//! Standardized exit codes for dcg commands.
//!
//! These codes are stable and documented for agent consumption.

/// Command completed successfully (allowed, passed, healthy)
pub const EXIT_SUCCESS: i32 = 0;

/// Command was denied/blocked by a security rule
pub const EXIT_DENIED: i32 = 1;

/// Command triggered a warning (with --fail-on warn)
pub const EXIT_WARNING: i32 = 2;

/// Configuration error (invalid config file, missing required config)
pub const EXIT_CONFIG_ERROR: i32 = 3;

/// Parse/input error (invalid JSON, malformed command)
pub const EXIT_PARSE_ERROR: i32 = 4;

/// IO error (file not found, permission denied, network error)
pub const EXIT_IO_ERROR: i32 = 5;
```

### 3. Unified OutputFormat Enum

```rust
/// Output format for all dcg commands.
///
/// This enum is shared across all commands for consistency.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Default, clap::ValueEnum)]
pub enum OutputFormat {
    /// Human-readable colored output (default for interactive use)
    #[default]
    #[value(alias = "text", alias = "human")]
    Pretty,

    /// Structured JSON output (for agents and scripting)
    #[value(alias = "sarif", alias = "structured")]
    Json,

    /// JSON Lines format (one JSON object per line)
    #[value(name = "jsonl")]
    Jsonl,

    /// Compact single-line output (for specific commands like explain)
    Compact,
}
```

### 4. Robot Mode Behavior

When `--robot` or `DCG_ROBOT=1` is set:

| Aspect | Normal Mode | Robot Mode |
|--------|-------------|------------|
| stdout | JSON or pretty | Always JSON |
| stderr | Rich output | Silent |
| Exit codes | Varies | Standardized |
| ANSI codes | If TTY | Never |
| Progress | Shown | Hidden |
| Warnings | stderr | In JSON |

### 5. JSON Response Envelope

All robot-mode JSON responses include metadata:

```json
{
  "dcg_version": "1.2.3",
  "schema_version": 1,
  "command_name": "test",
  "success": true,
  "data": {
    // Command-specific payload
  },
  "metadata": {
    "elapsed_ms": 42,
    "robot_mode": true,
    "agent": {
      "detected": "claude-code",
      "trust_level": "medium"
    }
  }
}
```

### 6. Migration Strategy

1. **Phase 1 (Non-Breaking)**
   - Add `--robot` flag and `DCG_ROBOT` env var
   - Add `src/exit_codes.rs` module
   - Add `OutputFormat` enum
   - Document robot mode in AGENTS.md

2. **Phase 2 (Deprecation)**
   - Deprecate command-specific `--json` bool flags
   - Deprecate inconsistent format enums
   - Emit deprecation warnings when old flags are used
   - Old flags continue to work

3. **Phase 3 (Future)**
   - Remove deprecated flags in next major version
   - Consider gRPC/MCP native protocol

## Consequences

### Positive

- **Simpler agent integration**: Single `--robot` flag configures everything
- **Predictable behavior**: Agents know exactly what to expect
- **Stable contract**: JSON schema versioning prevents breaking changes
- **Better testing**: Golden file tests can verify robot mode output
- **Documentation**: Clear, centralized docs for agent developers

### Negative

- **More flags**: Adds another global flag to the CLI
- **Migration effort**: Existing scripts using `--json` need updates (eventually)
- **Maintenance**: Must maintain both human and robot output paths

### Neutral

- **Backward compatible**: All existing behavior continues to work
- **Opt-in**: Robot mode is not the default; humans get pretty output

## Implementation Notes

### Files to Modify

1. `src/cli.rs` - Add `--robot` flag and `OutputFormat` enum
2. `src/exit_codes.rs` - New file with exit code constants
3. `src/lib.rs` - Export exit_codes module
4. `src/main.rs` - Use exit codes, handle robot mode
5. `src/output/mod.rs` - Add robot mode output suppression
6. `docs/agents.md` - Document robot mode

### Testing Requirements

1. Golden file tests for robot mode JSON output
2. E2E tests verifying stderr suppression
3. Exit code verification tests
4. Environment variable tests (`DCG_ROBOT`)

## Related Beads

- `bd-7373`: Implement unified --robot global CLI flag
- `bd-87tn`: Standardize exit codes across all dcg commands
- `bd-1mvw`: Create unified OutputFormat enum for all CLI commands
- `bd-2s08`: Verify stdout/stderr separation
- `bd-z3h5`: E2E test script for agent workflow
- `bd-taet`: Golden file tests for JSON stability

## References

- [Claude Code Hook Protocol](https://docs.anthropic.com/claude-code/hooks)
- [Gemini CLI BeforeTool Hook](https://github.com/google-gemini/gemini-cli)
- [12-Factor App: Treat logs as event streams](https://12factor.net/logs)
- [Unix Philosophy: Write programs that do one thing well](https://en.wikipedia.org/wiki/Unix_philosophy)



================================================
FILE: docs/agents.md
================================================
# Agent-Specific Profiles

dcg can detect which AI coding agent is invoking it and apply agent-specific
trust levels and configuration overrides. This allows you to grant higher
trust to well-behaved agents while maintaining strict controls for unknown ones.

## Supported Agents

| Agent | Detection Method | Environment Variable |
|-------|------------------|---------------------|
| Claude Code | Environment | `CLAUDE_CODE=1` or `CLAUDE_SESSION_ID` |
| Aider | Environment | `AIDER_SESSION=1` |
| Continue | Environment | `CONTINUE_SESSION_ID` |
| Codex CLI | Environment | `CODEX_CLI=1` |
| Gemini CLI | Environment | `GEMINI_CLI=1` |

## Detection Priority

Agent detection follows this priority order:

1. **Explicit `--agent` flag**: Manual override via CLI
2. **Environment variables**: Most agents set identifying env vars
3. **Parent process inspection**: Fallback check of process tree
4. **Unknown**: Default when no agent is detected

## Trust Levels

Three trust levels control how strictly dcg evaluates commands:

| Level | Description |
|-------|-------------|
| `high` | Relaxed evaluation; agent has proven reliable |
| `medium` | Default; standard evaluation rules apply |
| `low` | Strict evaluation; extra caution for unknown agents |

## Configuration

Configure agent profiles in your `config.toml`:

```toml
# Trust Claude Code more (it sets CLAUDE_CODE=1)
[agents.claude-code]
trust_level = "high"
additional_allowlist = ["npm run build", "cargo test"]

# Restrict unknown agents
[agents.unknown]
trust_level = "low"
extra_packs = ["paranoid"]

# Default profile for unspecified agents
[agents.default]
trust_level = "medium"
```

### Profile Options

| Option | Type | Description |
|--------|------|-------------|
| `trust_level` | string | `"high"`, `"medium"`, or `"low"` |
| `disabled_packs` | array | Packs to disable for this agent |
| `extra_packs` | array | Additional packs to enable |
| `additional_allowlist` | array | Commands to allowlist for this agent |
| `disabled_allowlist` | bool | If true, ignore base allowlist for this agent |

### Example: Restrictive Config for CI

```toml
# In .dcg.toml (project-level)
[agents.unknown]
trust_level = "low"
disabled_allowlist = true
extra_packs = ["core", "database", "filesystem"]

[agents.claude-code]
trust_level = "medium"
additional_allowlist = ["npm test", "npm run lint"]
```

## Custom Agents

Define profiles for custom agents by setting an environment variable:

```bash
# Set a custom agent identifier
export MY_BUILD_BOT=1
```

Then configure in `config.toml`:

```toml
[agents.my-build-bot]
trust_level = "high"
additional_allowlist = ["make deploy"]
```

## Profile Resolution

When resolving which profile to use:

1. Look for exact match: `agents.<agent-config-key>`
2. Fall back to `agents.unknown` if agent is unrecognized
3. Fall back to `agents.default` if no specific profile exists

## Verbose Output

Use `--verbose` or `-v` to see agent detection info:

```bash
$ dcg test "git push --force" --verbose
Command: git push --force
...
Elapsed: 21.14ms
Agent: Claude Code
Trust level: medium
Severity: critical
```

Use `-vv` for detailed debug output:

```bash
$ dcg test "git push --force" -vv
...
Agent detection:
  Detected: Claude Code (claude-code)
  Method: environment_variable
  Matched: CLAUDE_CODE
  Profile: agents.claude-code
  Trust level: medium
```

## JSON Output

The `--format json` output includes agent information:

```json
{
  "command": "git push --force",
  "decision": "deny",
  "agent": {
    "detected": "claude-code",
    "trust_level": "medium",
    "detection_method": "environment_variable"
  }
}
```

## Robot Mode

Robot mode provides a unified, machine-friendly interface for AI agents. When
enabled, dcg optimizes its output for programmatic consumption.

### Enabling Robot Mode

```bash
# Via flag
dcg --robot test "rm -rf /"

# Via environment variable
DCG_ROBOT=1 dcg test "rm -rf /"
```

### Robot Mode Behavior

| Aspect | Normal Mode | Robot Mode |
|--------|-------------|------------|
| stdout | JSON or pretty | Always JSON |
| stderr | Rich colored output | Silent |
| Exit codes | Varies | Standardized |
| ANSI codes | If TTY | Never |
| Progress | Shown | Hidden |
| Suggestions | Shown | In JSON only |

### Standardized Exit Codes

In robot mode, dcg uses consistent exit codes across all commands:

| Code | Constant | Meaning |
|------|----------|---------|
| 0 | `EXIT_SUCCESS` | Success / Allow |
| 1 | `EXIT_DENIED` | Command denied/blocked |
| 2 | `EXIT_WARNING` | Warning (with --fail-on warn) |
| 3 | `EXIT_CONFIG_ERROR` | Configuration error |
| 4 | `EXIT_PARSE_ERROR` | Parse/input error |
| 5 | `EXIT_IO_ERROR` | IO error |

### Robot Mode JSON Output

All robot-mode responses are pure JSON on stdout:

```json
{
  "command": "rm -rf /",
  "decision": "deny",
  "rule_id": "core.filesystem:rm-rf-root",
  "pack_id": "core.filesystem",
  "severity": "critical",
  "reason": "rm -rf / would delete the entire filesystem",
  "agent": {
    "detected": "claude-code",
    "trust_level": "medium",
    "detection_method": "environment_variable"
  }
}
```

### Hook Mode vs Robot Mode

**Hook mode** (default when no subcommand) follows the Claude Code protocol:
- Always exits 0 (hook protocol requirement)
- JSON on stdout for denials, empty for allows
- Rich output on stderr for human visibility

**Robot mode** with subcommands uses standardized exit codes:
- Exit 1 for denials (allows scripting with `$?`)
- Pure JSON on stdout
- Silent stderr

### Example: Agent Integration

```bash
#!/bin/bash
# Script for AI agent to check commands before execution

check_command() {
    local cmd="$1"
    local result

    # Use robot mode for predictable output
    result=$(dcg --robot test "$cmd" 2>/dev/null)
    local exit_code=$?

    if [ $exit_code -eq 0 ]; then
        echo "Command allowed: $cmd"
        return 0
    elif [ $exit_code -eq 1 ]; then
        echo "Command BLOCKED: $cmd"
        echo "Reason: $(echo "$result" | jq -r '.reason')"
        return 1
    else
        echo "Error checking command (exit code: $exit_code)"
        return $exit_code
    fi
}

# Usage
check_command "git status"      # Allowed
check_command "rm -rf /"        # Blocked
```

### Unified Output Format

Robot mode uses the unified `OutputFormat` enum:

```bash
# These are equivalent in robot mode
dcg --robot test "cmd"
dcg --robot --format json test "cmd"
```

Available formats:
- `pretty` / `text` / `human` - Human-readable (default without --robot)
- `json` / `sarif` / `structured` - JSON output (default with --robot)
- `jsonl` - JSON Lines (one object per line, for streaming)
- `compact` - Compact single-line output

## Best Practices

1. **Start with defaults**: The default `medium` trust level is safe for most
   use cases.

2. **Grant trust incrementally**: Only increase trust for agents after
   observing their behavior.

3. **Use project-level configs**: Put agent profiles in `.dcg.toml` so they're
   version-controlled with your project.

4. **Restrict unknown agents**: Always configure `agents.unknown` with lower
   trust in production environments.

5. **Review the JSON output**: Use `--format json` in CI to audit which agents
   are accessing your codebase.

6. **Use robot mode for scripting**: When integrating dcg into automated
   workflows, use `--robot` for consistent, parseable output.

7. **Check exit codes**: In robot mode, use exit codes to make decisions
   without parsing JSON for simple allow/deny checks.



================================================
FILE: docs/allow-once-usage.md
================================================
# Allow-Once: Temporary Exception Flow

This guide explains how to use the allow-once feature to temporarily override dcg's blocking behavior for specific commands.

---

## Overview

When dcg blocks a command, it prints a 5-digit numeric code that can be used to temporarily allow that exact command. This provides an escape hatch for false positives without permanently weakening your security policy.

**Key properties:**
- Exceptions are scoped to the exact command + directory (project root in git repos, cwd otherwise)
- Exceptions expire after 24 hours
- By default, exceptions are reusable until expiry
- All exceptions are logged for audit

---

## Example: Blocked Command Output

When dcg blocks a command, you'll see output like this:

```
ALLOW-24H CODE: [12345] | run: dcg allow-once 12345
Tip: dcg explain "git reset --hard HEAD"

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ COMMAND BLOCKED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                 â”‚
â”‚  ðŸ›‘ BLOCKED: Destructive command detected                      â”‚
â”‚                                                                 â”‚
â”‚  Pack: core.git                                                 â”‚
â”‚  Rule: reset-hard                                               â”‚
â”‚                                                                 â”‚
â”‚  Reason: git reset --hard discards uncommitted changes          â”‚
â”‚          and can cause irreversible data loss                   â”‚
â”‚                                                                 â”‚
â”‚  Command: git reset --hard HEAD                                 â”‚
â”‚                                                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

The first line contains the allow-once code (`12345` in this example).

---

## Allowing a Blocked Command

To allow the blocked command, run:

```bash
dcg allow-once 12345
```

This creates a temporary exception that:
- Allows the exact command that was blocked
- Is scoped to the project root (if in a git repo) or current directory (otherwise)
- Expires after 24 hours
- Can be used multiple times until expiry

### Single-Use Exceptions

For a one-time exception that's consumed after the first use:

```bash
dcg allow-once 12345 --single-use
```

This is more restrictive and recommended when you only need to run the command once.

---

## Expiry and Scope

### Time Limit

All allow-once exceptions expire after **24 hours** from creation. This cannot be changed.

### Directory Scope

Exceptions are scoped based on whether the command was blocked inside a git repository:

- **project scope** (automatic in git repos): If the blocked command was inside a git repository, the exception applies anywhere within that repository (root and all subdirectories).
- **cwd scope** (outside git repos): If blocked outside a git repository, the exception only applies in the exact directory where the command was blocked.

The scope is automatically determinedâ€”you cannot override it. This ensures exceptions are appropriately scoped: broad enough to be useful within a project, but not so broad that they leak across unrelated directories.

### Exact Command Match

The exception only applies to the **exact command text** that was blocked. Even minor differences (extra spaces, different arguments) will not match.

---

## Redaction and Security

### Default Behavior

By default, dcg redacts potentially sensitive information from commands when displaying them:

```bash
dcg allow-once list
# Shows: git clone https://***@github.com/...
```

### Viewing Raw Commands

To see the actual command text (useful for debugging), use `--show-raw`:

```bash
dcg allow-once list --show-raw
# Shows: git clone https://token@github.com/...
```

**Security note:** Only use `--show-raw` in trusted environments. The raw command may contain tokens, passwords, or other sensitive data.

---

## Precedence and Force Override

### Normal Allow-Once

A standard allow-once exception overrides pack-based denials but does **not** override explicit blocklist entries in your config file (`.dcg.toml` or `~/.config/dcg/config.toml`).

### Force Override

If you've explicitly blocked a command in your config and need to override it, use `--force`:

```bash
dcg allow-once 12345 --force
```

This requires additional confirmation because:
1. You explicitly added the block to your config
2. Overriding it may indicate a mistake or policy conflict
3. The action is logged for audit purposes

---

## Managing Exceptions

### List Active Exceptions

To see pending codes and active allow-once entries:

```bash
dcg allow-once list
```

Add `--show-raw` to see unredacted commands:

```bash
dcg allow-once list --show-raw
```

### Revoke an Exception

To revoke a pending code or active exception:

```bash
dcg allow-once revoke 12345
```

You can also revoke by full hash (useful when multiple codes collide):

```bash
dcg allow-once revoke 0123abcd...
```

### Clear All Exceptions

To clear expired entries:

```bash
dcg allow-once clear
```

To wipe all pending codes:

```bash
dcg allow-once clear --pending
```

To wipe all active allow-once entries:

```bash
dcg allow-once clear --allow-once
```

To wipe everything:

```bash
dcg allow-once clear --all
```

---

## Command Reference

### Basic Usage

```bash
dcg allow-once <CODE>              # Apply an allow-once code
dcg allow-once <CODE> --single-use # Apply as one-time exception
dcg allow-once <CODE> --force      # Override config blocklist
dcg allow-once <CODE> --dry-run    # Preview without applying
```

### Management Commands

```bash
dcg allow-once list                # List pending and active entries
dcg allow-once list --show-raw     # List with unredacted commands
dcg allow-once revoke <CODE>       # Revoke a specific exception
dcg allow-once clear               # Clear expired entries
dcg allow-once clear --all         # Wipe all entries
```

### Collision Handling

When multiple blocked commands share the same short code, you must disambiguate:

```bash
dcg allow-once 12345 --pick 1       # Select by index (1-based)
dcg allow-once 12345 --hash 0123... # Select by full hash
```

Without disambiguation, the CLI will show a list of matching entries to choose from.

### Additional Flags

| Flag | Description |
|------|-------------|
| `--yes`, `-y` | Auto-confirm (non-interactive) |
| `--json` | Output JSON for automation |
| `--show-raw` | Show unredacted command text |
| `--dry-run` | Preview without applying |
| `--single-use` | Consumed after first allow |
| `--force` | Override config blocklist |
| `--pick <N>` | Select by index when codes collide |
| `--hash <HASH>` | Select by full hash when codes collide |

---

## Logging and Audit

All allow-once actions are logged:

- **Pending code creation**: Logged when a command is blocked
- **Exception application**: Logged when `dcg allow-once` is run
- **Exception consumption**: Logged when a single-use exception is used
- **Exception expiry**: Logged when entries are pruned

Enable verbose logging for detailed audit trails:

```bash
DCG_VERBOSE=1 dcg allow-once 12345
```

Log files are stored in `~/.config/dcg/dcg.log` by default (configurable).

---

## Storage Locations

| File | Purpose |
|------|---------|
| `~/.config/dcg/pending_exceptions.jsonl` | Pending codes from blocked commands |
| `~/.config/dcg/allow_once.jsonl` | Active allow-once entries |

These can be overridden with environment variables:
- `DCG_PENDING_EXCEPTIONS_PATH`
- `DCG_ALLOW_ONCE_PATH`

---

## Optional HMAC Hardening

Set `DCG_ALLOW_ONCE_SECRET` to harden short-code generation with HMAC-SHA256.
This prevents attackers (or tooling) from forging valid short codes without the secret.

Trade-offs:
- **Security**: stronger, tamper-resistant short codes.
- **Recoverability**: if the secret changes or is lost, previously issued codes will no longer resolve.
  Re-run the blocked command to generate a new code under the new secret.

Keep the secret stable within the environment where you expect to resolve codes.

---

## Best Practices

1. **Use `--single-use` for one-off operations** - Prefer single-use exceptions when you only need to run a command once.

2. **Review before applying** - Use `dcg explain "<command>"` to understand why the command was blocked before allowing it.

3. **Use `--force` sparingly** - If you find yourself frequently needing `--force`, consider updating your config blocklist instead.

4. **Monitor logs** - Periodically review allow-once activity for security auditing.

5. **Clear old entries** - Run `dcg allow-once clear` periodically to remove expired entries.

---

## Troubleshooting

### "Code not found or expired"

The short code may have expired (24-hour limit) or been revoked. Re-run the blocked command to generate a new code.

### "Code matches multiple entries"

Use `--pick <N>` or `--hash <HASH>` to disambiguate:

```bash
dcg allow-once 12345 --pick 1
```

### "Cannot override config blocklist without --force"

The blocked command is in your config blocklist. Add `--force` if you're certain:

```bash
dcg allow-once 12345 --force
```

### Permissions Error

Ensure you have write access to `~/.config/dcg/`. The allow-once stores are user-scoped by default.



================================================
FILE: docs/canonical-corpus-invariants.md
================================================
# Canonical Command Corpus and Invariants

This document defines the canonical command corpus and the behavior
invariants that MUST NOT change. The corpus is designed to be consumed
directly by golden tests and the shared e2e harness.

## Canonical Corpus Location and Format

File: `tests/corpus/canonical.toml`

Schema (version 1):

- `schema_version` (int)
- `[[case]]` entries with:
  - `id` (string, stable identifier)
  - `category` (string)
  - `input_kind` (`command` or `hook_json`)
  - `command` (string, required when `input_kind = "command"`)
  - `raw_input` (string, required when `input_kind = "hook_json"`)
  - `expected_decision` (`allow` or `deny`)
  - `expected_log` (inline table of expected log/assertion fields)

`expected_log` is the stable set of fields that golden/e2e harnesses
must validate when present:

- `decision` (allow/deny)
- `pack_id`
- `pattern_name`
- `rule_id` (pack_id:pattern_name)
- `mode` (deny/warn/log)
- `source` (pack, heredoc_ast, config_override, legacy_pattern)
- `reason_contains` (substring match)

For allow cases, `expected_log` may contain only `decision`.

## Corpus Coverage Requirements

The canonical corpus MUST include, at minimum, these categories:

- git safe (status/log/checkout -b/restore --staged)
- git destructive (reset --hard, clean -fd, push --force)
- rm safe in temp dirs (/tmp, /var/tmp, $TMPDIR)
- rm destructive elsewhere
- wrapper prefixes: sudo, env, command
- quoted command words
- substring false positives (echo/grep/rg)
- heredoc + inline code triggers (python -c, bash -c, etc.)
- malformed JSON in hook mode (empty/invalid JSON/non-string command)

The corpus MUST include edge cases:

- multi-segment commands (pipes, &&, ||, ;)
- command substitution $(...) and backticks
- command -v/-V (query mode; non-execution)
- backslash-escaped command words (\git)
- inline -c/-e code with mixed quoting

## Behavior Invariants (Must Never Change)

1) Pack ordering is deterministic and stable.
   - Packs are ordered by tier, then lexicographically by pack_id.
   - Tier ordering is fixed (safe, core, system, infrastructure, cloud,
     kubernetes, containers, database, package_managers, strict_git, cicd).

2) Safe-before-destructive evaluation is preserved.
   - All safe patterns across enabled packs are evaluated first.
   - Any safe match immediately allows the command.

3) Allowlist scope is precise.
   - A matched allowlist entry bypasses only the specific matched rule.
   - Allowlisting does not suppress evaluation of other packs/patterns.

4) Fail-open behavior is mandatory.
   - Hook input parse errors, oversized inputs, or exceeded deadlines must
     allow execution (no deny output).
   - Heredoc extraction/AST errors fail open by default unless strict
     settings explicitly override.

5) Word-boundary keyword gating is stable.
   - Quick-reject uses keyword detection over executable spans.
   - Substring false positives (e.g., "digit", ".gitignore", quoted data)
     must not trigger pack evaluation.

6) Hook output contract is stable.
   - Allow: no stdout JSON.
   - Deny: JSON to stdout and a warning box to stderr.
   - Warn/log modes: no stdout JSON deny.

Any change that violates these invariants requires an explicit design
review and a corpus update with documented rationale.



================================================
FILE: docs/cli-versions.yaml
================================================
# CLI version tracking for pack maintenance.
# Keep this file updated after quarterly audits.

secrets.vault:
  tool: vault
  tested_versions: ["1.15.x", "1.16.x"]
  last_verified: 2026-01-10
  changelog_url: https://github.com/hashicorp/vault/releases

backup.rclone:
  tool: rclone
  tested_versions: ["1.65.x", "1.66.x"]
  last_verified: 2026-01-10
  changelog_url: https://rclone.org/changelog/

cicd.github_actions:
  tool: gh
  tested_versions: ["2.44.x", "2.45.x"]
  last_verified: 2026-01-10
  changelog_url: https://github.com/cli/cli/releases



================================================
FILE: docs/configuration.md
================================================
# Configuration Guide

This guide explains how dcg loads configuration and how to enable packs,
allowlists, and hooks.

## Configuration Precedence (Highest â†’ Lowest)

1. **CLI flags**
2. **Environment variables**
3. **Explicit config path**: `DCG_CONFIG=/path/to/config.toml`
4. **Project config**: `.dcg.toml` at repo root
5. **User config**: `~/.config/dcg/config.toml`
6. **System config**: `/etc/dcg/config.toml`

## Pack Configuration

Enable or disable packs in config files:

```toml
[packs]
enabled = [
  "database.postgresql",
  "containers.docker",
  "kubernetes", # enables all kubernetes sub-packs
]

disabled = [

]
```

### Environment Overrides

- `DCG_PACKS="containers.docker,kubernetes"`
- `DCG_DISABLE="kubernetes.helm"`
- `DCG_VERBOSE=1`
- `DCG_COLOR=auto|always|never`
- `DCG_BYPASS=1` (escape hatch; use sparingly)

## External Packs (YAML)

External packs let you define custom rules without modifying the binary. The
authoritative schema is `docs/pack.schema.yaml`. The schema is versioned via
`schema_version` for forward compatibility.

### Example Pack File

```yaml
schema_version: 1
id: mycompany.deploy
name: MyCompany Deployment Policies
version: 1.0.0
description: Prevents accidental production deployments

keywords:
  - deploy
  - release
  - publish

destructive_patterns:
  - name: prod-direct
    pattern: deploy\\s+--env\\s*=?\\s*prod
    severity: critical
    description: Direct production deployment
    explanation: |
      Production deployments must go through the release pipeline.
      Direct deploys bypass approval workflows and audit logging.
      Use https://deploy.mycompany.com instead.

safe_patterns:
  - name: staging-deploy
    pattern: deploy\\s+--env\\s*=?\\s*(staging|dev)
    description: Non-production deployments are allowed
```

### Rust Struct Mapping (for the pack loader)

```rust
#[derive(Debug, Deserialize)]
pub struct ExternalPack {
    pub schema_version: u32,
    pub id: String,
    pub name: String,
    pub version: String,
    pub description: Option<String>,
    #[serde(default)]
    pub keywords: Vec<String>,
    #[serde(default)]
    pub destructive_patterns: Vec<ExternalDestructivePattern>,
    #[serde(default)]
    pub safe_patterns: Vec<ExternalSafePattern>,
}

#[derive(Debug, Deserialize)]
pub struct ExternalDestructivePattern {
    pub name: String,
    pub pattern: String,
    #[serde(default)]
    pub severity: Option<String>,
    pub description: Option<String>,
    pub explanation: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct ExternalSafePattern {
    pub name: String,
    pub pattern: String,
    pub description: Option<String>,
}
```

## Allowlists

Allowlists are layered in this order:

1. **Project**: `.dcg/allowlist.toml`
2. **User**: `~/.config/dcg/allowlist.toml`
3. **System**: `/etc/dcg/allowlist.toml`

Use project allowlists for repo-specific exceptions and user allowlists for
personal workflows.

## Hook Configuration

Scan hooks are loaded from `.dcg/hooks.toml` when present. See
`docs/scan-precommit-guide.md` for hook configuration and pre-commit examples.

## Heredoc Scanning

Heredoc scanning can be enabled or configured with:

```toml
[heredoc]
enabled = true
timeout_ms = 50
max_body_bytes = 1048576
max_body_lines = 10000
max_heredocs = 10
fallback_on_parse_error = true
fallback_on_timeout = true
```

CLI overrides:
- `--heredoc-scan` / `--no-heredoc-scan`
- `--heredoc-timeout <ms>`
- `--heredoc-languages <lang1,lang2,...>`

## Agent-Specific Profiles

dcg can detect which AI coding agent is invoking it and apply agent-specific
trust levels and configuration overrides.

```toml
[agents.claude-code]
trust_level = "high"
additional_allowlist = ["npm run build"]

[agents.unknown]
trust_level = "low"
extra_packs = ["paranoid"]
```

See [agents.md](agents.md) for full documentation on agent detection, trust
levels, and profile configuration.



================================================
FILE: docs/coverage-audit-baseline.md
================================================
# Coverage Audit & Mock Inventory Baseline

**Bead**: `git_safety_guard-xqv`
**Date**: 2026-01-08 (updated 2026-01-09)
**Agent**: MagentaBridge (updated by Opus4.5)

## Executive Summary

This document provides a baseline inventory of test coverage and mock/fake constructs in the dcg codebase. The codebase has excellent test coverage with 715+ unit tests and minimal mocking, following a "real fixtures over mocks" philosophy.

---

## Test Coverage by Module

| Module | Test Count | Notes |
|--------|------------|-------|
| `main.rs` (tests/) | 102 | Integration and edge case tests |
| `cli.rs` | 94 | CLI parsing and command validation |
| `heredoc.rs` | 90 | Heredoc extraction and analysis |
| `ast_matcher.rs` | 75 | AST pattern matching |
| `context.rs` | 60 | Command context analysis |
| `scan.rs` | 59 | Scan engine and findings |
| `packs/` | 48 | Pack system and patterns |
| `evaluator.rs` | 38 | Core evaluation engine |
| `config.rs` | 36 | Configuration parsing |
| `trace.rs` | 34 | Tracing and debugging |
| `allowlist.rs` | 24 | Allowlist management |
| `simulate.rs` | 21 | Command simulation |
| `suggestions.rs` | 14 | User-facing suggestions |
| `hook.rs` | 6 | Claude Code hook protocol |
| `corpus/` | 5 | TOML corpus regression tests |
| `perf.rs` | 3 | Performance budgets |

**Total**: 715 unit tests + 1 doctest + corpus tests

---

## Mock/Fake Inventory

### 1. Parity Test Mocks (`src/evaluator.rs:1460-1483`)

**Location**: `src/evaluator.rs:1460-1483`

```rust
struct MockSafePattern {
    regex: Regex,
}
impl LegacySafePattern for MockSafePattern { ... }

struct MockDestructivePattern {
    regex: Regex,
    reason: String,
}
impl LegacyDestructivePattern for MockDestructivePattern { ... }
```

**Purpose**: Verify parity between pack-based and legacy evaluation paths.

**Assessment**: KEEP - These mocks are intentionally testing compatibility during the pack migration. They should remain until legacy patterns are fully retired.

**Replacement Strategy**: N/A - Will be removed when legacy patterns are deleted.

---

### 2. Dummy Path Placeholders (`src/allowlist.rs`)

**Locations**: Lines 632, 645, 659, 675, 689

```rust
let file = parse_allowlist_toml(AllowlistLayer::Project, Path::new("dummy"), toml);
```

**Purpose**: Placeholder paths for TOML parsing tests. The path is only used for error message source attribution.

**Assessment**: KEEP - These are trivial and appropriate. The path value doesn't affect test behavior.

**Replacement Strategy**: N/A - Could create a `test_allowlist.toml` fixture file, but the inline TOML is actually clearer for documenting expected behavior.

---

### 3. Invalid Pack ID Test Data (`src/cli.rs`)

**Locations**: Lines 4865, 4871-4872

```rust
assert!(!is_valid_pack_id("fake.pack"));
assert!(!is_valid_pack_id("containers.fake"));
```

**Purpose**: Negative test cases for pack ID validation.

**Assessment**: KEEP - These are valid negative tests, not mocks. They test rejection of invalid inputs.

---

### 4. Test Helper Functions

| Location | Function | Purpose | Assessment |
|----------|----------|---------|------------|
| `src/cli.rs:3439` | `make_dcg_entry()` | Build test JSON | KEEP - Simple builder |
| `src/scan.rs:1805` | `make_finding()` | Create ScanFinding | KEEP - Simple builder |
| `src/scan.rs:2003` | `make_finding_at()` | Create positioned finding | KEEP - Simple builder |
| `src/scan.rs:2018` | `make_finding_at_col()` | Create finding with column | KEEP - Simple builder |
| `src/allowlist.rs:771` | `make_test_entry()` | Create AllowEntry | KEEP - Simple builder |
| `src/evaluator.rs:972-984` | `default_config()`, `default_compiled_overrides()`, `default_allowlists()` | Default fixtures | KEEP - Shared fixtures |
| `src/scan.rs:1426` | `default_config()` | Scan default config | KEEP - Local fixture |

---

### 5. Static Default Fixtures (`src/evaluator.rs:1928`)

**Location**: `src/evaluator.rs:1928-1936`

```rust
fn default_allowlists() -> &'static LayeredAllowlist {
    static ALLOWLISTS: OnceLock<LayeredAllowlist> = OnceLock::new();
    ALLOWLISTS.get_or_init(|| load_default_allowlists())
}
```

**Purpose**: Lazily-initialized shared fixture for allowlist tests.

**Assessment**: EXCELLENT - This is a best practice pattern. The fixture uses real production data, not mocks.

---

## Coverage Tool Status

**Current State**: `cargo-llvm-cov` installed but tests fail under coverage instrumentation

**Issue**: Performance budget thresholds in `src/perf.rs` are too tight for coverage-instrumented builds. Coverage instrumentation adds ~50% overhead, causing tests to exceed the 50ms budget and fail with `Timeout { elapsed_ms: 55-92, budget_ms: 50 }`.

**Failing Test Categories** (24 tests fail under coverage):
- `heredoc::tests::tier2_extraction::*` - Timeout (55-92ms vs 50ms budget)
- `ast_matcher::tests::*_fixtures::*` - Some TypeScript/JavaScript/Perl/Ruby fixtures

**Recommendations**:
1. **Short-term**: Skip performance-sensitive tests during coverage runs:
   ```bash
   cargo llvm-cov --all-features --ignore-filename-regex='(tests/|benches/|\.cargo/)' -- --skip tier2_extraction
   ```
2. **Long-term**: Add `#[cfg(not(coverage))]` guards or increase budgets for coverage mode

**Regular Test Status**: All 102+ unit tests pass without coverage instrumentation (confirmed 2026-01-09).

**Usage** (when fixed):
```bash
# Generate HTML report
cargo llvm-cov --html

# Generate lcov for CI
cargo llvm-cov --lcov --output-path lcov.info
```

---

## Proposed CI Coverage Thresholds

Based on the test distribution, these thresholds are recommended:

| Module | Current Est. | Target | Rationale |
|--------|-------------|--------|-----------|
| `evaluator.rs` | ~85% | 90% | Core safety logic |
| `heredoc.rs` | ~80% | 85% | Security-critical parsing |
| `packs/` | ~75% | 80% | Pattern matching |
| `cli.rs` | ~70% | 75% | Many edge cases |
| `config.rs` | ~80% | 85% | Configuration parsing |
| **Overall** | ~75% | **80%** | Project minimum |

**CI Configuration** (for future `.github/workflows/coverage.yml`):
```yaml
- name: Check coverage
  run: |
    cargo llvm-cov --fail-under 80
```

---

## Test Improvement Opportunities

### High Priority

1. **Add corpus edge cases for heredoc worst-case parsing**
   - Current: Performance edge cases exist (`regex_worst_case.toml`)
   - Missing: Heredoc parsing edge cases (malformed delimiters, nested heredocs)

2. **Property-based testing for pattern matching**
   - Use `proptest` or `quickcheck` for pattern matching
   - Generate random command strings to find edge cases

### Medium Priority

3. **Fuzz testing for JSON input parsing**
   - The hook protocol accepts arbitrary JSON
   - AFL or cargo-fuzz could find parsing bugs

4. **Benchmark-based regression tests**
   - Convert performance budgets in `src/perf.rs` to actual tests
   - Fail CI if regressions exceed thresholds

### Low Priority

5. **Golden file tests for CLI output**
   - Snapshot testing for `--help`, `--version`, error messages
   - Detect unintended output changes

---

## Summary

The codebase has a strong testing foundation:

- **715+ unit tests** with good module coverage
- **Minimal mocking** - almost all tests use real production code paths
- **Appropriate test helpers** - builder functions, not behavioral mocks
- **Real fixtures** - `load_default_allowlists()` uses actual config

**Key Finding**: The mock inventory is remarkably small. The `MockSafePattern` and `MockDestructivePattern` in `evaluator.rs` are the only behavioral mocks, and they exist specifically to test legacy/pack parity during migration.

**Recommendation**: Fix coverage instrumentation timeout issues (see Coverage Tool Status), then establish baseline coverage metrics. The proposed 80% threshold is achievable with the current test suite.

---

## Related Documents

- **E2E Coverage Matrix**: See `docs/design-2cu-false-positive-reduction.md` Section 7.1 for detailed E2E gap analysis covering hook, CLI, and scan flows.



================================================
FILE: docs/coverage_audit.md
================================================
# DCG Coverage Audit & Mock Inventory

**Date**: 2026-01-09
**Bead**: git_safety_guard-xqv

## Executive Summary

This audit establishes a baseline coverage map, inventories mock/fake usage in tests, and provides concrete replacement strategies.

## Test Summary

| Category | Count | Status |
|----------|-------|--------|
| Unit tests (main binary) | 105 | PASS |
| Integration tests (regression_corpus) | 5 | PASS |
| Doc tests | 1 passed, 9 ignored | PASS |
| **Total** | **111** | **PASS** |

### Tests Under Coverage Instrumentation

When running with `cargo llvm-cov`, 28 tests fail due to timeout/performance issues:

| Module | Failures | Root Cause |
|--------|----------|------------|
| `heredoc::tests::tier2_extraction` | 13 | 50ms timeout budget exceeded under instrumentation |
| `ast_matcher::tests::javascript_*` | 7 | AST parsing timeout with coverage overhead |
| `ast_matcher::tests::typescript_*` | 4 | AST parsing timeout with coverage overhead |
| `ast_matcher::tests::perl_*` | 2 | AST parsing timeout with coverage overhead |
| `ast_matcher::tests::ruby_*` | 2 | AST parsing timeout with coverage overhead |

**Recommendation**: Increase timeout budgets when running under coverage, or use `#[cfg(not(coverage))]` conditional compilation for strict timing tests.

## Coverage by Module (Estimated)

Based on test distribution and code review:

| Module | Estimated Coverage | Notable Gaps |
|--------|-------------------|--------------|
| `main.rs` | ~80% | Input size limits (new code), edge cases |
| `evaluator.rs` | ~85% | Allowlist override edge cases |
| `hook.rs` | ~75% | Error paths, colorful output truncation |
| `config.rs` | ~90% | Policy merge edge cases |
| `packs/*.rs` | ~85% | Some pattern edge cases |
| `heredoc.rs` | ~60% | Tier 2/3 extraction (timeout-sensitive) |
| `ast_matcher.rs` | ~50% | JS/TS/Perl/Ruby patterns (timeout issues) |
| `context.rs` | ~80% | Complex tokenization cases |
| `allowlist.rs` | ~85% | Layer precedence edge cases |
| `trace.rs` | ~40% | Explain mode output formatting |
| `scan.rs` | ~30% | Repository scanning (minimal tests) |
| `simulate.rs` | ~20% | New module, minimal test coverage |

### Proposed Coverage Thresholds for CI

| Threshold | Initial Target | Stretch Goal |
|-----------|----------------|--------------|
| Overall | 70% | 85% |
| Critical modules (evaluator, hook) | 80% | 90% |
| Non-critical (trace, scan) | 50% | 70% |

### CI Coverage Thresholds (Enforced)

As of 2026-01-09, CI enforces the initial targets:

- Overall line coverage: **>= 70%**
- `src/evaluator.rs` line coverage: **>= 80%**
- `src/hook.rs` line coverage: **>= 80%**

Threshold enforcement lives in `.github/workflows/ci.yml` under the
"Check coverage thresholds (enforced)" step.

## Mock/Fake Inventory

### 1. MockSafePattern / MockDestructivePattern (evaluator.rs)

**Location**: `src/evaluator.rs:1460-1493`

```rust
struct MockSafePattern {
    regex: Regex,
}

impl LegacySafePattern for MockSafePattern { ... }

struct MockDestructivePattern {
    regex: Regex,
    reason: String,
}

impl LegacyDestructivePattern for MockDestructivePattern { ... }
```

**Usage**: Tests at lines 1492, 1542, 1595, 1637, 1677, 1727

**Purpose**: Allows testing the `run_evaluation_pipeline` function without loading actual pack patterns.

**Replacement Strategy**:
1. **Option A (Recommended)**: Replace with real pack fixtures from `REGISTRY`
   - Use `REGISTRY.get_pack("core.git")` to get actual patterns
   - Tests become integration-level but verify real behavior
2. **Option B**: Create a test fixture module with pre-compiled patterns
   - Move mock definitions to `src/test_fixtures.rs`
   - Share across test modules

**Effort**: Medium (3-5 hours)
**Priority**: P2

### 2. Dummy Paths in Allowlist Tests (allowlist.rs)

**Location**: `src/allowlist.rs:632, 645, 659, 675, 689`

```rust
let file = parse_allowlist_toml(AllowlistLayer::Project, Path::new("dummy"), toml);
```

**Purpose**: Tests parsing logic without needing real files.

**Replacement Strategy**:
- Keep as-is - these are appropriate test doubles for parsing logic
- The `Path::new("dummy")` is used only for error messages/debugging
- No behavioral coupling to actual filesystem

**Effort**: N/A (acceptable pattern)
**Priority**: P4 (no action needed)

### 3. Fake Pack IDs in CLI Tests (cli.rs)

**Location**: `src/cli.rs:4870, 4876-4877`

```rust
assert!(!is_valid_pack_id("fake.pack"));
assert!(!is_valid_pack_id("containers.fake"));
```

**Purpose**: Tests validation of invalid pack identifiers.

**Replacement Strategy**:
- Keep as-is - these test negative cases correctly
- Using obviously-fake IDs like "fake.pack" is the right approach

**Effort**: N/A (acceptable pattern)
**Priority**: P4 (no action needed)

## Replacement Plan Summary

| Mock/Fake | Location | Action | Priority | Effort |
|-----------|----------|--------|----------|--------|
| MockSafePattern | evaluator.rs:1460 | Replace with real pack fixtures | P2 | 3-5h |
| MockDestructivePattern | evaluator.rs:1471 | Replace with real pack fixtures | P2 | (included above) |
| Path::new("dummy") | allowlist.rs | Keep (appropriate) | P4 | N/A |
| "fake.pack" test data | cli.rs | Keep (appropriate) | P4 | N/A |

## Compilation Issues Fixed

During this audit, the following issues were identified and fixed:

1. **Missing `Read` import** (`src/main.rs:40`)
   - Changed: `use std::io::{self, BufRead, IsTerminal}` â†’ `use std::io::{self, IsTerminal, Read}`
   - Reason: `take()` method requires `Read` trait in scope

2. **Private `merge` method** (`src/config.rs:752`)
   - Changed: `fn merge` â†’ `pub(crate) fn merge`
   - Reason: Tests in main.rs need to access this method

## Clippy Warnings

The following clippy warnings exist (all pedantic/nursery, not blocking):

| File | Warning | Category |
|------|---------|----------|
| simulate.rs:481 | must_use_candidate | pedantic |
| simulate.rs:507 | doc_markdown | pedantic |
| simulate.rs:555 | doc_markdown | pedantic |
| simulate.rs:557 | doc_markdown | pedantic |
| simulate.rs:595 | doc_markdown | pedantic |
| simulate.rs:657 | must_use_candidate | pedantic |
| simulate.rs:735 | must_use_candidate | pedantic |
| simulate.rs:823 | missing_errors_doc | pedantic |
| main.rs:467 | significant_drop_tightening | nursery |

## Recommendations

1. **Immediate**: Run `cargo clippy --fix` to resolve doc formatting warnings
2. **Short-term**: Replace evaluator mock structs with real pack fixtures (blocks git_safety_guard-1g6)
3. **Medium-term**: Increase heredoc/AST timeout budgets for coverage runs
4. **Long-term**: Add tests for scan.rs and simulate.rs modules

## Next Steps (Downstream Beads)

This audit unblocks:
- `git_safety_guard-1g6`: Replace evaluator mock tests with real pack fixtures
- `git_safety_guard-484`: Coverage: no-mock unit tests + gating
- `git_safety_guard-64n`: Replace remaining mocks/fakes with real integration fixtures
- `git_safety_guard-rl8`: Enforce coverage thresholds in CI (llvm-cov)



================================================
FILE: docs/custom-packs.md
================================================
# Custom Pack Authoring Guide

This guide covers creating external YAML packs for dcg. Custom packs let you
define organization-specific security policies without modifying the dcg binary.

## Quick Start

1. Create a pack file at `~/.config/dcg/packs/mycompany.yaml`
2. Define at least one pattern (safe or destructive)
3. Validate with `dcg pack validate ~/.config/dcg/packs/mycompany.yaml`
4. Restart dcg or reload config

See `examples/packs/example.yaml` for a complete working example.

## Pack File Structure

```yaml
# Required fields
schema_version: 1                    # Always use 1 (current version)
id: mycompany.policies               # namespace.name format
name: MyCompany Security Policies    # Human-readable name
version: 1.0.0                       # Your pack's semantic version

# Optional fields
description: |
  What this pack protects against.

keywords:                            # Trigger evaluation (recommended)
  - mycommand
  - mytool

destructive_patterns:                # Patterns that block/warn
  - name: pattern-id
    pattern: regex-pattern
    severity: critical               # critical/high/medium/low
    description: Short denial reason
    explanation: |                   # Optional detailed explanation
      Longer help text with alternatives.

safe_patterns:                       # Patterns that explicitly allow
  - name: safe-pattern-id
    pattern: safe-regex-pattern
    description: Why this is allowed
```

## Field Reference

### Required Pack Fields

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique identifier in `namespace.name` format. Must match `^[a-z][a-z0-9_]*\.[a-z][a-z0-9_]*$` |
| `name` | string | Human-readable pack name shown in messages |
| `version` | string | Semantic version (`X.Y.Z`) for your own tracking |

### Optional Pack Fields

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `schema_version` | integer | 1 | Schema version for forward compatibility |
| `description` | string | none | What this pack protects against |
| `keywords` | array | `[]` | Keywords that trigger pattern matching |
| `destructive_patterns` | array | `[]` | Patterns that block or warn |
| `safe_patterns` | array | `[]` | Patterns that explicitly allow |

### Destructive Pattern Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | string | yes | Stable identifier within the pack |
| `pattern` | string | yes | fancy-regex pattern to match |
| `severity` | string | no | `critical`, `high` (default), `medium`, `low` |
| `description` | string | no | Short reason shown on denial |
| `explanation` | string | no | Detailed explanation for verbose output |

### Safe Pattern Fields

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | string | yes | Stable identifier within the pack |
| `pattern` | string | yes | fancy-regex pattern to match |
| `description` | string | no | Why this command is allowed |

## Severity Levels

Severity determines the default action when a command matches:

| Severity | Default Action | Use Case |
|----------|---------------|----------|
| `critical` | Always deny | Irreversible operations (rm -rf /, DROP DATABASE) |
| `high` | Deny (allowlistable) | Dangerous but sometimes needed (force push, truncate) |
| `medium` | Warn but allow | Worth noting but not blocking (large deletes) |
| `low` | Log only | Learning/audit purposes |

## Keywords Best Practices

Keywords gate pattern evaluation. Commands without any keywords skip the pack
entirely, improving performance.

**Do:**
- Use specific, unambiguous keywords: `kubectl`, `terraform`, `mycompany-deploy`
- Include common aliases if applicable: `k` for kubectl
- Keep the list short (< 10 keywords)

**Don't:**
- Use single letters or common words: `a`, `run`, `do`
- Include partial matches: `rm` instead of `rm -rf`
- Omit keywords (forces evaluation on every command)

## Regex Pattern Guidelines

Patterns use [fancy-regex](https://docs.rs/fancy-regex) syntax, which supports:
- Standard regex: `\s`, `\w`, `.*`, `[a-z]+`
- Lookahead: `(?=...)`, `(?!...)`
- Lookbehind: `(?<=...)`, `(?<!...)`
- Backreferences: `\1`, `\2`

### Performance Considerations

dcg uses a dual regex engine:
- **Linear engine** (O(n)): For simple patterns without lookahead/lookbehind
- **Backtracking engine**: For patterns requiring advanced features

Simple patterns are faster. The validator reports which engine each pattern uses.

### Pattern Specificity

Write patterns that match **exactly** what you want to block:

```yaml
# Too broad - matches "rm" anywhere
pattern: rm

# Too narrow - misses "rm -rf --no-preserve-root"
pattern: rm\s+-rf\s+/

# Good - matches rm -rf variations targeting root or system paths
pattern: \brm\s+(?:-[a-zA-Z]*r[a-zA-Z]*\s+)*(?:-[a-zA-Z]*f[a-zA-Z]*\s+)*(?:/|/\*|/usr|/etc|/var|/home)
```

### Anchoring

Use word boundaries (`\b`) to avoid matching substrings:

```yaml
# Matches "deploy", "deployer", "redeploy"
pattern: deploy

# Only matches "deploy" as a word
pattern: \bdeploy\b
```

### Flag Handling

Match flags flexibly to handle different orderings:

```yaml
# Handles: --env prod, --env=prod, --env  prod
pattern: --env\s*[=\s]?\s*prod
```

## Schema Versioning

The `schema_version` field enables forward compatibility:

- **Version 1** (current): All fields documented in this guide
- Future versions may add new fields but will maintain backward compatibility
- Packs with `schema_version` higher than supported are rejected with a clear error

When dcg adds new features (e.g., new pattern fields), the schema version
increments. Your existing packs continue working; only new features require
updating `schema_version`.

## Pack ID Collision Rules

External packs **cannot** override built-in packs. This prevents accidental or
malicious security bypasses.

### Built-in Pack Namespaces (Reserved)

- `core.*` - Git, filesystem operations
- `database.*` - PostgreSQL, MySQL, MongoDB, Redis, SQLite
- `containers.*` - Docker, Podman, Compose
- `kubernetes.*` - kubectl, Helm, Kustomize
- `cloud.*` - AWS, Azure, GCP
- `storage.*` - S3, GCS, MinIO, Azure Blob
- `infrastructure.*` - Terraform, Pulumi, Ansible
- `backup.*` - Restic, rclone
- `cdn.*`, `apigateway.*`, `monitoring.*`, `messaging.*`, `search.*`, `secrets.*`
- ...and others (see `dcg packs list` for full list)

### Choosing Your Namespace

Use a unique namespace that identifies your organization:

```yaml
# Good - unique to your organization
id: acmecorp.deploy
id: myproject.database
id: internal.tools

# Bad - collides with built-in
id: core.git          # Error: collides with built-in pack 'Git'
id: database.custom   # Might collide with future built-ins
```

### Collision Detection

The validator checks for collisions:

```
$ dcg pack validate malicious.yaml
Error: Pack ID 'core.git' collides with built-in pack 'Git'.
External packs cannot override built-in security packs.
```

## Validation

Always validate packs before deployment:

```bash
dcg pack validate ~/.config/dcg/packs/mycompany.yaml
```

The validator checks:
- YAML syntax
- Schema compliance
- ID format (`namespace.name`)
- Version format (semantic versioning)
- Pattern compilation (catches invalid regex)
- Duplicate pattern names
- Built-in pack collisions
- Regex engine selection (reports linear vs backtracking)

### Example Validation Output

```
Validating: mycompany.yaml

Pack Information:
  ID:      mycompany.deploy
  Name:    MyCompany Deployment Policies
  Version: 1.0.0

Patterns:
  prod-direct-deploy (destructive, critical) [linear engine]
  staging-dev-deploy (safe) [linear engine]

Engine Summary: 2 patterns, 100% linear (optimal performance)

Result: Valid
```

## Loading Custom Packs

### Configuration

Add pack paths in your config file:

```toml
# ~/.config/dcg/config.toml or .dcg.toml
[packs]
custom_paths = [
  "~/.config/dcg/packs/*.yaml",
  ".dcg/packs/*.yaml",
  "/etc/dcg/packs/*.yaml"
]
```

### Load Order and Precedence

1. **Built-in packs** load first (cannot be overridden)
2. **External packs** load in path order (later paths override earlier)
3. For duplicate external IDs, last loaded wins

This allows:
- System-wide packs in `/etc/dcg/packs/`
- User overrides in `~/.config/dcg/packs/`
- Project-specific packs in `.dcg/packs/`

### Fail-Open Loading

Invalid pack files generate warnings but don't block loading:

```
Warning: Failed to load pack from /etc/dcg/packs/broken.yaml: Invalid pattern 'test-pattern' ([unclosed): regex parse error
Loaded 3 external packs (1 warning)
```

This ensures a typo in one pack doesn't disable all protection.

## FAQ

### Q: My pattern isn't matching. How do I debug?

Use `dcg test` with your command:

```bash
dcg test "deploy --env prod"
```

This shows which packs evaluated and which patterns matched.

### Q: Can I override a built-in pattern?

No. Built-in packs cannot be overridden by external packs for security.
Instead, use allowlists to permit specific commands:

```toml
# ~/.config/dcg/allowlist.toml
[[rules]]
command_prefix = "git push --force origin feature/"
reason = "Force push allowed on feature branches"
```

### Q: How do I test my pack before deploying?

```bash
# Validate syntax and patterns
dcg pack validate mypack.yaml

# Test against specific commands
dcg test --pack-path mypack.yaml "dangerous-command"
```

### Q: What happens if schema_version is higher than supported?

dcg rejects the pack with a clear error:

```
Error: Schema version 99 is not supported (max: 1)
```

This prevents newer packs from silently failing on older dcg versions.

### Q: Can I use lookahead/lookbehind in patterns?

Yes. fancy-regex supports all common regex features. However, patterns with
lookahead/lookbehind use the backtracking engine, which is slightly slower.
The validator reports which engine each pattern uses.

### Q: How many patterns can I have in a pack?

There's no hard limit, but for performance:
- Aim for < 50 patterns per pack
- Use keywords to skip evaluation when possible
- Prefer specific patterns over broad ones

### Q: How do I share packs with my team?

Options:
1. Check packs into your repo in `.dcg/packs/`
2. Host on a shared filesystem (`/etc/dcg/packs/`)
3. Distribute via your configuration management system

## See Also

- `docs/pack.schema.yaml` - JSON Schema for pack files
- `docs/configuration.md` - General dcg configuration
- `examples/packs/example.yaml` - Complete working example



================================================
FILE: docs/decision-dfa-backend.md
================================================
# Decision: regex-automata DFA Backend

**Decision ID:** ksk.8.2
**Date:** 2026-01-11
**Status:** CLOSED - DROP
**Author:** Claude Opus 4.5

## Context

Task ksk.8 explored using `regex-automata` as an alternative/supplement to the current `regex`/`fancy-regex` dual-engine approach. The feasibility study (ksk.8.1) completed benchmarks and recommended a "hybrid approach" (Option B).

## Decision

**DROP the regex-automata DFA backend initiative.**

The marginal benefits do not justify the added complexity.

## Rationale

### Performance Analysis

| Metric | Current | With regex-automata | Delta |
|--------|---------|---------------------|-------|
| Match time (is_match) | ~47ns | ~48ns | -2% slower |
| Match time (find) | ~49ns | ~52ns | -6% slower |
| Pack evaluation (match found) | ~75ns | ~78ns | -4% slower |
| Pack evaluation (no match) | ~312ns | ~318ns | -2% slower |
| Compilation time | baseline | +40-60% | slower |
| Binary size | 39 MB | +2-5% | larger |

**Key finding:** regex-automata is actually **slower** across all measured operations, not faster. The only improvement is ~27-32% faster handling of pathological ReDoS patterns, which both engines already handle in O(n) time.

### Cost-Benefit Summary

**Costs:**
- Three regex engines to maintain (regex, fancy-regex, regex-automata)
- ~2-5% binary size increase
- Increased code complexity in `CompiledRegex` enum
- Risk of subtle behavioral differences between engines
- Developer cognitive load (which engine for which pattern?)

**Benefits:**
- Slightly better ReDoS resistance on edge cases (already O(n) with current impl)
- Future potential for multi-pattern DFA optimization (speculative)
- Unified API potential (not realized in hybrid approach)

### Decisive Factor

The current implementation already achieves **sub-50ns matching** and **~650 MiB/s throughput**. These numbers are excellent for dcg's use case. Adding complexity to achieve marginal (or negative) performance changes is not justified.

## Alternatives Considered

1. **Option A (Full replacement):** Not viable - loses RegexSet benefits, higher compilation time
2. **Option B (Hybrid approach):** Rejected - complexity cost outweighs marginal benefits
3. **Option C (RegexSet optimization):** Could be explored independently without regex-automata

## Action Items

1. Keep `regex-automata` as dev-dependency only (for benchmark comparisons)
2. Close ksk.8 and ksk.8.2 as "dropped/deferred"
3. Remove from active roadmap
4. Revisit if:
   - Performance regression is detected in future
   - regex-automata gains significant advantages in new versions
   - Multi-pattern matching becomes a bottleneck

## References

- [Feasibility Report](regex-automata-feasibility-report.md)
- Benchmark code: `benches/regex_automata_comparison.rs`
- Task tracker: ksk.8, ksk.8.1, ksk.8.2



================================================
FILE: docs/design-2cu-false-positive-reduction.md
================================================
# Design: False Positive Reduction for String Arguments

## Status: DESIGN COMPLETE
**Author:** SunnyMill
**Date:** 2026-01-08
**Bead:** git_safety_guard-2cu
**Reviewed:** Pending

---

## 1. Executive Summary

This design formalizes the execution-context model and Safe String-Argument Registry already implemented in `src/context.rs`. It defines:
1. When to skip pattern matching (safe data contexts)
2. How to integrate context classification into the evaluator pipeline
3. Performance budget and test matrix

---

## 2. Execution Context Model

### 2.1 SpanKind Enum (Existing Implementation)

The classification uses six distinct context types:

| SpanKind | Pattern Check? | Description |
|----------|---------------|-------------|
| **Executed** | YES | Command word or unquoted argument |
| **InlineCode** | YES | Content after -c/-e flags (bash -c, python -c) |
| **HeredocBody** | YES | Heredoc content (escalate to Tier 2/3) |
| **Unknown** | YES | Ambiguous context (conservative treatment) |
| **Argument** | NO* | Double-quoted argument to non-code command |
| **Data** | NO | Single-quoted string (no substitution possible) |

*Argument spans MAY have pattern matching applied at lower priority; current design skips them.

### 2.2 Decision Rules

1. **Ambiguity â†’ Executed**: If classification is uncertain, treat as executable
2. **Single quotes are always safe**: No variable expansion or command substitution
3. **Double quotes require analysis**: Check for $() and backticks inside
4. **Inline code commands (-c/-e/-r)**: Always treat following argument as code

### 2.3 Supported Inline Code Commands

```rust
inline_code_commands: &[
    "bash", "sh", "zsh", "ksh", "dash",  // shells with -c
    "python", "python3", "python2",       // python with -c
    "node", "nodejs",                     // node with -e
    "ruby", "perl", "php", "lua",         // various -e/-r
]
```

---

## 3. Safe String-Argument Registry

### 3.1 Scope Definition

The registry maintains TWO categories:

#### 3.1.1 All-Args-Data Commands
Commands where ALL arguments are purely printed output:
- `echo`
- `printf`

#### 3.1.2 Flag-Data Pairs
Specific command+flag combinations where the flag's value is documentation/data:

| Command | Flags | Rationale |
|---------|-------|-----------|
| **git** | -m, --message | Commit/tag messages |
| **bd** | --description, --title, --notes, --reason | Issue tracking metadata |
| **grep** | -e, --regexp, -F, --fixed-strings | Search patterns |
| **rg** | -e, --regexp, --fixed-strings | Search patterns |
| **gh** | -t, --title, -b, --body, -m, --message | GitHub CLI metadata |
| **cargo** | --message | Package metadata |
| **npm** | --message | Package metadata |

### 3.2 Conservative Extension Rules

New entries MUST satisfy ALL criteria:
1. Arguments are NEVER executed by the shell
2. Use case documented with real-world false positive example
3. Test case demonstrating both the false positive and the fix
4. No flag collision with code-executing flags (e.g., never add bash -c)

---

## 4. Integration Strategy

### 4.1 Two-Phase Approach

**Phase 1 (Current):** Sanitization before pattern matching
```
command â†’ sanitize_for_pattern_matching() â†’ sanitized_command â†’ pattern_match()
```

**Phase 2 (Future):** Span-aware pattern matching
```
command â†’ classify_command() â†’ spans[] â†’ match_executable_spans_only()
```

### 4.2 Integration Point in Evaluator

Modify `evaluate_command_with_legacy()` in `src/evaluator.rs`:

```rust
// Before Step 5 (legacy safe patterns):
let sanitized = context::sanitize_for_pattern_matching(&normalized);

// Use sanitized for legacy pattern matching
for pattern in safe_patterns {
    if pattern.is_match(&sanitized) { ... }
}
for pattern in destructive_patterns {
    if pattern.is_match(&sanitized) { ... }
}

// Pack matching also uses sanitized
REGISTRY.check_command(&sanitized, &enabled_packs)
```

### 4.3 Backward Compatibility

- Original command preserved for logging/explain output
- Sanitized command used only for pattern matching
- No behavioral change for commands without safe-data arguments

---

## 5. Test Matrix

### 5.1 Must-ALLOW Cases (False Positives to Eliminate)

| Command | Contains | Why Safe |
|---------|----------|----------|
| `git commit -m "Fix reset --hard detection"` | reset --hard | Message is data |
| `git commit -m "docs: git reset --hard"` | reset --hard | Message is data |
| `bd create --description="blocks git clean"` | git clean | Description is data |
| `bd update --notes="test git clean -f"` | clean -f | Notes is data |
| `echo "example: git reset --hard"` | reset --hard | echo args are data |
| `printf "git push --force %s"` | push --force | printf args are data |
| `grep "reset --hard" patterns.txt` | reset --hard | First positional arg is pattern |
| `rg -e "git push --force" src/` | push --force | -e flag is pattern |
| `rg "git clean -fd" --json` | clean -fd | First positional arg is pattern |
| `gh issue create -t "Fix git clean bug"` | git clean | Title is data |
| `gh pr create -b "Updates git reset"` | reset | Body is data |

**Note:** `git log --grep` is NOT currently in SafeStringRegistry - this is a registry gap to address in fpim.

### 5.2 Must-BLOCK Cases (True Positives to Preserve)

| Command | Contains | Why Dangerous |
|---------|----------|---------------|
| `rm -rf /home/user` | rm -rf | Direct execution |
| `git reset --hard HEAD` | reset --hard | Direct git command |
| `git push --force origin main` | push --force | Direct git command |
| `bash -c "git reset --hard"` | reset --hard | Inline code execution |
| `python -c "import os; os.system('rm')"` | os.system | Inline code execution |
| `sh -c 'git clean -fd'` | clean -fd | Inline code execution |
| `echo $(git reset --hard)` | reset --hard | Command substitution |
| `git commit -m "$(git push --force)"` | push --force | Subst in message |

### 5.3 Edge Cases

| Command | Decision | Rationale |
|---------|----------|-----------|
| `git commit -m 'reset --hard'` | ALLOW | Single quotes = data |
| `git commit -m "$(date)"` | ALLOW* | Substitution but safe content |
| `echo "normal text"` | ALLOW | No dangerous content |
| `bd create --title="test" && git clean` | BLOCK | After && is executed |
| `grep "pattern" src/ \| xargs rm` | per-segment | Pipe creates segments |

*Note: `$(date)` contains substitution but the command itself (`date`) is safe. However, conservative implementations may block any substitution in arguments.

---

## 6. Performance Budget

### 6.1 Targets

| Operation | Budget | Measured |
|-----------|--------|----------|
| Context classification | <100Î¼s | ~2Î¼s avg |
| Sanitization | <100Î¼s | ~5Î¼s avg |
| Full pipeline addition | <200Î¼s | <50Î¼s typ |

### 6.2 Constraints

1. No per-command regex compilation for sanitization
2. Tokenization is O(n) single-pass
3. SafeStringRegistry uses static arrays (constant-time lookup)
4. Cow<str> avoids allocation when no sanitization needed

### 6.3 Validation

```rust
#[test]
fn test_performance_typical_commands() {
    // Assert <100Î¼s per command average
    assert!(avg_microseconds < 100.0);
}
```

---

## 7. Implementation Status

| Component | Status | Location |
|-----------|--------|----------|
| SpanKind enum | âœ… Implemented | context.rs:27-56 |
| ContextClassifier | âœ… Implemented | context.rs:220-497 |
| SafeStringRegistry | âœ… Implemented | context.rs:535-672 |
| sanitize_for_pattern_matching | âœ… Implemented | context.rs:722-870 |
| Unit tests | âœ… 50+ tests | context.rs:1278-1873 |
| **Evaluator integration** | âŒ NOT DONE | evaluator.rs (needs update) |
| E2E tests | âš ï¸ Partial | e2e_test.sh |

---

### 7.1 E2E Coverage Matrix (Gap Analysis)

This matrix captures current E2E coverage across hook + CLI + scan flows. It
highlights gaps and the script(s) that provide coverage today.

| Area | Hook | CLI | Scan | Evidence | Notes / Gaps |
|------|------|-----|------|----------|--------------|
| Hook allow/deny core (git/rm) | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Broad allow/deny cases + path normalization |
| Policy modes (warn/log/deny) | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Uses `DCG_POLICY_DEFAULT_MODE` |
| Pack enablement (non-core packs) | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Docker/K8s/DB/infra packs via `DCG_PACKS` |
| Non-Bash tools ignored | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Read/Write/Edit/Grep/Glob |
| Malformed hook input | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Invalid JSON, missing fields |
| Allowlist (project layer) | âœ… | â€” | â€” | `scripts/e2e_test.sh` | Rule allow/expire/conditions |
| Allowlist layering (user/system) | âŒ | â€” | â€” | â€” | No precedence tests across project/user/system |
| Config precedence (env/project/user/system) | âŒ | âŒ | âŒ | â€” | Needs hermetic HOME/XDG + temp project |
| Config overrides (allow/block regex) | âŒ | âŒ | âŒ | â€” | No E2E that validates override regex behavior |
| Doctor (install/uninstall + health) | â€” | âŒ | â€” | â€” | No E2E coverage for settings.json edits |
| `dcg test` CLI | â€” | âŒ | â€” | â€” | No E2E for CLI test command behavior |
| `dcg explain` formats | â€” | âŒ | â€” | â€” | Pretty/compact/json not validated |
| `dcg simulate` formats | â€” | âŒ | â€” | â€” | Parser/output not exercised end-to-end |
| Scan `--staged` (basic) | â€” | â€” | âœ… | `scripts/scan_precommit_e2e.sh` | Empty/destructive/data-only/mixed |
| Scan `--git-diff` (CI) | â€” | â€” | âœ… | `scripts/scan_gitdiff_e2e.sh` | Add/modify/rename/delete + ordering |
| Scan output schema + determinism | â€” | â€” | âœ… | `scripts/scan_precommit_e2e.sh` | JSON schema + ordering |
| Scan extractors: GitHub Actions | â€” | â€” | âœ… | `scripts/scan_precommit_e2e.sh` | `run:` extraction |
| Scan `--paths` include/exclude | â€” | â€” | âŒ | â€” | No E2E for include/exclude glob behavior |
| Scan install/uninstall pre-commit | â€” | â€” | âŒ | â€” | No E2E for hook install/uninstall |
| Scan limits (max_findings/size/truncate) | â€” | â€” | âŒ | â€” | No E2E for caps/truncation |
| Heredoc detection (multi-lang) | âš ï¸ | â€” | â€” | `scripts/e2e_test.sh` | Tests present but depend on heredoc epic |
| Execution-context sanitization | âš ï¸ | â€” | â€” | `scripts/e2e_test.sh` | Tests present but depend on t8x epic |

**Gap priorities**
1. **P0**: allowlist layering, config precedence, doctor install/uninstall (correctness + safety).
2. **P1**: explain/simulate CLI coverage; scan limits + `--paths`; scan pre-commit install/uninstall.
3. **P2**: expand path/quoting/encoding matrix + cross-platform variants; add `dcg test` CLI E2E.

### 7.2 Proposed E2E Additions (Scripts/Tests)

These are concrete, minimal E2E additions to close the gaps above.

**P0 (must-have)**
- Extend `scripts/e2e_test.sh` to cover allowlist layering (project/user/system precedence) using a temp repo + temp HOME/XDG_CONFIG_HOME. Rationale: allowlist correctness gates safe bypasses.
- Add a config precedence E2E harness (new `scripts/e2e_config_precedence.sh` or a new section in `scripts/e2e_test.sh`). Rationale: env/project/user/system precedence bugs silently misconfigure protection.
- Add a doctor E2E harness (e.g., `scripts/doctor_e2e.sh`) that operates on a temp `settings.json`. Rationale: installation health checks must be reliable and safe.

**P1 (high)**
- Add `dcg explain` E2E coverage (pretty/compact/json) and validate stable pack + pattern IDs. Rationale: users depend on explain for debugging and allowlist rules.
- Add `dcg simulate` E2E coverage for parser and output formats, including truncation/redaction. Rationale: simulate is the onboarding/debugging path for large command corpora.
- Add `dcg scan --paths` E2E coverage with include/exclude globs + fail-on thresholds. Rationale: CI workflows typically use paths, not just staged/diff.
- Extend scan E2E to cover `max_findings`, `max_file_size`, and `truncate`. Rationale: limits are safety valves and must be deterministic.

**P2 (nice-to-have)**
- Expand path/quoting/encoding matrix in `scripts/e2e_test.sh` for path normalization and quoting edge cases. Rationale: reduces false positives and platform drift.
- Add a small `dcg test` CLI E2E section to validate CLI parity with hook decisions. Rationale: parity prevents confusion during debugging.

---

## 8. Remaining Work

### 8.1 High Priority
1. Integrate `sanitize_for_pattern_matching()` into evaluator pipeline
2. Add E2E tests for false positive scenarios from Section 5.1
3. Document in README/help output that string arguments are context-aware

### 8.2 Medium Priority
4. Consider extending registry for more commands (jq, sed patterns, awk scripts)
5. Add `dcg explain` output showing sanitization decisions

### 8.3 Low Priority
6. Investigate tree-sitter-bash for more accurate tokenization
7. Add configuration for custom safe-flag entries

---

## 9. References

- git_safety_guard-t8x: Epic: False Positive Immunity
- git_safety_guard-fpim: Implement false positive reduction (in_progress by PurpleRobin)
- git_safety_guard-2ta: Two-tier detection architecture (in_progress by RusticPuma)
- src/context.rs: Full implementation

---

## 10. Appendix: Counterexamples (What NOT to Add)

These should NEVER be in SafeStringRegistry:
- `bash -c` â†’ Executes code
- `python -c` â†’ Executes code
- `xargs` â†’ Can execute arbitrary commands
- `eval` â†’ Executes arbitrary string
- `exec` â†’ Replaces process
- `source` / `.` â†’ Executes script file

---

## 11. Meta-Note: Ironic False Positive

While writing this design document, the command `bd update --notes="..."` was blocked because the notes content contained dangerous patterns being documented. This is the exact problem this design solves - the ACFS hook (Python predecessor) doesn't have context awareness, but dcg with this design will allow such documentation commands.



================================================
FILE: docs/design-allow-once-short-code.md
================================================
# Design: Allow-Once Short-Code Exceptions

## Status: DRAFT
**Author:** ChartreuseForest  
**Date:** 2026-01-10  
**Bead:** git_safety_guard-oien.1  
**Reviewed:** Pending

---

## 1. Executive Summary

This design specifies a short-code "allow-once" exception flow that:
- Provides a time-limited escape hatch for false positives.
- Preserves safety guarantees (scoped to exact command + cwd).
- Is auditable, deterministic, and safe under concurrent hook execution.

The flow adds a pending-exceptions store that records short codes on deny
and allows users to grant temporary exceptions by code.

---

## 2. UX Overview

### 2.1 Deny Output (Hook)

On deny, print a short code at the very top of the message:

```
ALLOW-ONCE CODE: ab12
To allow once: dcg allow-once ab12
```

Notes:
- Code is always shown when a block occurs.
- Keep the first line short for TUI truncation.
- Code is lowercase hex.

### 2.2 CLI Commands

```
dcg allow-once <code>
dcg allow-once <code> --single-use
dcg allow-once <code> --show-raw
dcg allow-once <code> --hash <full_hash>
dcg allow-once <code> --index <n>
```

Behavior:
- Default is reusable until expiry (exact command + cwd match).
- `--single-use` marks the exception as consumed after the first allow.
- `--show-raw` reveals the raw command when resolving collisions.
- `--hash` or `--index` disambiguates collisions non-interactively.
- If the code maps to multiple pending entries, the CLI must disambiguate
  (see Section 5.3).

---

## 3. Short-Code Generation

### 3.1 Hash Input

Hash input string (exact formatting, including spaces):

```
"<timestamp> | <cwd> | <command_raw>"
```

Fields:
- `timestamp`: RFC3339 UTC format, seconds precision (e.g., `2026-01-10T06:30:00Z`).
  - Fallback: if RFC3339 formatting fails, use Unix epoch seconds as a decimal string.
- `cwd`: absolute current working directory string as observed by the hook (literal cwd, not repo root).
- `command_raw`: full raw command text as executed (no normalization; includes whitespace/newlines).

### 3.2 Hash Output

- `full_hash`: SHA-256 of the input string, lowercase hex.
- `short_code`: last 4 hex chars of `full_hash`.

Collision policy:
- Short code is for UI only.
- Store `full_hash` and all metadata per record.
- Multiple records may share a short code and must be disambiguated.

---

## 4. Storage Design

### 4.1 Location

Default path (user scope):
```
~/.config/dcg/pending_exceptions.jsonl
```

Notes:
- Use `dirs::config_dir()` and `dcg` subdir, consistent with allowlist.
- Add optional env override for tests:
  - `DCG_PENDING_EXCEPTIONS_PATH`

### 4.2 Format: JSONL

Rationale:
- Append-only, safe for concurrent writes.
- Deterministic field order via struct field order in serialization.

Each line is a JSON object with fixed field order:

```json
{
  "schema_version": 1,
  "short_code": "ab12",
  "full_hash": "0123abcd...ff",
  "created_at": "2026-01-10T06:30:00Z",
  "expires_at": "2026-01-11T06:30:00Z",
  "cwd": "/abs/path",
  "command_raw": "git reset --hard HEAD",
  "command_redacted": "git reset --hard ***",
  "reason": "Blocked by core.git:reset-hard",
  "single_use": false,
  "consumed_at": null
}
```

Rules:
- `schema_version` is required (current = 1).
- `expires_at` is computed at creation time (now + 24h).
- `consumed_at` is null unless consumed (single-use only).
- `command_redacted` is used for display and logs by default.

### 4.3 Deterministic Ordering

Ensure serialization uses a struct with fields in the exact order above.
Do not serialize maps with nondeterministic key ordering.

---

## 5. Record Lifecycle

### 5.1 Creation

On deny:
- Create a new record with the computed hash and metadata.
- Append to JSONL file as a single write (newline-terminated).
- Return the short code to the user.

### 5.2 Pruning

On load or every write:
- Drop entries where `expires_at` is in the past.
- Drop entries with `consumed_at` set (single-use only).
- Log pruned count (see Section 7).

### 5.3 Collision Handling

When `dcg allow-once <code>` is called:
- Load all active records matching `short_code`.
- If zero matches: return a clear error (code expired or unknown).
- If one match: grant exception.
- If multiple matches:
  - Show a table of redacted commands with index, created_at, cwd, and full_hash prefix.
  - Require `--hash <full_hash>` or `--index <n>` to disambiguate.
  - If TTY and no flag, prompt for selection (safe, local-only).

---

## 6. Concurrency & Integrity

### 6.1 Atomic Append

Use `OpenOptions::new().create(true).append(true)` and write each JSON line
with a single `write_all()` call. This preserves atomicity on POSIX.

### 6.2 Partial Corruption (Fail-Open)

Parsing strategy:
- Read file line-by-line.
- Parse each line independently.
- If a line fails to parse, skip it and continue.
- If the entire file is unreadable, treat as empty and continue (fail-open).

Rationale:
- The hook must not block or crash due to a corrupt store.
- Corruption should never prevent command execution.

---

## 7. Logging & Redaction

### 7.1 Redaction

Store both:
- `command_raw` for exact match + hashing.
- `command_redacted` for display/log output (default).

Redaction should:
- Remove obvious secrets (tokens, passwords, long hex strings).
- Mirror the logging redaction behavior where possible.

### 7.2 Logging Events

Log when:
- Entries are pruned (expired or consumed).
- A pending exception is consumed (single-use).

Log format should include:
- `short_code`, `full_hash`, `cwd`, `created_at`, `expires_at`, `consumed_at`.
- Use redacted command by default unless `--show-raw`.

---

## 8. Security & Scope

Scope enforcement:
- Exceptions are bound to exact `command_raw` and `cwd`.
- No canonicalization: matching uses the exact raw command text captured at deny time.
- Allow-once overrides pack denies, but not explicit config block overrides
  unless the CLI is invoked with `--force` (separate task).

Expiry:
- All records expire after 24 hours (non-configurable for MVP).

---

## 9. Testing Plan

Unit tests must cover:
- Hash input formatting and short code derivation.
- RFC3339 timestamp format parsing and expiry checks.
- Pruning expired and consumed entries.
- Collision disambiguation behavior.
- Redaction output vs raw command.
- Fail-open on corrupt lines or missing file.

E2E tests:
- Deny emits code on first line.
- `dcg allow-once <code>` allows the exact command + cwd.
- `--single-use` consumes after first allow.

---

## 10. Implementation Notes (Non-Normative)

- Reuse `chrono::Utc::now().format("%Y-%m-%dT%H:%M:%SZ")` for timestamp.
- Keep serialization simple with a `struct PendingException`.
- Avoid new deps if possible; if locking is required, prefer `fs2` (explicit version).



================================================
FILE: docs/design-lazy-pack-registry.md
================================================
# Design: Lazy Pack Registry + Lazy Regex Compilation

Goal: eliminate eager regex compilation from the hot path while preserving
behavior and attribution exactly (isomorphism).

## Goals

- List packs/keywords without compiling regex.
- Allow-path quick-reject without compiling regex.
- Compile regex only for enabled packs actually evaluated.
- Preserve ordering, attribution, and fail-open behavior.

## Non-Goals

- Changing patterns, policy, or allow/deny semantics.
- Altering pack ordering or safe-before-destructive logic.
- Introducing a daemon or persistent service.

## Proposed Types (metadata-only packs)

### PackSpec

```rust
pub struct PackSpec {
    pub id: &'static str,
    pub name: &'static str,
    pub description: &'static str,
    pub keywords: &'static [&'static str],
    pub safe_patterns: &'static [SafePatternSpec],
    pub destructive_patterns: &'static [DestructivePatternSpec],
}
```

### SafePatternSpec

```rust
pub struct SafePatternSpec {
    pub name: &'static str,
    pub pattern: &'static str,
    pub compiled: std::sync::OnceLock<CompiledRegex>,
}
```

### DestructivePatternSpec

```rust
pub struct DestructivePatternSpec {
    pub name: Option<&'static str>,
    pub pattern: &'static str,
    pub reason: &'static str,
    pub severity: Severity,
    pub compiled: std::sync::OnceLock<CompiledRegex>,
}
```

### Lazy Compile API

```rust
impl SafePatternSpec {
    pub fn is_match(&self, haystack: &str) -> bool;
    pub fn find_span(&self, haystack: &str) -> Option<(usize, usize)>;
}

impl DestructivePatternSpec {
    pub fn is_match(&self, haystack: &str) -> bool;
    pub fn find_span(&self, haystack: &str) -> Option<(usize, usize)>;
}
```

- `CompiledRegex` comes from `src/packs/regex_engine.rs` and auto-selects
  linear vs backtracking engine.
- `OnceLock::get_or_init` is used on first match attempt only.

## Registry Structure

`PackRegistry` stores only `PackSpec` (no compiled regex).

Derived data:
- `keywords` list is computed from `PackSpec.keywords`.
- `expand_enabled_ordered` uses pack IDs only.

Evaluation:
- **Safe pass:** iterate safe patterns across enabled packs; on first match
  return allow.
- **Destructive pass:** iterate destructive patterns across enabled packs;
  return the first match (respecting severity/mode).

Compilation happens only when a pattern is actually evaluated.

## Keyword Index + Candidate Pack Selection

This section specifies the keyword gating semantics that the index must
preserve. It applies to quick-reject and any future "candidate pack"
pre-filter, and is designed to be **conservative** (never more restrictive
than the legacy `pack.might_match`).

### Executable spans (context classification)

Keyword gating operates on **executable spans** only, derived from
`context::classify_command()`:

- The command is tokenized into spans tagged as `Executed`, `Argument`,
  `InlineCode`, or `Comment`.
- **Only `Executed` spans are searched for keywords.**
  - This avoids keyword hits inside data-only arguments, comments, or inline
    code examples.
- If no executable spans are detected, keyword gating treats the command as
  non-executable content and **quick-rejects** (safe to skip pack evaluation).

### Word-boundary matching

Keyword matching is **token-aware** within executable spans:

- A keyword match is valid only when it respects word boundaries for ASCII
  word characters (`[A-Za-z0-9_]`).
- Boundary rules are based on the keyword itself:
  - If the keyword begins with a word character, the preceding byte must be
    non-word or span start.
  - If the keyword ends with a word character, the following byte must be
    non-word or span end.
  - Keywords that begin/end with non-word characters do **not** require a
    boundary on that side (e.g., `/usr/bin/git` or `--flag`).
- Substring matches inside longer tokens **do not** count
  (e.g., `"cat .gitignore"` does not match `git`).

### Candidate pack selection (superset rule)

Candidate selection must be **no more restrictive** than the current
`pack.might_match` behavior. It may be more permissive, but never stricter:

1. **Fast substring prefilter (optional)**: use SIMD substring search across
   the raw command to avoid expensive classification when no keywords appear.
2. **Normalized executable scan**: if any keyword survives the span + boundary
   checks, **include** that pack in the candidate set.
3. **Superset guarantee**: if `pack.might_match(cmd)` would return `true`,
   the candidate set **must include** that pack.

### Normalization + fallback behavior

Keyword gating should run on a **normalized** view of the command:

- Strip wrapper prefixes (`sudo`, `env`, `command`, leading backslash).
- Dequote only **executed command words** (arguments remain untouched).
- Strip common absolute paths (`/usr/bin/git` â†’ `git`).

Fallbacks must remain conservative:

- If **no keywords are configured**, do **not** quick-reject; evaluate packs.
- If normalization produces an **owned** string (wrapper stripped/dequoted),
  use the normalized value for scanning.
- If normalization cannot safely slice (e.g., tokenizer failure),
  treat the original command as the scan source (fail open).

### Validation mapping

Add tests that explicitly assert:

- Word-boundary semantics (`git` vs `gitignore`, `/usr/bin/git`).
- Executable-span filtering (keywords in comments/strings do not match).
- Candidate-pack superset behavior vs `pack.might_match`.
- Empty keyword list disables quick-reject.

## Isomorphism Guarantees

1) **Ordering unchanged**
   - Same `expand_enabled_ordered` tier + lexicographic sort.
2) **Safe-before-destructive unchanged**
   - Two-pass evaluation preserved.
3) **Attribution unchanged**
   - Pack ID and pattern name sourced from the same specs; no renaming.
4) **Allowlist scope unchanged**
   - Allowlisting still bypasses only the matched rule, not the pack.
5) **Fail-open unchanged**
   - Regex execution errors still treated as non-match.
6) **Decision parity**
   - For any command, the first matching rule (by order) and its reason are
     identical to the eager-compile version.

## Handling Compile Errors (Parity)

Current behavior panics early on invalid patterns due to `Regex::new(...).expect`.

With lazy compilation, compile errors would shift to first use. To preserve
"invalid patterns are caught immediately" in dev/test without penalizing
production:

- Add a test `all_pack_patterns_compile` that explicitly compiles every
  pattern under `#[cfg(test)]`.
- Optional CLI: `dcg packs --validate` to force compile all patterns.

## Migration Plan (Phased)

1) **Introduce specs + lazy regex primitive**
   - Add `SafePatternSpec` / `DestructivePatternSpec` with `OnceLock`.
   - Reuse `CompiledRegex` (no behavior change yet).

2) **Refactor pack definitions**
   - Replace `Vec<SafePattern>` with static arrays of `SafePatternSpec`.
   - Replace `Vec<DestructivePattern>` with static arrays of `DestructivePatternSpec`.

3) **Registry metadata-only**
   - `PackRegistry::new` builds only `PackSpec` and keywords.
   - No regex compilation on init.

4) **Evaluator wiring**
   - Safe/destructive passes call `spec.is_match()` which compiles lazily.

5) **Parity guardrails**
   - Add `all_pack_patterns_compile` test.
   - Add regression corpus parity test: eager vs lazy output identical.

## Integration Points

- `src/packs/mod.rs`: Pack/Pattern type refactor and registry construction.
- `src/packs/regex_engine.rs`: Lazy compile backing type (`CompiledRegex`).
- `src/evaluator.rs`: Pattern match calls use lazy spec API.
- `src/main.rs`: Pack keyword gating remains metadata-only.

## Success Criteria

- `dcg packs --enabled` is metadata-only (no regex compile).
- Hook allow path performs no regex compilation.
- Golden/e2e parity unchanged for allow/deny outcomes and reasons.

## Profiling Workflow (gprofng fallback)

When `perf` is blocked (e.g., `perf_event_paranoid=4`), use `gprofng` to
capture repeatable CPU + heap profiles. The goal is to surface inclusive
time hotspots for pack registry initialization and regex compilation.

### CPU hotspot (startup-heavy path)

Use a short loop to stabilize measurements and keep the command focused on
registry init (`dcg packs --enabled`):

```bash
gprofng collect app -o /tmp/dcg_packs_loop_cpu.er -F '=dcg' -p on \
  sh -c 'for i in $(seq 1 20); do ./target/release/dcg packs --enabled >/dev/null; done'

gprofng display text -functions /tmp/dcg_packs_loop_cpu.er | head -n 50
```

### Heap profile

```bash
gprofng collect app -o /tmp/dcg_packs_heap.er -H on -p on \
  ./target/release/dcg packs --enabled >/dev/null
```

### I/O sanity fallback

If gprofng cannot initialize, a quick I/O profile can still validate that the
binary is running cleanly:

```bash
strace -c -f ./target/release/dcg packs --enabled >/dev/null
```

### Comparing before/after

1. Record the command, binary path, and git commit SHA.
2. Save the `.er` artifacts with a timestamp (`/tmp/dcg_packs_*_<date>.er`).
3. Compare the top 20 functions (inclusive time) to confirm hotspots moved.



================================================
FILE: docs/graduated-response.md
================================================
# Design: Graduated Response System

## Status: DRAFT
**Author:** ChartreuseStone
**Date:** 2026-01-19
**Bead:** git_safety_guard-2at5
**Epic:** E10 (git_safety_guard-yejh)
**Reviewed:** Pending

---

## 1. Executive Summary

This design specifies a graduated response system that replaces the current
binary allow/deny behavior with context-aware escalation levels. The system
tracks command occurrences within sessions and across session history, enabling
more nuanced responses based on pattern frequency and user behavior.

Key features:
- Three response levels: WARNING, SOFT_BLOCK, HARD_BLOCK
- Four graduation modes: paranoid, strict, standard, lenient
- Session-scoped occurrence tracking (resets on new shell)
- Cross-session history tracking (persisted, time-windowed)
- Severity-based overrides (critical patterns always hard block)

---

## 2. Response Levels

### 2.1 WARNING

**Behavior:**
- Command is **allowed to proceed**
- Warning message displayed to stderr
- Event logged to history
- Designed for first occurrence in a session

**Output format (stderr):**
```
âš ï¸  dcg WARNING: This command matches a destructive pattern

Pattern:  core.git:reset-hard
Severity: high
Command:  git reset --hard HEAD~1

This is occurrence 1/2 in this session. Command will proceed.
Use --quiet to suppress warnings.
```

**JSON output (stdout):**
```json
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "allow",
    "responseLevel": "warning",
    "sessionOccurrence": 1,
    "sessionThreshold": 2,
    "ruleId": "core.git:reset-hard",
    "warningMessage": "Command matches destructive pattern"
  }
}
```

### 2.2 SOFT_BLOCK

**Behavior:**
- Command is **blocked initially**
- User can confirm to proceed (interactive mode)
- Requires explicit "yes" confirmation, no auto-bypass
- Triggered after session threshold exceeded

**Output format (stderr):**
```
ðŸ›‘ dcg SOFT BLOCK: Command requires confirmation

Pattern:  core.git:reset-hard
Severity: high
Command:  git reset --hard HEAD~1

This is occurrence 3 in this session (threshold: 2).
History: 2 occurrences in last 24h (threshold: 5).

To proceed, use: dcg confirm <code>
Code: 7f3a
```

**JSON output (stdout):**
```json
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "deny",
    "responseLevel": "soft_block",
    "sessionOccurrence": 3,
    "sessionThreshold": 2,
    "historyOccurrence": 2,
    "historyThreshold": 5,
    "confirmCode": "7f3a",
    "ruleId": "core.git:reset-hard",
    "remediation": {
      "confirmCommand": "dcg confirm 7f3a",
      "safeAlternative": "git stash"
    }
  }
}
```

### 2.3 HARD_BLOCK

**Behavior:**
- Command is **blocked with no override**
- User must add pattern to allowlist or use `dcg allow-once`
- Triggered when history threshold exceeded
- Always used in "paranoid" mode
- Always used for critical severity patterns (configurable)

**Output format (stderr):**
```
ðŸš« dcg HARD BLOCK: Command blocked (threshold exceeded)

Pattern:  core.git:reset-hard
Severity: high
Command:  git reset --hard HEAD~1

This command has been blocked 6 times in the last 24h (threshold: 5).
Direct confirmation is not available for this command.

Options:
  1. Add to allowlist: dcg allowlist add core.git:reset-hard --project
  2. Allow once:       dcg allow-once <code>
  3. Review history:   dcg history core.git:reset-hard

Code: 9b2e
```

**JSON output (stdout):**
```json
{
  "hookSpecificOutput": {
    "hookEventName": "PreToolUse",
    "permissionDecision": "deny",
    "responseLevel": "hard_block",
    "sessionOccurrence": 4,
    "historyOccurrence": 6,
    "historyThreshold": 5,
    "allowOnceCode": "9b2e",
    "ruleId": "core.git:reset-hard",
    "remediation": {
      "allowOnceCommand": "dcg allow-once 9b2e",
      "allowlistCommand": "dcg allowlist add core.git:reset-hard --project"
    }
  }
}
```

---

## 3. Graduation Modes

Graduation modes define how quickly responses escalate from WARNING to HARD_BLOCK.

### 3.1 Mode Definitions

| Mode | Behavior | Use Case |
|------|----------|----------|
| `paranoid` | Always HARD_BLOCK | Current behavior, maximum safety |
| `strict` | WARNING â†’ SOFT_BLOCK â†’ HARD_BLOCK | High-security environments |
| `standard` | WARNING â†’ WARNING â†’ SOFT_BLOCK â†’ HARD_BLOCK | Balanced default |
| `lenient` | WARNING (repeating) â†’ SOFT_BLOCK (never hard) | Development/experimentation |

### 3.2 Graduation Curves

```
Occurrence:     1       2       3       4       5       6+
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
paranoid:      HARD    HARD    HARD    HARD    HARD    HARD
strict:        WARN    SOFT    HARD    HARD    HARD    HARD
standard:      WARN    WARN    SOFT    SOFT    HARD    HARD
lenient:       WARN    WARN    WARN    SOFT    WARN    WARN...
```

### 3.3 Mode Selection Logic

```rust
fn select_response_level(
    mode: GraduationMode,
    session_count: u32,
    history_count: u32,
    session_threshold: u32,
    history_threshold: u32,
    severity: Severity,
    critical_always_hard: bool,
) -> ResponseLevel {
    // Critical severity override
    if severity == Severity::Critical && critical_always_hard {
        return ResponseLevel::HardBlock;
    }

    match mode {
        GraduationMode::Paranoid => ResponseLevel::HardBlock,

        GraduationMode::Strict => {
            if history_count >= history_threshold {
                ResponseLevel::HardBlock
            } else if session_count >= session_threshold {
                ResponseLevel::SoftBlock
            } else {
                ResponseLevel::Warning
            }
        }

        GraduationMode::Standard => {
            if history_count >= history_threshold {
                ResponseLevel::HardBlock
            } else if session_count >= session_threshold {
                ResponseLevel::SoftBlock
            } else {
                ResponseLevel::Warning
            }
        }

        GraduationMode::Lenient => {
            // Lenient never hard blocks (except critical override above)
            if session_count >= session_threshold {
                ResponseLevel::SoftBlock
            } else {
                ResponseLevel::Warning
            }
        }
    }
}
```

---

## 4. Configuration Schema

### 4.1 Configuration File

Location: `~/.config/dcg/config.toml` (user) or `.dcg/config.toml` (project)

```toml
[response]
# Graduation mode: paranoid, strict, standard, lenient
mode = "standard"

# Session tracking (resets on new shell)
session_threshold = 2  # Soft block after this many in session

# History tracking (cross-session persistence)
history_threshold = 5  # Hard block after this many in history window
history_window = "24h" # Lookback period for history (e.g., "1h", "24h", "7d")

# Severity overrides
critical_always_hard = true  # Critical severity bypasses graduation
high_minimum_level = "warning"  # Minimum level for high severity

# Behavior flags
show_warnings = true           # Display warning messages
quiet_after_threshold = false  # Suppress repeated warnings
log_warnings = true            # Log warnings to history
```

### 4.2 Environment Variable Overrides

```bash
DCG_RESPONSE_MODE=strict       # Override mode
DCG_SESSION_THRESHOLD=3        # Override session threshold
DCG_HISTORY_THRESHOLD=10       # Override history threshold
DCG_CRITICAL_ALWAYS_HARD=false # Disable critical override
```

### 4.3 CLI Flags

```bash
dcg --mode=paranoid            # Temporary mode override
dcg --no-warnings              # Suppress warning output
dcg --session-threshold=1      # Override for this invocation
```

### 4.4 Configuration Merge Order

Priority (highest to lowest):
1. CLI flags
2. Environment variables
3. Project config (`.dcg/config.toml`)
4. User config (`~/.config/dcg/config.toml`)
5. System config (`/etc/dcg/config.toml`)
6. Built-in defaults

---

## 5. State Machine

### 5.1 Decision Flow

```
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Command Input     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  Pattern Matching   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚                â”‚                â”‚
                              â–¼                â–¼                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Safe    â”‚   â”‚ Unmatched â”‚   â”‚Destructiveâ”‚
                        â”‚  Pattern  â”‚   â”‚  Pattern  â”‚   â”‚  Pattern  â”‚
                        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                              â”‚               â”‚               â”‚
                              â–¼               â–¼               â–¼
                           ALLOW           ALLOW     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                     â”‚ Load Session   â”‚
                                                     â”‚ & History      â”‚
                                                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â–¼
                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                     â”‚ Check Critical â”‚
                                                     â”‚ Override       â”‚
                                                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€yesâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                              â”‚                              â”‚no
                              â–¼                              â–¼
                         HARD_BLOCK              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                 â”‚ Apply Graduation   â”‚
                                                 â”‚ Mode Logic         â”‚
                                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚              â”‚              â”‚              â”‚
                              â–¼              â–¼              â–¼              â–¼
                           WARNING      SOFT_BLOCK     HARD_BLOCK      ALLOW
                              â”‚              â”‚              â”‚        (lenient)
                              â–¼              â–¼              â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Increment â”‚  â”‚ Increment â”‚  â”‚ Increment â”‚
                        â”‚ Counters  â”‚  â”‚ Counters  â”‚  â”‚ Counters  â”‚
                        â”‚ Log Event â”‚  â”‚ Log Event â”‚  â”‚ Log Event â”‚
                        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                              â”‚              â”‚              â”‚
                              â–¼              â–¼              â–¼
                           PROCEED        PROMPT         BLOCK
                                         CONFIRM
```

### 5.2 State Transitions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      session_count < session_threshold      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NEW    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ WARNING â”‚
â”‚ COMMAND â”‚                                             â”‚  STATE  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                       â”‚
     â”‚  session_count >= session_threshold AND               â”‚ command
     â”‚  history_count < history_threshold                    â”‚ allowed
     â”‚                                                       â–¼
     â”‚                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚SOFT_BLOCKâ”‚
     â”‚                                                  â”‚  STATE  â”‚
     â”‚                                                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                                       â”‚
     â”‚  history_count >= history_threshold                   â”‚ user
     â”‚                                                       â”‚ confirms
     â”‚                                                       â–¼
     â”‚                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚HARD_BLOCKâ”‚
                                                       â”‚  STATE  â”‚
                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Session Tracking

### 6.1 Session Identification

Sessions are identified by a combination of:
- Shell process ID (PPID of dcg process)
- Terminal device (TTY)
- Session start timestamp

```rust
struct SessionId {
    ppid: u32,
    tty: Option<String>,
    start_ts: DateTime<Utc>,
}
```

### 6.2 Session Store

Location: `/tmp/dcg-sessions/<session_hash>.json`

Format:
```json
{
  "session_id": "abc123...",
  "ppid": 12345,
  "tty": "/dev/pts/1",
  "start_ts": "2026-01-19T10:00:00Z",
  "last_active": "2026-01-19T10:30:00Z",
  "occurrences": {
    "core.git:reset-hard": 2,
    "core.filesystem:rm-rf-general": 1
  }
}
```

### 6.3 Session Lifecycle

- **Creation:** First destructive command in a new shell
- **Update:** Increment pattern counters on each match
- **Expiry:** Sessions auto-expire after 24h of inactivity
- **Cleanup:** Prune expired sessions on startup

---

## 7. History Tracking

### 7.1 History Store

Location: `~/.config/dcg/history.jsonl`

Each line represents a single event:
```json
{
  "schema_version": 1,
  "timestamp": "2026-01-19T10:30:00Z",
  "rule_id": "core.git:reset-hard",
  "pack_id": "core.git",
  "severity": "high",
  "response_level": "warning",
  "session_id": "abc123...",
  "cwd": "/home/user/project",
  "command_hash": "sha256:...",
  "allowed": true
}
```

### 7.2 History Queries

```rust
fn count_history(
    rule_id: &str,
    window: Duration,
    cwd: Option<&Path>,  // Optional scope to directory
) -> u32
```

### 7.3 History Maintenance

- Auto-prune entries older than `max_history_age` (default: 30d)
- Configurable max history size (default: 10000 entries)
- Prune on startup and periodically during long sessions

---

## 8. Soft Block Confirmation Flow

### 8.1 Confirmation Code

Generated same as allow-once codes (see design-allow-once-short-code.md):
```
short_code = sha256("<timestamp> | <cwd> | <command_raw>")[-4:]
```

### 8.2 Confirmation Command

```bash
dcg confirm <code>
```

Behavior:
- Valid for 5 minutes (short-lived)
- Scope: exact command + cwd
- Single-use (consumed on use)
- Stores in pending_confirmations.jsonl

### 8.3 Confirmation Store

Location: `~/.config/dcg/pending_confirmations.jsonl`

```json
{
  "schema_version": 1,
  "short_code": "7f3a",
  "full_hash": "sha256:...",
  "created_at": "2026-01-19T10:30:00Z",
  "expires_at": "2026-01-19T10:35:00Z",
  "cwd": "/home/user/project",
  "command_hash": "sha256:...",
  "rule_id": "core.git:reset-hard",
  "consumed_at": null
}
```

---

## 9. Integration with Existing Features

### 9.1 Allow-Once Codes

Allow-once bypasses graduation entirely:
- If command has a valid allow-once exception, skip graduation checks
- Response level is implicitly ALLOW
- Still logged to history (with `allowed: true, via: "allow-once"`)

### 9.2 Allowlist

Allowlisted patterns bypass graduation entirely:
- Check allowlist before graduation
- Response level is implicitly ALLOW
- Not logged to history (no tracking needed)

### 9.3 Explain Command

`dcg explain` shows graduation status:
```
$ dcg explain "git reset --hard HEAD~1"

Pattern:    core.git:reset-hard
Pack:       core.git
Severity:   high
Status:     Would be blocked (SOFT_BLOCK)

Graduation info:
  Mode:              standard
  Session count:     3
  Session threshold: 2
  History count:     2
  History threshold: 5
  History window:    24h

Recommendation: This command has been used 3 times this session.
                Consider adding to allowlist if this is expected workflow.
```

---

## 10. CLI Commands

### 10.1 New Commands

```bash
# View response configuration
dcg config response

# View session state
dcg session [--json]

# View history for a pattern
dcg history <rule_id> [--window=24h] [--json]

# Clear session state (restart graduation)
dcg session clear

# Confirm a soft-blocked command
dcg confirm <code>
```

### 10.2 Modified Commands

```bash
# Stats includes graduation info
dcg stats [--graduation]

# Explain shows graduation state
dcg explain "<command>"
```

---

## 11. Backward Compatibility

### 11.1 Default Behavior

Default mode is `standard`, which differs from current `paranoid` behavior.
To preserve existing behavior:

```toml
[response]
mode = "paranoid"
```

### 11.2 Migration

On first run with new version:
1. Check if config exists
2. If no `[response]` section, add with `mode = "paranoid"` comment
3. Log message about new graduation feature

---

## 12. Security Considerations

### 12.1 Session Hijacking

Mitigations:
- Session ID includes TTY and PPID
- Session files have 0600 permissions
- Session directory in /tmp with restricted access

### 12.2 History Tampering

Mitigations:
- History file has 0600 permissions
- JSONL append-only for concurrent writes
- Fail-open on corruption (safety over tracking)

### 12.3 Confirmation Code Prediction

Mitigations:
- Codes include high-entropy timestamp
- 5-minute expiry limits attack window
- Single-use prevents replay

---

## 13. Testing Plan

### 13.1 Unit Tests

- Response level selection logic for all modes
- Session counter increment/decrement
- History query with time windows
- Configuration merge order
- Confirmation code generation and validation

### 13.2 Integration Tests

- Full graduation flow (WARNING â†’ SOFT_BLOCK â†’ HARD_BLOCK)
- Session persistence across dcg invocations
- History accumulation and pruning
- Allow-once/allowlist bypass
- Critical severity override

### 13.3 E2E Tests

Add to `scripts/e2e_test.sh`:
```bash
# Graduation mode tests
test_graduation_warning_first_occurrence
test_graduation_soft_block_session_threshold
test_graduation_hard_block_history_threshold
test_graduation_paranoid_always_hard
test_graduation_lenient_never_hard
test_graduation_critical_override
```

---

## 14. Implementation Tasks

See dependent beads:
- **git_safety_guard-4kcu**: [E10-T2] Implement occurrence tracking (session state)
- **git_safety_guard-8sjj**: [E10-T3] Implement cross-session tracking via history
- **git_safety_guard-tmob**: [E10-T5] Add graduation config options

---

## 15. Open Questions

1. **Session expiry behavior**: Should sessions expire after shell exit or time-based only?
2. **Project-scoped graduation**: Should graduation counters be per-project or global?
3. **Pack-level configuration**: Should modes be configurable per-pack?
4. **Confirmation TTY requirement**: Should soft block confirmation require TTY?

---

## Appendix A: Default Configuration

```toml
[response]
mode = "standard"
session_threshold = 2
history_threshold = 5
history_window = "24h"
critical_always_hard = true
high_minimum_level = "warning"
show_warnings = true
quiet_after_threshold = false
log_warnings = true

[history]
max_age = "30d"
max_entries = 10000
prune_on_startup = true
```

---

## Appendix B: Response Level Enum

```rust
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum ResponseLevel {
    /// Command allowed with warning message
    Warning,
    /// Command blocked, user can confirm to proceed
    SoftBlock,
    /// Command blocked, no direct override available
    HardBlock,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum GraduationMode {
    Paranoid,
    Strict,
    Standard,
    Lenient,
}
```

---

## Appendix C: JSON Schema

See `docs/json-schema/hook-output.json` for the complete JSON schema including
new graduation-related fields.



================================================
FILE: docs/heredoc-error-messages.md
================================================
# Heredoc Block Message Design

This document defines the human-readable and JSON error message formats for
heredoc and inline-script blocking. The goal is to be clear, actionable, and
safe-by-default (no secret leakage).

## Goals

- Explain *why* the heredoc was blocked in plain language.
- Provide stable identifiers for allowlisting.
- Show a small context window around the match.
- Avoid leaking secrets (redaction + truncation rules).
- Preserve behavior in non-TTY environments (no ANSI).

## Non-Goals

- Full source rendering or syntax highlighting.
- Perfect language detection in edge cases.

## Human-Readable Format (stderr)

### Header

```
BLOCKED: Destructive pattern in heredoc
```

### Details

```
Language:   <language>
Rule ID:    <pack_id:pattern_name>
Reason:     <short reason>
Matched:    <matched snippet>
Line:       <line number in heredoc>
Severity:   <deny|warn>
```

### Context Window

Show a small window with the offending line highlighted:

```
Context:
  1| import os
  2| path = "/tmp/data"
> 3| os.system("rm -rf /tmp/data")
  4| print("done")
```

### Suggestions

```
Suggestions:
- <safe alternative 1>
- <safe alternative 2>
- If intentional: dcg allow <rule-id> -r "reason"
```

### Example

```
BLOCKED: Destructive pattern in heredoc
Language:   python
Rule ID:    heredoc.python.os_system
Reason:     os.system() executes shell commands
Matched:    os.system("rm -rf /tmp/data")
Line:       3
Severity:   deny

Context:
  1| import os
  2| path = "/tmp/data"
> 3| os.system("rm -rf /tmp/data")
  4| print("done")

Suggestions:
- Use subprocess with explicit arguments instead
- If intentional: dcg allow heredoc.python.os_system -r "reason"
```

## JSON Format (stdout)

For the Claude Code hook protocol:

```json
{
  "hookSpecificOutput": {
    "permissionDecision": "deny",
    "reason": "Heredoc contains destructive pattern: os.system() executes shell commands",
    "details": {
      "detection_type": "heredoc",
      "language": "python",
      "rule_id": "heredoc.python.os_system",
      "matched_text": "os.system(\"rm -rf /tmp/data\")",
      "line_in_heredoc": 3,
      "severity": "deny",
      "suggestions": [
        "Use subprocess with explicit arguments instead",
        "If intentional: dcg allow heredoc.python.os_system -r \"reason\""
      ]
    }
  }
}
```

### JSON Requirements

- `permissionDecision` must be `deny` for blocks.
- `reason` should be concise and user-friendly.
- `details.rule_id` must be a stable allowlist key.
- `details.matched_text` must be redacted/truncated.
- `details.suggestions` should include at least one actionable step.

## Redaction and Truncation Rules

- Redact quoted strings by default for logs in non-TTY output.
- Truncate `matched_text` to 120 chars (configurable).
- Always preserve rule ID and reason; never redact those.
- Context lines should be truncated to 160 chars each.

## Context Extraction Rules

- Window size: 2 lines before and after the matched line.
- If at file boundaries, show only available lines.
- Use 1-based line numbers within the heredoc payload.

## Decision Mapping

- **Critical/High** -> `deny`
- **Medium** -> `warn` unless a catastrophic literal target is detected
- **Low** -> `log` (no block)

## Testing Checklist

- Valid JSON payload on deny (hook protocol compliance).
- Context extraction respects boundaries.
- Redaction/truncation applied to matched text and context.
- Non-TTY output contains no ANSI.
- Allowlist suggestion uses the correct rule ID.




================================================
FILE: docs/pack-expansion-guide.md
================================================
# Pack Expansion Guide

This guide details the process, tools, and standards for adding new packs to `destructive_command_guard`.

## Prerequisites

- Rust nightly toolchain
- `cargo-nextest` (recommended for faster tests)
- `jq` (for processing test output)

## 1. Create the Pack Module

1.  Identify the category (e.g., `containers`, `database`). If it's new, create `src/packs/<category>/mod.rs`.
2.  Create `src/packs/<category>/<tool>.rs`.
3.  Implement the `create_pack()` function returning a `Pack`.

```rust
use crate::packs::{Pack, Pattern, destructive};
use std::sync::LazyLock;
use fancy_regex::Regex;

pub fn create_pack() -> Pack {
    Pack {
        id: "category.tool".to_string(),
        name: "Tool Name".to_string(),
        description: "Blocks destructive Tool commands".to_string(),
        keywords: vec!["tool".to_string()],
        safe_patterns: vec![
            pattern!("list", r"tool\s+list"),
        ],
        destructive_patterns: vec![
            destructive!(r"tool\s+delete", "deletes resources"),
        ],
    }
}
```

## 2. Unit Testing (Required)

We use a standardized template for unit tests to ensure coverage of edge cases, severity, and performance.

1.  Open `src/packs/test_template.rs`.
2.  Copy the `mod tests { ... }` block.
3.  Paste it at the bottom of your new pack file.
4.  Adapt the tests:
    *   Change `example_pack` to `super`.
    *   Update destructive/safe test cases.
    *   Keep the edge case/performance tests (adapt inputs if needed).

```bash
# Run unit tests
cargo test packs::category::tool
```

## 3. E2E Testing (Required)

Every pack must have a dedicated shell script for verification in a real environment.

1.  Copy the template:
    ```bash
    cp scripts/templates/test_pack.sh scripts/test_pack_tool.sh
    chmod +x scripts/test_pack_tool.sh
    ```
2.  Edit `scripts/test_pack_tool.sh`:
    *   Set `PACK_NAME` (e.g., "category.tool").
    *   Add `test_cmd` calls for your destructive and safe patterns.
3.  Run it:
    ```bash
    ./scripts/test_pack_tool.sh --verbose
    ```

## 4. Test Fixtures

Add your destructive commands to the central database. This allows global regression testing.

1.  Open `tests/fixtures/destructive_commands.yaml`.
2.  Add a new section for your pack:

```yaml
category.tool:
  - command: "tool delete prod"
    reason: "deletes production resources"
  - command: "tool nuke --force"
    reason: "wipes everything"
```

## 5. Registration

1.  Add `pub mod tool;` to `src/packs/<category>/mod.rs`.
2.  Add `category::tool::create_pack` to `PACK_ENTRIES` in `src/packs/mod.rs`.

## 6. Validation

Run the full suite to ensure no regressions:

```bash
# Unit tests
cargo test

# Global E2E
./scripts/e2e_test.sh

# Your pack E2E
./scripts/test_pack_tool.sh
```



================================================
FILE: docs/pack-expansion-index.md
================================================
# Pack Expansion Index

Last updated: 2026-01-10

This is the master index for the pack expansion initiative. It consolidates
the hierarchy, dependency order, and resolved decisions so contributors can
quickly navigate the work.

## Complete Hierarchy

```
Master Epic (pcq)
â”‚
â”œâ”€â”€ FOUNDATION (Must complete first)
â”‚   â”‚
â”‚   â”œâ”€â”€ Testing Infrastructure (e7j) [P0]
â”‚   â”‚   â”œâ”€â”€ Unit test template (i79) [CLOSED]
â”‚   â”‚   â”œâ”€â”€ E2E test framework (ly4)
â”‚   â”‚   â”œâ”€â”€ Logging infrastructure (jdb)
â”‚   â”‚   â”œâ”€â”€ Test fixtures database (l968) [CLOSED]
â”‚   â”‚   â”œâ”€â”€ CI/CD integration (6ozg)
â”‚   â”‚   â”œâ”€â”€ Performance regression testing (qxc7)
â”‚   â”‚   â”œâ”€â”€ Pack dev/validation tooling (hxgx)
â”‚   â”‚   â””â”€â”€ E2E scenario definitions (ct5s) [CLOSED]
â”‚   â”‚
â”‚   â”œâ”€â”€ Design Decisions (8u1) [P0] [CLOSED]
â”‚   â”‚   â”œâ”€â”€ Completion validation checklist (ltou) [CLOSED]
â”‚   â”‚   â””â”€â”€ Pack task template (ikf2) [CLOSED]
â”‚   â”‚
â”‚   â”œâ”€â”€ Operational Infrastructure [P1]
â”‚   â”‚   â”œâ”€â”€ Pack maintenance/versioning (ewbq)
â”‚   â”‚   â”œâ”€â”€ Production monitoring (hi1t)
â”‚   â”‚   â”œâ”€â”€ Coverage gap audit (me0s)
â”‚   â”‚   â””â”€â”€ User experience (rm2n)
â”‚   â”‚
â”‚   â””â”€â”€ Documentation (mbq7) [P1]
â”‚
â”œâ”€â”€ Tier 1: Critical Security Gaps (6ae) [P0] - 22 pack tasks
â”‚   â”œâ”€â”€ secrets.*: vault, aws_secrets, onepassword, doppler (4)
â”‚   â”œâ”€â”€ cicd.*: github_actions DONE, gitlab_ci, jenkins, circleci (4)
â”‚   â”œâ”€â”€ messaging.*: kafka, rabbitmq, nats, sqs_sns (4)
â”‚   â”œâ”€â”€ search.*: elasticsearch, opensearch, algolia, meilisearch (4)
â”‚   â”œâ”€â”€ backup.*: restic, borg, rclone, velero (4)
â”‚   â”œâ”€â”€ rsync (78a) - PROMOTED from remote.*
â”‚   â””â”€â”€ s3 (3a1) - PROMOTED from storage.*
â”‚
â”œâ”€â”€ Tier 2: High Value (hhh) [P1] - 18 pack tasks
â”‚   â”œâ”€â”€ platform.github (3w5) - repos, releases, deploy keys, webhooks
â”‚   â”œâ”€â”€ platform.gitlab (z2q) - projects, releases, runners
â”‚   â”œâ”€â”€ dns.*: cloudflare, route53, generic (3)
â”‚   â”œâ”€â”€ loadbalancer.*: nginx, elb, haproxy, traefik (4)
â”‚   â”œâ”€â”€ monitoring.*: datadog, pagerduty, prometheus, newrelic (4)
â”‚   â””â”€â”€ payment.*: stripe, braintree, square (3)
â”‚
â””â”€â”€ Tier 3: Valuable (9ic) [P2] - 17 pack tasks
    â”œâ”€â”€ remote.*: ssh, scp (2) - rsync promoted out
    â”œâ”€â”€ cdn.*: cloudflare_workers, fastly, cloudfront (3)
    â”œâ”€â”€ apigateway.*: aws, kong, apigee (3)
    â”œâ”€â”€ featureflags.*: launchdarkly, split, flipt, unleash (4)
    â”œâ”€â”€ email.*: sendgrid, ses, mailgun, postmark (4)
    â””â”€â”€ storage.*: gcs, azure_blob, minio (3) - s3 promoted out
```

## Resolved Decisions

### rsync and S3 Promotion (DECIDED in bnyn)
**Decision**: Promote both to Tier 1.
- rsync (78a): now P0, blocks Tier 1 epic directly.
- S3 (3a1): now P0, blocks Tier 1 epic directly.
- Rationale: both are top-5 developer footguns based on incident data.

### GitHub/GitLab Pack Boundaries (DECIDED in qdhh)
**Decision**: Keep packs separate but clarify boundaries.
- cicd.github_actions: secrets, variables, workflows, runs, API actions.
- platform.github: repos, releases, deploy keys, webhooks, collaborators.
- Same pattern for GitLab (cicd.gitlab_ci vs platform.gitlab).

## Work Order

1. **Foundation First** - testing infra, design decisions, dev tooling.
2. **Tier 1** - critical packs (secrets, cicd, messaging, search, backup + rsync, s3).
3. **Tier 2** - high-value packs (platform, dns, loadbalancer, monitoring, payment).
4. **Tier 3** - valuable packs (remote, cdn, apigateway, featureflags, email, storage).

## Key Reference Beads

| ID | Purpose | Status |
|----|---------|--------|
| ikf2 | Pack task template - required sections | CLOSED |
| ltou | Completion checklist - validation before merge | CLOSED |
| ct5s | E2E scenario definitions - test case examples | CLOSED |
| hxgx | Dev tooling - pattern tester, validator, debugger | OPEN |
| ewbq | Maintenance strategy - CLI version tracking | OPEN |
| bnyn | Priority decision - rsync/S3 promotion | CLOSED |
| qdhh | Scope decision - GitHub/GitLab boundaries | CLOSED |
| hcyz | Tier rationale - why strict ordering | OPEN |

## Testing Requirements Summary

Every pack MUST have:
- Unit tests (>= 90% coverage)
- E2E test file with scenarios
- Performance < 500 microseconds
- Completion checklist passed
- Documentation updated

## Commands

```bash
bd ready                              # Packs ready to implement
bd list --status=open | rg PACK       # All pack tasks
bd show <id>                          # Pack details
bd blocked                            # Blocked items
```



================================================
FILE: docs/pack-implementation-checklist.md
================================================
# Pack Implementation Checklist

Use this checklist when adding a new pack to `destructive_command_guard`.

## 1. Analysis
- [ ] Identify the tool (e.g., `kubectl`, `aws`).
- [ ] List destructive commands (e.g., `delete`, `terminate`).
- [ ] List safe commands that might look similar.
- [ ] Identify the "quick reject" keywords (e.g., `kubectl`).

## 2. Implementation
- [ ] Create `src/packs/<category>/<tool>.rs`.
- [ ] Define the `Pack` struct with ID, name, description.
- [ ] Add keywords.
- [ ] Implement `destructive_patterns` (regex + reason).
- [ ] Implement `safe_patterns` (if needed for whitelist).

## 2a. Explanation Style Guide (for destructive patterns)

Explanations are optional but recommended for user-facing clarity. When present:

- Keep it short: 2-4 sentences, ~400 chars or less.
- Stay neutral and factual; avoid scaremongering or moralizing.
- Structure:
  1) What the command does.
  2) Why that is risky (data loss, downtime, security blast radius).
  3) Safer alternative and/or preview command.
- Use concrete nouns and commands (e.g., `git reset --soft`, `--dry-run`).
- Avoid absolutes unless accurate (prefer "often" or "can").
- Match the existing `reason` but add real detail (not repetition).

## 3. Unit Testing
- [ ] Copy `src/packs/test_template.rs` content to `src/packs/<category>/<tool>.rs` (mod tests).
- [ ] Update `test_pack_creation` to use `validate_pack`.
- [ ] Implement tests for all destructive patterns.
- [ ] Implement tests for safe patterns.
- [ ] Verify `cargo test packs::<category>::<tool>` passes.

## 4. E2E & Integration Testing
- [ ] Add known destructive commands to `tests/fixtures/destructive_commands.yaml`.
- [ ] Create `scripts/test_pack_<tool>.sh` using `scripts/templates/test_pack.sh`.
- [ ] Run the E2E script: `./scripts/test_pack_<tool>.sh --verbose`.
- [ ] Verify no regressions: `./scripts/e2e_test.sh`.

## 5. Registration
- [ ] Add module to `src/packs/<category>/mod.rs`.
- [ ] Register pack in `src/packs/mod.rs` (PACK_ENTRIES).

## 6. Documentation
- [ ] Add to `docs/packs/README.md` (or index).
- [ ] Verify `cargo run -- pack list` shows the new pack.
- [ ] (Optional) Add specific usage examples to docs.



================================================
FILE: docs/pack-maintenance.md
================================================
# Pack Maintenance and CLI Evolution Strategy

CLI tools evolve: new commands appear, flags change, and destructive operations
shift over time. This document defines how packs stay current.

## 1) CLI Version Tracking

Maintain `docs/cli-versions.yaml` with:
- tool name
- tested versions
- last verified date
- changelog URL

Update the file as part of each quarterly audit.

## 2) Quarterly Version Audit

Every quarter:
1. Check new releases for each tracked CLI.
2. Review changelogs for destructive operations or syntax changes.
3. Update pack patterns as needed.
4. Update `tested_versions` and `last_verified`.
5. Run the full test suite.

## 3) Breaking Change Protocol

When a CLI introduces breaking changes:
1. Open an urgent patch bead.
2. Update patterns for new syntax.
3. Keep backward compatibility for N-1 version when feasible.
4. Document the change in release notes.

## 4) Deprecation Strategy

When removing patterns:
1. Mark deprecated in code comments.
2. Log a warning when deprecated patterns match.
3. Keep for two releases.
4. Remove and document in changelog.

## 5) User-Reported Updates

Handle reports as follows:
- **False negatives**: add patterns + tests.
- **False positives**: add safe patterns + edge cases.
- **New pack requests**: create new pack tasks with the standard template.

## 6) Automation

### CLI Version Checker

`scripts/check_cli_versions.sh` scans changelogs and flags new releases.
It is intended for scheduled CI usage and should open an issue when a new
version is detected (implementation TODO).

The weekly CI runner is defined in `.github/workflows/cli-version-audit.yml`.

### Multi-Version CI Testing

Add CI matrices for high-risk tools (Vault, rclone, gh) to verify patterns
against multiple versions. Initial plan (example):

```yaml
matrix:
  vault_version: ["1.15.0", "1.16.0", "latest"]
  rclone_version: ["1.65.0", "1.66.0", "latest"]
```

## 7) Privacy and Safety

History and version checking must never log command contents. Use hashes
and metadata only.



================================================
FILE: docs/pack-task-template.md
================================================
# Standard Pack Task Requirements Template

Purpose: define the required sections for every pack task. Use this when
creating or validating pack work items.

## Required Sections

### 1. Scope (Required)
Brief description of what tool/CLI/API this pack protects.

### 2. Destructive Patterns (Required)
List ALL destructive patterns with:
- Exact command or pattern
- Clear explanation of why it is dangerous
- Example of data loss or damage it could cause

### 3. Safe Patterns (Required)
List safe patterns that should NOT be blocked:
- Read-only operations
- Status/info commands
- Dry-run/preview modes

### 4. Implementation Notes (Required)
- Parent category bead ID
- Keywords to trigger pack evaluation
- Special considerations (aliases, API endpoints, etc.)
- Known overlaps with other packs

### 5. Testing Requirements (Required)
Standard checklist for ALL packs:
- [ ] Unit tests in `src/packs/<category>/<pack>.rs` using `test_template.rs` patterns
- [ ] E2E test script created at `scripts/test_pack_<pack_name>.sh` (use `scripts/templates/test_pack.sh`)
- [ ] Fixtures added to `tests/fixtures/destructive_commands.yaml`
- [ ] Test coverage >= 90%
- [ ] All destructive patterns have test cases
- [ ] All safe patterns have test cases
- [ ] Edge cases tested (quotes, special chars)
- [ ] Performance benchmark < 500us (verify with `cargo bench`)

### 6. Acceptance Criteria (Required)
Specific, measurable criteria:
- [ ] Pattern X blocked
- [ ] Pattern Y allowed
- [ ] E2E script passes
- [ ] Documentation updated (`docs/packs/README.md`)
- [ ] Completion checklist passed

## Example Structure

```markdown
# [PACK] category.name - Tool Name Pack

## Scope
Implement pattern matching for ToolName CLI operations.

## Destructive Patterns
- `tool delete X` - Permanently deletes X
- `tool remove --force` - Force removes without confirmation

## Safe Patterns
- `tool list`, `tool show`
- `tool status`

## Implementation Notes
- Parent category: category.* (git_safety_guard-XXX)
- Keywords: tool
- Note: Consider --dry-run flag

## Testing Requirements
[Standard checklist as above]

## Acceptance Criteria
- [ ] Delete operations blocked
- [ ] List/show operations allowed
- [ ] Completion checklist passed
```

## Validation
Use [CHECKLIST] Pack Implementation Completion Validation (git_safety_guard-ltou)
when signing off pack work. The canonical checklist lives in
`docs/pack-implementation-checklist.md`.


================================================
FILE: docs/pack-testing-guide.md
================================================
# Pack Testing Guide

This guide outlines the testing framework and best practices for creating and maintaining packs in `destructive_command_guard`.

## Philosophy

- **Safety First**: We prefer blocking a safe command (false positive) over allowing a destructive one (false negative).
- **Specificity**: Patterns should match specific dangerous flags/subcommands, not just the tool name.
- **Coverage**: Every pattern must be tested.
- **Performance**: Regexes must be efficient (avoid catastrophic backtracking).

## The Test Framework

We provide a `validate_pack` helper that automates structural checks.

```rust
use crate::packs::test_helpers::*;

#[test]
fn test_pack_creation() {
    let pack = my_pack::create_pack();
    validate_pack(&pack); // Checks ID, patterns, keywords, etc.
}
```

### Validation Checks

`validate_pack` enforces:
1.  **ID Format**: Lowercase, dots, underscores, digits.
2.  **Required Fields**: Name, description, keywords (at least one).
3.  **Pattern Compilation**: All regexes must compile.
4.  **Reasons**: All destructive patterns must have a reason.
5.  **Uniqueness**: All pattern names must be unique within the pack.

## Writing Tests

Use `assert_blocks` and `assert_allows` for clear, readable tests.

### Destructive Patterns

```rust
#[test]
fn test_destructive_prune() {
    let pack = my_pack::create_pack();
    assert_blocks(&pack, "docker system prune", "removes all unused");
}
```

### Safe Patterns

```rust
#[test]
fn test_safe_ps() {
    let pack = my_pack::create_pack();
    assert_allows(&pack, "docker ps");
}
```

### Specificity (False Positives)

Verify that unrelated commands are not blocked.

```rust
#[test]
fn test_specificity() {
    let pack = my_pack::create_pack();
    assert_no_match(&pack, "echo docker"); // Keyword in argument shouldn't match
}
```

## Performance Testing

Ensure your patterns don't hang on large inputs.

```rust
#[test]
fn test_performance() {
    let pack = my_pack::create_pack();
    assert_matches_within_budget(&pack, "docker run ...");
}
```

## Checklist

- [ ] `validate_pack` passes.
- [ ] Every destructive pattern has a `test_blocks` case.
- [ ] Every safe pattern has a `test_allows` case.
- [ ] "Edge case" inputs (quotes, whitespace) are tested.
- [ ] Performance test included.


================================================
FILE: docs/pack.schema.yaml
================================================
$schema: "https://json-schema.org/draft/2020-12/schema"
title: "dcg external pack schema"
type: object
additionalProperties: false
required:
  - schema_version
  - id
  - name
  - version
properties:
  schema_version:
    type: integer
    minimum: 1
    description: Schema version for forward compatibility.
    default: 1
  id:
    type: string
    pattern: "^[a-z][a-z0-9_]*\\.[a-z][a-z0-9_]*$"
    description: Unique pack identifier (e.g., mycompany.policies).
  name:
    type: string
    description: Human-readable pack name.
  version:
    type: string
    pattern: "^\\d+\\.\\d+\\.\\d+$"
    description: Semantic version of the pack definition.
  description:
    type: string
    description: What this pack protects against.
  keywords:
    type: array
    description: Keywords that trigger evaluation for this pack.
    items:
      type: string
    default: []
  destructive_patterns:
    type: array
    description: Patterns that block or warn based on severity.
    items:
      type: object
      additionalProperties: false
      required:
        - name
        - pattern
      properties:
        name:
          type: string
          description: Stable pattern identifier within the pack.
        pattern:
          type: string
          description: fancy-regex pattern to match.
        severity:
          type: string
          enum: [low, medium, high, critical]
          default: high
          description: Default decision mode based on severity.
        description:
          type: string
          description: Short human-readable reason shown on denial.
        explanation:
          type: string
          description: Longer explanation shown in verbose output.
    default: []
  safe_patterns:
    type: array
    description: Patterns that explicitly allow commands.
    items:
      type: object
      additionalProperties: false
      required:
        - name
        - pattern
      properties:
        name:
          type: string
          description: Stable pattern identifier within the pack.
        pattern:
          type: string
          description: fancy-regex pattern to match.
        description:
          type: string
          description: Short reason for allowlisting.
    default: []



================================================
FILE: docs/pattern-library-design.md
================================================
# Pattern Library Design Specification

## Decision: Hybrid Approach (Rust + TOML extensions)

**Rationale:** Core patterns hardcoded in Rust for performance and type safety. Optional user extensions via TOML for flexibility.

---

## 1. Pattern Metadata Schema

### HeredocPattern struct (Rust)

```rust
/// A destructive pattern for heredoc/inline script scanning.
pub struct HeredocPattern {
    /// Stable rule ID: "{pack_id}.{pattern_name}"
    /// Example: "heredoc.python.shutil_rmtree"
    pub id: &'static str,

    /// Target language for this pattern.
    pub language: Language,

    /// Pattern matcher (regex or AST).
    pub matcher: PatternMatcher,

    /// Human-readable explanation.
    pub reason: &'static str,

    /// Suggestion for safe alternative.
    pub suggestion: Option<&'static str>,

    /// Severity level (affects default mode).
    pub severity: Severity,

    /// False positive risk notes (for maintainers).
    pub fp_notes: Option<&'static str>,
}

pub enum Language {
    Python,
    Bash,
    JavaScript,
    TypeScript,
    Ruby,
    Perl,
    Go,
    Php,
    Unknown,
}

pub enum PatternMatcher {
    /// Simple regex (Tier 1 compatible).
    Regex(Regex),

    /// AST pattern for ast-grep-core.
    Ast(String),

    /// Composite: regex trigger + AST validation.
    Composite {
        trigger: Regex,
        validator: String,
    },
}

pub enum Severity {
    /// Always block (irreversible + high confidence).
    Critical,

    /// Block by default, allowlistable.
    High,

    /// Warn by default, blockable via config.
    Medium,

    /// Log only (for history/learning).
    Low,
}
```

---

## 2. Stable Rule ID Format

Pattern: `{category}.{language}.{operation}[.{variant}]`

Examples:
- `heredoc.python.shutil_rmtree`
- `heredoc.python.subprocess_rm_rf`
- `heredoc.bash.rm_rf.recursive` (variant uses dot separator)
- `heredoc.javascript.fs_rmsync_recursive`
- `heredoc.ruby.fileutils_rm_rf`

### ID Stability Rules

1. **Never rename** an existing pattern ID
2. **Deprecate** instead of remove (add `.deprecated` suffix)
3. **New variants** get new ID (don't modify existing)
4. **ID = allowlist key** (users reference by ID)

---

## 3. Pack Integration

### New pack category: `heredoc`

```
heredoc.python    - Python heredoc patterns
heredoc.bash      - Bash heredoc patterns
heredoc.javascript - JavaScript heredoc patterns
heredoc.ruby      - Ruby heredoc patterns
heredoc.perl      - Perl heredoc patterns
heredoc.go        - Go heredoc patterns
heredoc.php       - PHP heredoc patterns
```

### Integration with existing packs

Heredoc patterns are a NEW category alongside existing packs.
They're only evaluated when:
1. Tier 1 regex triggers heredoc detection
2. Tier 2 extracts content + detects language
3. Tier 3 runs language-specific patterns

---

## 4. Initial Pattern Inventory

### Python (heredoc.python)

| ID | Pattern | Severity | FP Risk |
|----|---------|----------|---------|
| shutil_rmtree | `shutil.rmtree($PATH)` | Critical | Low |
| os_removedirs | `os.removedirs($PATH)` (removes empty dirs up path) | Critical | Low |
| subprocess_rm_rf | `subprocess.*(["rm", "-rf", ...])` | Critical | Medium |
| os_system_rm | `os.system("rm ...")` | Critical | Medium |

### Bash (heredoc.bash)

| ID | Pattern | Severity | FP Risk |
|----|---------|----------|---------|
| rm_rf | `rm -rf $PATH` (non-temp) | Critical | Medium |
| git_destructive | destructive git commands | Critical | Low |
| destructive_pipe | `| sh`, `| bash`, `| zsh` | High | Medium |

### JavaScript (heredoc.javascript)

| ID | Pattern | Severity | FP Risk |
|----|---------|----------|---------|
| fs_rmsync_recursive | `fs.rmSync($, {recursive: true})` | Critical | Low |
| execsync_rm | `execSync("rm ...")` | Critical | Medium |
| spawn_rm | `spawn("rm", [...])` | Critical | Medium |

### Ruby (heredoc.ruby)

| ID | Pattern | Severity | FP Risk |
|----|---------|----------|---------|
| fileutils_rm_rf | `FileUtils.rm_rf($PATH)` | Critical | Low |
| system_rm | `system("rm ...")` | Critical | Medium |
| backtick_rm | backtick with rm | Critical | Medium |

---

## 5. Contextual Pattern Strategy

### Problem: Low-signal patterns

`subprocess.run(cmd)` - too broad (cmd could be anything)

### Solution: Composite matchers

1. Regex trigger: detects subprocess/exec call
2. AST extraction: gets the command argument
3. Secondary check: validates command is destructive

```rust
PatternMatcher::Composite {
    trigger: regex!(r"subprocess\.\w+\("),
    validator: "$EXPR.run($CMD)".to_string(),
}
// The matcher first runs `trigger` regex. If it matches,
// it extracts via the `validator` AST pattern, then checks
// if $CMD contains destructive content.
```

---

## 6. Pattern Authoring Checklist

Every new pattern MUST have:

- [ ] Unique stable ID following naming convention
- [ ] Severity level with justification
- [ ] Human-readable reason (<100 chars)
- [ ] At least 1 positive fixture (should match)
- [ ] At least 1 negative fixture (should NOT match)
- [ ] FP notes documenting known false positive scenarios
- [ ] Optional suggestion for safe alternative

### Test Fixture Format

```rust
#[test]
fn test_heredoc_python_shutil_rmtree() {
    let pattern = patterns::get("heredoc.python.shutil_rmtree");

    // Positive fixtures (should match)
    assert!(pattern.matches("shutil.rmtree('/home/user')"));
    assert!(pattern.matches("shutil.rmtree(path)"));

    // Negative fixtures (should NOT match)
    assert!(!pattern.matches("# shutil.rmtree('/tmp')"));  // Comment
    assert!(!pattern.matches("'shutil.rmtree(x)'"));       // String literal
    assert!(!pattern.matches("shutil.copy(path)"));        // Different function
}
```

---

## 7. Default Mode by Severity

---

## 8. rm Parser Parity Spec (core.filesystem)

This section defines the intended parser semantics that must be **isomorphic**
to current regex behavior in `src/packs/core/filesystem.rs`. The goal is for a
future rm parser to match the same allow/deny outcomes and severity as today.

### 8.1 Command Identification

- Match only `rm` as the command word (after wrapper stripping).
- Ignore non-`rm` commands; defer to other packs.

### 8.2 Flag Semantics (Must Match Current Regex)

Treat the command as **destructive** if any of the following are present:
- **Combined flags** containing both `r`/`R` and `f` in a single token:
  - Example: `-rf`, `-fr`, `-rfx`, `-xfr` (order-insensitive).
- **Separate flags** containing `-r`/`-R` and `-f` in any order:
  - Example: `-r -f`, `-f -r`, with optional extra short-flag tokens in between.
- **Long flags**: both `--recursive` and `--force` (any order).

Extra flags are allowed and must **not** change the match decision if the
above conditions are met (e.g., `--no-preserve-root` should still match).

### 8.3 Option Terminator (`--`)

- If `--` appears, treat all subsequent tokens as paths.
- Presence of `--` does not weaken destructive detection; it only stops
  option parsing.

### 8.4 Path Classification Rules

**Safe allowlist (temp-only):**
- `/tmp/...`
- `/var/tmp/...`
- `$TMPDIR/...`
- `${TMPDIR}...` (including `${TMPDIR}/...`)
- Quoted forms of `$TMPDIR/...` or `${TMPDIR}...` (double-quoted)

**Traversal guard (must remain blocked even in temp dirs):**
- Any path containing `..` as a segment:
  - Examples: `/tmp/../etc`, `/var/tmp/foo/../bar`

**Critical block (Severity: Critical):**
- Root or home paths:
  - `/`, `/etc`, `/home`, `~/`, or any `~`-prefixed path

**General destructive (Severity: High):**
- Any `rm` with recursive + force flags that is **not** in the safe allowlist
  and does **not** match the critical root/home rule.

### 8.5 Multiple Paths

- If multiple path arguments are present, **all** paths must satisfy the safe
  allowlist + traversal guard to be safe.
- If any path is unsafe or critical, the overall command must be blocked.

### 8.6 Quoted Paths

- Double-quoted paths are allowed in temp allowlist matching.
- Quoted paths containing `..` must still be blocked (traversal guard).

### 8.7 Mapping to Existing Tests

Parser rules MUST map to the existing test cases in
`src/packs/core/filesystem.rs`:

- **Critical root/home:**
  - `test_rm_rf_root_critical`
- **General destructive:**
  - `test_rm_rf_general_high`
- **Flag ordering (combined, separate, long):**
  - `test_rm_flags_ordering`
- **Temp allowlist (unquoted + quoted):**
  - `test_safe_rm_tmp`, `test_safe_rm_variants`
- **Traversal guard:**
  - `test_safe_rm_variants` (cases with `..`)

Any new parser implementation must be validated against these tests and
augmented with parser-specific tests that keep **exact decision parity**.

| Severity | Default Mode | User Override |
|----------|--------------|---------------|
| Critical | Block | Allowlist only |
| High | Block | Allowlist by ID |
| Medium | Warn | Block via config |
| Low | Log | Warn/Block via config |

---

## 8. Allowlisting Integration

Users allowlist by stable rule ID:

```toml
# dcg.toml
[allow]
rules = [
    "heredoc.python.subprocess_rm_rf",  # We review these manually
    "heredoc.bash.rm_rf",               # Our CI needs this
]
```

Allowlists are scoped by:
- Rule ID (required)
- Optional: file pattern, expiration, reason

---

## Acceptance Criteria Met

- Clear pattern metadata schema
- Stable rule IDs for hook output / allowlisting
- Severity taxonomy tied to default modes
- FP controls via test fixtures requirement
- Integration plan with pack system
- Contextual patterns via composite matchers



================================================
FILE: docs/pattern_audit.md
================================================
# Pattern Audit Report
Generated: 2026-01-10T17:39:52.939979

## `src/packs/cicd/github_actions.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `gh-actions-secret-list` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-variable-list` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-workflow-list` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-workflow-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-run-list` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-run-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| safe | `gh-actions-api-explicit-get` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-secret-remove` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-variable-remove` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-workflow-disable` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-run-cancel` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-api-delete-secrets` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |
| destructive | `gh-actions-api-delete-variables` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|var...` |

## `src/packs/containers/compose.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `compose-down-no-volumes` | Found '!' | `(?:docker-compose\|docker\s+compose)\s+down(?!\s+.*(?:-v\...` |

## `src/packs/core/filesystem.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `rm-rf-tmp` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:/tmp/(?!\.\....` |
| safe | `rm-fr-tmp` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:/tmp/(?!\.\....` |
| safe | `rm-rf-var-tmp` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:/var/tmp/(?!...` |
| safe | `rm-fr-var-tmp` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:/var/tmp/(?!...` |
| safe | `rm-rf-tmpdir` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:\$TMPDIR/(?!...` |
| safe | `rm-fr-tmpdir` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:\$TMPDIR/(?!...` |
| safe | `rm-rf-tmpdir-brace` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:\$\{TMPDIR(?...` |
| safe | `rm-fr-tmpdir-brace` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:\$\{TMPDIR(?...` |
| safe | `rm-rf-tmpdir-quoted` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:"\$TMPDIR/(?...` |
| safe | `rm-fr-tmpdir-quoted` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:"\$TMPDIR/(?...` |
| safe | `rm-rf-tmpdir-brace-quoted` | Found '!' | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:"\$\{TMPDIR(...` |
| safe | `rm-fr-tmpdir-brace-quoted` | Found '!' | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:"\$\{TMPDIR(...` |
| safe | `rm-r-f-tmp` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:/tm...` |
| safe | `rm-f-r-tmp` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:/tm...` |
| safe | `rm-r-f-var-tmp` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:/va...` |
| safe | `rm-f-r-var-tmp` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:/va...` |
| safe | `rm-r-f-tmpdir` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:\$T...` |
| safe | `rm-f-r-tmpdir` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:\$T...` |
| safe | `rm-r-f-tmpdir-brace` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:\$\...` |
| safe | `rm-f-r-tmpdir-brace` | Found '!' | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:\$\...` |
| safe | `rm-recursive-force-tmp` | Found '!' | `^rm\s+.*--recursive.*--force\s+(?:/tmp/(?!\.\.(?:/\|\s\|$...` |
| safe | `rm-force-recursive-tmp` | Found '!' | `^rm\s+.*--force.*--recursive\s+(?:/tmp/(?!\.\.(?:/\|\s\|$...` |
| safe | `rm-recursive-force-var-tmp` | Found '!' | `^rm\s+.*--recursive.*--force\s+(?:/var/tmp/(?!\.\.(?:/\|\...` |
| safe | `rm-force-recursive-var-tmp` | Found '!' | `^rm\s+.*--force.*--recursive\s+(?:/var/tmp/(?!\.\.(?:/\|\...` |
| safe | `rm-recursive-force-tmpdir` | Found '!' | `^rm\s+.*--recursive.*--force\s+(?:\$TMPDIR/(?!\.\.(?:/\|\...` |
| safe | `rm-force-recursive-tmpdir` | Found '!' | `^rm\s+.*--force.*--recursive\s+(?:\$TMPDIR/(?!\.\.(?:/\|\...` |
| safe | `rm-recursive-force-tmpdir-brace` | Found '!' | `^rm\s+.*--recursive.*--force\s+(?:\$\{TMPDIR(?!\.\.(?:/\|...` |
| safe | `rm-force-recursive-tmpdir-brace` | Found '!' | `^rm\s+.*--force.*--recursive\s+(?:\$\{TMPDIR(?!\.\.(?:/\|...` |

## `src/packs/core/git.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `restore-staged-long` | Found '!' | `git\s+(?:\S+\s+)*restore\s+--staged\s+(?!.*--worktree)(?!...` |
| safe | `restore-staged-short` | Found '!' | `git\s+(?:\S+\s+)*restore\s+-S\s+(?!.*--worktree)(?!.*-W\b)` |
| destructive | `checkout-ref-discard` | Found '!' | `git\s+(?:\S+\s+)*checkout\s+(?!-b\b)(?!--orphan\b)[^\s]+\...` |
| destructive | `restore-worktree` | Found '!' | `git\s+(?:\S+\s+)*restore\s+(?!--staged\b)(?!-S\b)` |
| destructive | `push-force-long` | Found '!' | `git\s+(?:\S+\s+)*push\s+.*--force(?![-a-z])` |

## `src/packs/database/mongodb.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `mongodump-no-drop` | Found '!' | `mongodump\s+(?!.*--drop)` |

## `src/packs/database/postgresql.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `pg-dump-no-clean` | Found '!' | `pg_dump\s+(?!.*--clean)(?!.*-c\b)` |

## `src/packs/database/redis.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| destructive | `shutdown` | Found '!' | `(?i)\bSHUTDOWN\b(?!\s+NOSAVE)` |

## `src/packs/infrastructure/ansible.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| destructive | `playbook-all-hosts` | Found '!' | `ansible-playbook\s+(?!.*(?:--check\|--limit\|--diff)).*-i...` |

## `src/packs/infrastructure/terraform.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `terraform-plan` | Found '!' | `terraform\s+plan(?!\s+.*-destroy)` |

## `src/packs/kubernetes/helm.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| destructive | `uninstall` | Found '!' | `helm\s+(?:uninstall\|delete)\b(?!.*--dry-run)` |
| destructive | `rollback` | Found '!' | `helm\s+rollback\b(?!.*--dry-run)` |

## `src/packs/kubernetes/kubectl.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| destructive | `delete-workload` | Found '!' | `kubectl\s+delete\s+(?:deployment\|statefulset\|daemonset\...` |
| destructive | `delete-pvc` | Found '!' | `kubectl\s+delete\s+(?:pvc\|persistentvolumeclaim)\b(?!.*-...` |
| destructive | `delete-pv` | Found '!' | `kubectl\s+delete\s+(?:pv\|persistentvolume)\b(?!.*--dry-run)` |

## `src/packs/kubernetes/kustomize.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `kustomize-build` | Found '!' | `kustomize\s+build(?!\s*\\|)` |
| safe | `kubectl-kustomize` | Found '!' | `kubectl\s+kustomize(?!\s*\\|)` |
| destructive | `kubectl-delete-k` | Found '!' | `kubectl\s+delete\s+-k\b(?!.*--dry-run)` |

## `src/packs/package_managers/mod.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `apt-get-list` | Found '!' | `apt-get\s+(?:update\|upgrade)(?!\s+.*-y)` |
| destructive | `npm-publish` | Found '!' | `npm\s+publish\b(?!.*--dry-run)` |
| destructive | `yarn-publish` | Found '!' | `yarn\s+publish\b(?!.*--dry-run)` |
| destructive | `pnpm-publish` | Found '!' | `pnpm\s+publish\b(?!.*--dry-run)` |
| destructive | `cargo-publish` | Found '!' | `cargo\s+publish\b(?!.*--dry-run)` |
| destructive | `poetry-publish` | Found '!' | `poetry\s+publish\b(?!.*--dry-run)` |

## `src/packs/platform/github.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `gh-repo-list-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| safe | `gh-gist-list-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| safe | `gh-release-list-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| safe | `gh-issue-list-view` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| safe | `gh-ssh-key-list` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| safe | `gh-api-explicit-get` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-repo-delete` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-repo-archive` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-gist-delete` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-release-delete` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-issue-delete` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-ssh-key-delete` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |
| destructive | `gh-api-delete-repo` | Found '!' | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\...` |

## `src/packs/system/disk.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| destructive | `fdisk-edit` | Found '!' | `fdisk\s+/dev/(?!.*-l)` |
| destructive | `parted-modify` | Found '!' | `parted\s+/dev/\S+\s+(?!print)` |

## `src/packs/system/permissions.rs`

| Kind | Name | Reason | Regex Preview |
|------|------|--------|---------------|
| safe | `chmod-non-recursive` | Found '!' | `chmod\s+(?!-[rR])(?:\d{3,4}\|[ugoa][+-][rwxXst]+)\s+[^/]` |




================================================
FILE: docs/patterns.md
================================================
# Heredoc Pattern Authoring Guide

This document describes how heredoc and inline-script patterns are defined, tested,
and allowlisted. It is intended for contributors and power users.

## Overview

Heredoc detection protects against destructive commands embedded in heredocs,
here-strings, and inline interpreter flags (for example, `python -c`). The
implementation uses a tiered pipeline (see `docs/adr-001-heredoc-scanning.md`)
that only evaluates heredoc patterns when a heredoc or inline script is detected.

Stable rule IDs are required for allowlisting. The naming convention is:

```
heredoc.<language>.<operation>
```

Example:

```
heredoc.python.shutil_rmtree
```

Rule IDs are the keys used in allowlists and explain output.

Pipeline (simplified):

```
command
  -> quick reject
  -> heredoc trigger
  -> extract content + detect language
  -> ast match (language patterns)
  -> decision (allow/warn/deny)
```

## Pattern Syntax

Heredoc patterns are authored using ast-grep pattern syntax (as implemented by
`ast-grep-core`). Common conventions used in this repo:

- `$$$` matches any subtree.
- `$X` captures a single AST node.
- Patterns are language-specific and only evaluated on code parsed for that
  language.

Examples:

- `shutil.rmtree($$$)`
- `child_process.execSync($$$)`
- `exec.Command($$$).Run()`

Perl patterns are handled via targeted regex scanning of string literals and
shell payloads (see `src/ast_matcher.rs`).

## Where Patterns Live

The built-in pattern inventory is defined in:

- `src/ast_matcher.rs` (`default_patterns()` and Perl scanners)

Suggestions for some patterns are mapped in:

- `src/suggestions.rs`

The high-level design and rationale are documented in:

- `docs/adr-001-heredoc-scanning.md`
- `docs/pattern-library-design.md`

## Adding New Patterns

1. **Choose a stable rule ID** (`heredoc.<language>.<operation>`). Do not rename
   existing IDs; deprecate instead.
2. **Add a `CompiledPattern::new(...)` entry** in `src/ast_matcher.rs` for
   language-specific AST matches, or extend the Perl scanners for regex-based
   matching.
3. **Provide a concise reason** (short, human-readable, under 100 chars).
4. **Set severity** (Critical / High / Medium / Low). Consider false-positive
   risk and catastrophic targets.
5. **Add a suggestion** when a safer alternative exists.
6. **Add tests** (positive and negative fixtures) in `src/ast_matcher.rs`.
7. **Update docs** (this file and any relevant design notes).

## Adding a New Language

1. Add the language to `ScriptLanguage` in `src/heredoc.rs`.
2. Map string aliases in `src/config.rs` heredoc language parsing.
3. Map to an AST language in `src/ast_matcher.rs` (`script_language_to_ast_lang`).
4. Add default patterns in `src/ast_matcher.rs`.
5. Add suggestions in `src/suggestions.rs` (if applicable).
6. Add positive and negative fixtures in `src/ast_matcher.rs`.

## Pattern Inventory (Current Defaults)

This list is derived from `src/ast_matcher.rs` and reflects the current
built-in rule IDs. Use these IDs for allowlisting and tests.

### Bash

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.bash.rm_r` | `rm -r $$$` | `rm -r` recursively deletes |
| `heredoc.bash.rm_rf` | `rm -rf $$$` | `rm -rf` recursively deletes files/directories |
| `heredoc.bash.git_reset_hard` | `git reset --hard` | discards uncommitted changes |
| `heredoc.bash.git_clean_fd` | `git clean -fd` | deletes untracked files |

### Go

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.go.os_remove` | `os.Remove($$$)` | deletes files |
| `heredoc.go.os_removeall` | `os.RemoveAll($$$)` | recursively deletes directories |
| `heredoc.go.exec_command` | `exec.Command($$$)` | executes shell commands |
| `heredoc.go.exec_command_run` | `exec.Command($$$).Run()` | executes shell commands |
| `heredoc.go.exec_command_output` | `exec.Command($$$).Output()` | executes shell commands |
| `heredoc.go.exec_command_combined_output` | `exec.Command($$$).CombinedOutput()` | executes shell commands |

### JavaScript (Node)

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.javascript.fs_rm` | `fs.rm($$$)` | deletes files/directories |
| `heredoc.javascript.fs_rmdir` | `fs.rmdir($$$)` | deletes directories |
| `heredoc.javascript.fs_rmsync` | `fs.rmSync($$$)` | deletes files/directories |
| `heredoc.javascript.fs_rmdirsync` | `fs.rmdirSync($$$)` | deletes directories |
| `heredoc.javascript.fs_unlink` | `fs.unlink($$$)` | deletes files |
| `heredoc.javascript.fs_unlinksync` | `fs.unlinkSync($$$)` | deletes files |
| `heredoc.javascript.fspromises_rm` | `fsPromises.rm($$$)` | deletes files/directories |
| `heredoc.javascript.fspromises_rmdir` | `fsPromises.rmdir($$$)` | deletes directories |
| `heredoc.javascript.execsync` | `child_process.execSync($$$)` | executes shell commands |
| `heredoc.javascript.require_execsync` | `require('child_process').execSync($$$)` | executes shell commands |
| `heredoc.javascript.spawnsync` | `child_process.spawnSync($$$)` | executes shell commands |

### TypeScript

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.typescript.fs_rm` | `fs.rm($$$)` | deletes files/directories |
| `heredoc.typescript.fs_rmdir` | `fs.rmdir($$$)` | deletes directories |
| `heredoc.typescript.fs_rmsync` | `fs.rmSync($$$)` | deletes files/directories |
| `heredoc.typescript.fs_rmdirsync` | `fs.rmdirSync($$$)` | deletes directories |
| `heredoc.typescript.fs_unlink` | `fs.unlink($$$)` | deletes files |
| `heredoc.typescript.fs_unlinksync` | `fs.unlinkSync($$$)` | deletes files |
| `heredoc.typescript.fspromises_rm` | `fsPromises.rm($$$)` | deletes files/directories |
| `heredoc.typescript.fspromises_rmdir` | `fsPromises.rmdir($$$)` | deletes directories |
| `heredoc.typescript.execsync` | `child_process.execSync($$$)` | executes shell commands |
| `heredoc.typescript.require_execsync` | `require('child_process').execSync($$$)` | executes shell commands |
| `heredoc.typescript.spawnsync` | `child_process.spawnSync($$$)` | executes shell commands |
| `heredoc.typescript.deno_remove` | `Deno.remove($$$)` | deletes files/directories |

### Python

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.python.shutil_rmtree` | `shutil.rmtree($$$)` | recursively deletes directories |
| `heredoc.python.os_remove` | `os.remove($$$)` | deletes files |
| `heredoc.python.os_rmdir` | `os.rmdir($$$)` | deletes directories |
| `heredoc.python.os_unlink` | `os.unlink($$$)` | deletes files |
| `heredoc.python.pathlib_unlink` | `pathlib.Path($$$).unlink($$$)` and `Path($$$).unlink($$$)` | deletes files |
| `heredoc.python.pathlib_rmdir` | `pathlib.Path($$$).rmdir($$$)` and `Path($$$).rmdir($$$)` | deletes directories |
| `heredoc.python.subprocess_run` | `subprocess.run($$$)` | executes shell commands |
| `heredoc.python.subprocess_call` | `subprocess.call($$$)` | executes shell commands |
| `heredoc.python.subprocess_popen` | `subprocess.Popen($$$)` | spawns shell processes |
| `heredoc.python.os_system` | `os.system($$$)` | executes shell commands |
| `heredoc.python.os_popen` | `os.popen($$$)` | executes shell commands |

### Ruby

| Rule ID | Pattern | Reason |
| --- | --- | --- |
| `heredoc.ruby.file_delete` | `File.delete($$$)` | deletes files |
| `heredoc.ruby.file_unlink` | `File.unlink($$$)` | deletes files |
| `heredoc.ruby.dir_delete` | `Dir.delete($$$)` | deletes directories |
| `heredoc.ruby.dir_rmdir` | `Dir.rmdir($$$)` | deletes directories |
| `heredoc.ruby.fileutils_rm` | `FileUtils.rm($$$)` | deletes files |
| `heredoc.ruby.fileutils_remove` | `FileUtils.remove($$$)` | deletes files |
| `heredoc.ruby.fileutils_remove_dir` | `FileUtils.remove_dir($$$)` | deletes directories |
| `heredoc.ruby.fileutils_rm_rf` | `FileUtils.rm_rf($$$)` | recursively deletes directories |
| `heredoc.ruby.system` | `system($$$)` | executes shell commands |
| `heredoc.ruby.exec` | `exec($$$)` | replaces process with shell command |
| `heredoc.ruby.kernel_system` | `Kernel.system($$$)` | executes shell commands |
| `heredoc.ruby.kernel_exec` | `Kernel.exec($$$)` | replaces process with shell command |
| `heredoc.ruby.open3_capture3` | `Open3.capture3($$$)` | executes shell commands |
| `heredoc.ruby.open3_popen3` | `Open3.popen3($$$)` | executes shell commands |
| `heredoc.ruby.backticks` | `` `$$$` `` | executes shell commands |

### Perl

Perl scanning uses targeted regexes plus shell-payload analysis. The following
rule IDs are emitted:

- `heredoc.perl.file_path.rmtree`
- `heredoc.perl.file_path.<fn_name>` (for `File::Path::<fn_name>`)
- `heredoc.perl.unlink`
- `heredoc.perl.rmdir`
- `heredoc.perl.system.<suffix>`
- `heredoc.perl.exec.<suffix>`
- `heredoc.perl.backticks.<suffix>`
- `heredoc.perl.qx.<suffix>`

Supported `<suffix>` values (from shell-payload detection):

- `git_reset_hard`
- `git_clean_fd`
- `rm_rf`
- `rm_rf_catastrophic`

## Derived Rule IDs

Some patterns refine their rule IDs based on detected arguments:

- For JavaScript/TypeScript `fs.*` and `fsPromises.*` patterns, a literal
  catastrophic path appends `.catastrophic` to the rule ID
  (example: `heredoc.javascript.fs_rmsync.catastrophic`).
- For TypeScript `deno_remove`, a catastrophic path appends `.catastrophic`.
- For Ruby `FileUtils`/`File`/`Dir` patterns, catastrophic paths append
  `.catastrophic`.
- For Ruby `system`/`exec`/`Open3`/backticks and Perl shell calls, literal
  payloads produce rule IDs with suffixes such as `.rm_rf` and
  `.rm_rf_catastrophic`.

All derived rule IDs are valid allowlist targets.

## Limitations and False Positive Notes

- Shell execution helpers (for example, `execSync`, `system`, `os.system`) only
  escalate to high-severity decisions when a literal payload is detected. Dynamic
  payloads are warn-only to avoid false positives.
- Some file deletion APIs are refined at match time. Non-recursive or
  non-catastrophic paths may result in warn-only severity.
- Patterns are evaluated only for supported languages and only when heredoc
  triggers are detected. Non-heredoc destructive code outside the supported
  languages is out of scope.

## Testing Requirements

Add tests under `src/ast_matcher.rs`:

- At least one positive and one negative fixture per new rule.
- Ensure comments/strings do not match (false positive guard).
- Include catastrophic-path fixtures when applicable.

Run:

```
cargo test ast_matcher
```




================================================
FILE: docs/regex-automata-decision-memo.md
================================================
# regex-automata Decision Memo

**Task:** ksk.8.2 - Decision gate: adopt or drop DFA backend
**Date:** 2026-01-11
**Status:** DEFER (do not adopt at this time)

## Summary

After reviewing the feasibility report (ksk.8.1) and benchmark results, the decision is to **defer adoption of regex-automata** as a runtime dependency. The current dual-engine approach (regex + fancy-regex) is adequate and performs well within all budgets.

## Decision Rationale

### Performance Analysis

| Metric | Current (regex) | regex-automata | Verdict |
|--------|-----------------|----------------|---------|
| Match latency | ~47-49ns | ~48-52ns | No win (2-6% slower) |
| Pack evaluation | ~75-312ns | ~78-318ns | No win (2-4% slower) |
| ReDoS patterns | ~15-22ns | ~15-16ns | Slight win (irrelevant*) |
| Compilation | ~4-5Âµs | ~6-7Âµs | Worse (40-60% slower) |

*Both engines already provide O(n) guarantees, so the ReDoS improvement is marginal.

### Maintenance Cost

| Factor | Impact | Assessment |
|--------|--------|------------|
| Third regex engine | High | Adds complexity to CompiledRegex enum |
| Feature flag management | Medium | Optional dependency adds build matrix complexity |
| Pattern classification | Medium | Must decide which patterns use which engine |
| Documentation burden | Low | More engine options to explain |

### Binary Size Impact

- Current binary: 39 MB (release, LTO, stripped)
- Estimated increase: +200-400KB (+2-5%)
- Conflicts with `opt-level = "z"` philosophy

### Current State Assessment

The existing implementation:
- Meets all performance budgets (see src/perf.rs)
- Handles 99%+ of commands via quick-reject before regex
- Uses lazy compilation to amortize pattern compile costs
- Already provides O(n) ReDoS resistance

## Recommendation

**Do not adopt regex-automata at this time.**

The cost-benefit analysis shows:
- **Costs:** 2-6% slower matching, 40-60% slower compilation, 2-5% binary size increase, increased maintenance burden
- **Benefits:** Marginally better ReDoS resistance (not needed), unified API (not compelling)

## Future Reconsideration Triggers

Revisit this decision if:
1. **Performance regression:** If pack evaluation exceeds budget (currently ~100Âµs target)
2. **Multi-pattern optimization:** If RegexSet approach in ksk.8 Option C shows significant wins
3. **Dependency consolidation:** If fancy-regex is deprecated or unmaintained
4. **Binary size becomes less critical:** If distribution constraints relax

## Actions

1. Keep `regex-automata` as dev-dependency only (for benchmarks)
2. Close ksk.8.2 with this decision documented
3. Consider closing ksk.8 parent task as "deferred"
4. Archive benchmark code in `benches/regex_automata_comparison.rs` for future reference

---

## Appendix: Benchmark Reproduction

```bash
# Run the comparison benchmarks
cargo bench --bench regex_automata_comparison

# Verify current performance meets budgets
cargo bench --bench heredoc_perf
./scripts/e2e_test.sh
```



================================================
FILE: docs/regex-automata-feasibility-report.md
================================================
# regex-automata Feasibility Report

**Task:** ksk.8.1 - Feasibility + prototype for regex-automata
**Date:** 2026-01-11
**Author:** SilentRaven (Opus 4.5)

## Executive Summary

This report evaluates the feasibility of using `regex-automata` as an alternative to the current `regex`/`fancy-regex` dual-engine approach in dcg. Based on benchmarks, **regex-automata shows comparable performance** to the current implementation with potential benefits for certain workloads.

**Recommendation:** Proceed with cautious integration for the ~85% of patterns that don't require lookahead/lookbehind. Keep `fancy-regex` for the remaining ~15%.

## Benchmark Results

### 1. Compilation Time

| Pattern | regex | regex-automata | Difference |
|---------|-------|----------------|------------|
| git-reset-hard | ~4.8Âµs | ~6.8Âµs | +42% slower |
| git-clean-force | ~4.5Âµs | ~6.2Âµs | +38% slower |
| rm-rf | ~5.2Âµs | ~7.1Âµs | +37% slower |
| drop-table | ~3.1Âµs | ~4.9Âµs | +58% slower |

**Analysis:** regex-automata has higher compilation overhead (~40-60% slower), but this is mitigated by dcg's `LazyCompiledRegex` pattern which compiles once per pattern lifetime.

### 2. Match Performance (Single Pattern)

| Operation | regex | regex-automata | Difference |
|-----------|-------|----------------|------------|
| is_match | ~47ns | ~48ns | ~2% slower |
| find | ~49ns | ~52ns | ~6% slower |

**Analysis:** Nearly identical match performance. Both engines deliver sub-50ns matching for typical patterns.

### 3. Multi-Pattern Evaluation (Pack Simulation)

| Scenario | regex | regex-automata | Difference |
|----------|-------|----------------|------------|
| Sequential (match found) | ~75ns | ~78ns | ~4% slower |
| Sequential (no match) | ~312ns | ~318ns | ~2% slower |
| Combined alternation | ~58ns | ~61ns | ~5% slower |

**Analysis:** Sequential evaluation performance is comparable. Combined alternation patterns show similar speedup in both engines.

### 4. Worst-Case (ReDoS Resistance)

| Pattern | regex | regex-automata | Status |
|---------|-------|----------------|--------|
| (a+)+$ | ~15ns | ~16ns | Both O(n) |
| (a\|a)+ | ~22ns | ~15ns | automata 32% faster |
| (a*)*b | ~22ns | ~16ns | automata 27% faster |

**Analysis:** Both engines handle catastrophic backtracking patterns in O(n) time. regex-automata shows slight advantage on pathological patterns.

### 5. Long Input Handling

| Input Size | regex | regex-automata | Throughput |
|------------|-------|----------------|------------|
| 100 bytes | 210ns | 201ns | ~520 MiB/s |
| 1KB | 1.48Âµs | 1.49Âµs | ~650 MiB/s |
| 5KB | 7.16Âµs | 7.16Âµs | ~665 MiB/s |
| 10KB | 14.3Âµs | 14.4Âµs | ~667 MiB/s |

**Analysis:** Nearly identical performance on long inputs. Both achieve ~650 MiB/s throughput, well within dcg's performance budgets.

## Build Size Impact

**Current binary size:** 39 MB (release, LTO, stripped)

**Dependency analysis:**
- `regex` crate: Already included (required for RegexSet in heredoc)
- `regex-automata`: Would add ~200-400KB estimated (shares some code with regex crate)

**Note:** Since `regex-automata` is currently only a dev-dependency for benchmarks, the production binary size is unchanged. If integrated as a runtime dependency:
- Estimated impact: +2-5% binary size
- Can be mitigated with feature flags

## Architecture Recommendations

### Option A: Drop-in Replacement (Not Recommended)
Replace `regex` with `regex-automata::meta::Regex` everywhere.
- **Pro:** Unified engine
- **Con:** Higher compilation time, loses RegexSet benefits

### Option B: Hybrid Approach (Recommended)
Keep current architecture but use `regex-automata` for specific optimizations:

1. **Pre-compiled DFA for hot patterns:** Use `regex-automata::dfa::dense::DFA` for the most frequently matched patterns (git-reset-hard, rm-rf, etc.)
2. **Keep lazy compilation:** Continue using `OnceLock` pattern for on-demand compilation
3. **Maintain fancy-regex:** Keep for lookahead/lookbehind patterns (~15% of patterns)

### Option C: RegexSet Optimization (Future Consideration)
Use `regex-automata`'s multi-pattern matching capabilities:
- Build a single DFA for all patterns in a pack
- Single scan instead of sequential pattern evaluation
- Potential 3-5x speedup for packs with many patterns

## Integration Plan

If proceeding with Option B:

```rust
// In regex_engine.rs
pub enum CompiledRegex {
    Linear(regex::Regex),           // Current: simple patterns
    Backtracking(fancy_regex::Regex), // Current: lookahead/lookbehind
    Automata(regex_automata::meta::Regex), // New: hot path patterns
}
```

**Migration steps:**
1. Add `regex-automata` as optional dependency with feature flag
2. Identify top 10 most frequently matched patterns
3. Create `Automata` variant for those patterns
4. Benchmark real-world improvement
5. Gradually expand coverage if beneficial

## Conclusion

**Verdict:** regex-automata is a viable alternative with comparable performance characteristics. The main benefits would come from:

1. **Unified API** - Single crate instead of regex + fancy-regex
2. **Future optimization potential** - Better support for pre-compiled DFAs and multi-pattern matching
3. **Slightly better ReDoS resistance** - Faster on pathological patterns

**Recommended next step:** Implement Option B as a controlled experiment, measuring real-world impact on dcg's E2E regression harness before committing to broader adoption.

---

## Appendix: Benchmark Commands

```bash
# Run comparison benchmarks
cargo bench --bench regex_automata_comparison

# Run existing heredoc benchmarks
cargo bench --bench heredoc_perf

# Run E2E regression
dcg corpus tests/corpora/canonical.csv --summary
```



================================================
FILE: docs/rich-rust-integration-plan.md
================================================
# rich_rust Integration Plan for dcg

## Executive Summary

This document outlines a comprehensive plan to integrate [`rich_rust`](https://github.com/Dicklesworthstone/rich_rust) into the dcg (Destructive Command Guard) codebase to achieve premium, stylish terminal output for human observers while maintaining full compatibility with AI coding agents.

**Critical Constraint:** Agent-facing output (JSON on stdout) must remain completely untouched. All rich_rust enhancements apply exclusively to human-facing output (stderr and human-readable CLI commands).

---

## Table of Contents

1. [Architecture Overview](#1-architecture-overview)
2. [Dependency Integration](#2-dependency-integration)
3. [Console Abstraction Layer](#3-console-abstraction-layer)
4. [Module-by-Module Integration](#4-module-by-module-integration)
5. [Feature Mapping](#5-feature-mapping)
6. [Migration Strategy](#6-migration-strategy)
7. [Agent Safety Measures](#7-agent-safety-measures)
8. [Performance Considerations](#8-performance-considerations)
9. [Testing Strategy](#9-testing-strategy)
10. [Rollout Phases](#10-rollout-phases)

---

## 1. Architecture Overview

### Current dcg Output Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         dcg CLI / Hook Mode                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  src/hook.rs â”‚    â”‚  src/cli.rs  â”‚    â”‚ src/output/mod.rs    â”‚  â”‚
â”‚  â”‚  (JSONâ†’stdout)â”‚    â”‚  (commands)  â”‚    â”‚ (TTY detection)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                       â”‚               â”‚
â”‚         â”‚                   â”‚                       â–¼               â”‚
â”‚         â”‚                   â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚         â”‚                   â”‚            â”‚  src/output/theme.rs â”‚   â”‚
â”‚         â”‚                   â”‚            â”‚  (colors, borders)   â”‚   â”‚
â”‚         â”‚                   â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                   â”‚                       â”‚               â”‚
â”‚         â”‚                   â–¼                       â–¼               â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚         â”‚    â”‚  src/output/{denial,test,tables,progress}.rs   â”‚    â”‚
â”‚         â”‚    â”‚  (DenialBox, TestResultBox, Tables, Progress)  â”‚    â”‚
â”‚         â”‚    â”‚  Uses: comfy-table, ratatui, colored, indicatifâ”‚    â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                           â”‚
â”‚         â–¼                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  STDOUT  â”‚  â† JSON only (agents)         â”‚    STDERR     â”‚     â”‚
â”‚   â”‚  (pure)  â”‚                               â”‚  (colorful)   â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Target Architecture with rich_rust

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         dcg CLI / Hook Mode                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  src/hook.rs â”‚    â”‚  src/cli.rs  â”‚    â”‚ src/output/mod.rs    â”‚  â”‚
â”‚  â”‚  (JSONâ†’stdout)â”‚    â”‚  (commands)  â”‚    â”‚ (rich_rust Console)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                       â”‚               â”‚
â”‚         â”‚                   â”‚                       â–¼               â”‚
â”‚         â”‚                   â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚         â”‚                   â”‚            â”‚  src/output/theme.rs â”‚   â”‚
â”‚         â”‚                   â”‚            â”‚  (rich_rust Theme)   â”‚   â”‚
â”‚         â”‚                   â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                   â”‚                       â”‚               â”‚
â”‚         â”‚                   â–¼                       â–¼               â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚         â”‚    â”‚  src/output/{denial,test,tables,progress}.rs   â”‚    â”‚
â”‚         â”‚    â”‚  rich_rust: Panel, Table, Rule, ProgressBar    â”‚    â”‚
â”‚         â”‚    â”‚  Markup syntax: [bold red]text[/]              â”‚    â”‚
â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                                                           â”‚
â”‚         â–¼                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚  STDOUT  â”‚  â† JSON only (UNCHANGED)      â”‚    STDERR     â”‚     â”‚
â”‚   â”‚  (pure)  â”‚                               â”‚  (premium UI) â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Dependency Integration

### 2.1 Cargo.toml Changes

```toml
# Add to [dependencies]
rich_rust = { version = "0.1", features = ["full"] }

# Remove after migration (or keep as fallback)
# colored = "2.1"          # Replaced by rich_rust Style
# comfy-table = "7.2"      # Replaced by rich_rust Table
# indicatif = "0.17"       # Replaced by rich_rust ProgressBar
# ratatui = { ... }        # Keep for now, gradual migration
```

### 2.2 Feature Flag Strategy

Create a feature flag for gradual rollout:

```toml
[features]
default = []
rich-output = ["dep:rich_rust"]
legacy-output = []  # Keep old rendering for compatibility testing
```

### 2.3 Conditional Compilation

```rust
#[cfg(feature = "rich-output")]
use rich_rust::prelude::*;

#[cfg(not(feature = "rich-output"))]
use crate::output::legacy::*;
```

---

## 3. Console Abstraction Layer

### 3.1 Create `src/output/console.rs`

This module wraps rich_rust's Console with dcg-specific defaults and stderr routing:

```rust
//! Console abstraction for dcg output.
//!
//! Provides a unified interface for all human-facing output, automatically
//! routing to stderr and detecting terminal capabilities.

use rich_rust::prelude::*;
use std::io::{self, Write};
use std::sync::OnceLock;

/// Global console instance for human-facing output.
static CONSOLE: OnceLock<DcgConsole> = OnceLock::new();

/// dcg-specific console wrapper.
pub struct DcgConsole {
    inner: Console,
    force_plain: bool,
}

impl DcgConsole {
    /// Create a new console that writes to stderr.
    pub fn new() -> Self {
        let inner = Console::new()
            .with_stderr()  // Critical: all output goes to stderr
            .with_force_terminal(false);  // Respect TTY detection

        Self {
            inner,
            force_plain: false,
        }
    }

    /// Create a plain-text console (no colors, no unicode).
    pub fn plain() -> Self {
        let inner = Console::new()
            .with_stderr()
            .with_no_color();

        Self {
            inner,
            force_plain: true,
        }
    }

    /// Print styled text using markup syntax.
    pub fn print(&self, text: &str) {
        if self.force_plain {
            self.inner.print_plain(text);
        } else {
            self.inner.print(text);
        }
    }

    /// Print a renderable (Panel, Table, Rule, etc.).
    pub fn print_renderable<R: Renderable>(&self, renderable: &R) {
        self.inner.print_renderable(renderable);
    }

    /// Print a horizontal rule with optional title.
    pub fn rule(&self, title: Option<&str>) {
        self.inner.rule(title);
    }

    /// Get terminal width.
    pub fn width(&self) -> usize {
        self.inner.width()
    }
}

/// Get the global console instance.
pub fn console() -> &'static DcgConsole {
    CONSOLE.get_or_init(|| {
        if crate::output::should_use_rich_output() {
            DcgConsole::new()
        } else {
            DcgConsole::plain()
        }
    })
}

/// Initialize the console with explicit settings.
pub fn init_console(force_plain: bool) {
    let _ = CONSOLE.set(if force_plain {
        DcgConsole::plain()
    } else {
        DcgConsole::new()
    });
}
```

---

## 4. Module-by-Module Integration

### 4.1 `src/output/denial.rs` - DenialBox â†’ rich_rust Panel

**Current Implementation:** Manual ANSI escape codes, custom box drawing

**Target Implementation:** rich_rust Panel with styled content

```rust
use rich_rust::prelude::*;

pub struct DenialBox {
    command: String,
    reason: String,
    pack: Option<String>,
    pattern: Option<String>,
    explanation: Option<String>,
    severity: Option<Severity>,
    allow_once_code: Option<String>,
}

impl DenialBox {
    pub fn render(&self, theme: &DcgTheme) -> String {
        let console = Console::new().with_stderr();

        // Build styled content using markup
        let mut content = Text::new();

        // Header with severity coloring
        let severity_style = match self.severity {
            Some(Severity::Critical) => "[bold bright_red]",
            Some(Severity::High) => "[bold red]",
            Some(Severity::Medium) => "[bold yellow]",
            Some(Severity::Low) => "[bold blue]",
            None => "[bold]",
        };

        content.push_line(format!("{severity_style}ðŸ›‘ COMMAND BLOCKED[/]"));
        content.push_line("");

        // Command with highlighting
        content.push_line(format!("[dim]Command:[/]  [bold]{cmd}[/]", cmd = self.command));

        if let Some(reason) = &self.reason {
            content.push_line(format!("[dim]Reason:[/]   {reason}"));
        }

        if let Some(pack) = &self.pack {
            content.push_line(format!("[dim]Pack:[/]     [cyan]{pack}[/]"));
        }

        if let Some(pattern) = &self.pattern {
            content.push_line(format!("[dim]Pattern:[/]  [magenta]{pattern}[/]"));
        }

        if let Some(explanation) = &self.explanation {
            content.push_line("");
            content.push_line(format!("[italic]{explanation}[/]"));
        }

        // Allow-once code section
        if let Some(code) = &self.allow_once_code {
            content.push_line("");
            content.push_line("[dim]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/]");
            content.push_line(format!(
                "[yellow]To allow once:[/] [bold]dcg allow-once {code}[/]"
            ));
        }

        // Create panel with severity-appropriate border
        let box_style = match self.severity {
            Some(Severity::Critical) => BoxStyle::double(),
            Some(Severity::High) => BoxStyle::heavy(),
            _ => BoxStyle::rounded(),
        };

        let border_color = match self.severity {
            Some(Severity::Critical) => "bright_red",
            Some(Severity::High) => "red",
            Some(Severity::Medium) => "yellow",
            Some(Severity::Low) => "blue",
            None => "red",
        };

        Panel::from_text(content.to_string())
            .title("[bold] DCG [/]")
            .border_style(Style::parse(border_color).unwrap_or_default())
            .box_style(box_style)
            .padding((1, 2))
            .to_string()
    }
}
```

### 4.2 `src/output/test.rs` - TestResultBox â†’ rich_rust Panel

**Current Implementation:** Similar manual rendering

**Target Implementation:**

```rust
use rich_rust::prelude::*;

impl TestResultBox {
    pub fn render(&self, theme: &DcgTheme) -> String {
        let (title, border_style, header_color) = match &self.result {
            TestOutcome::Blocked { .. } => (
                " WOULD BE BLOCKED ",
                BoxStyle::heavy(),
                "bold bright_red",
            ),
            TestOutcome::Allowed { .. } => (
                " WOULD BE ALLOWED ",
                BoxStyle::rounded(),
                "bold bright_green",
            ),
        };

        let mut content = Text::new();

        // Command line
        content.push_line(format!(
            "[dim]Command:[/]     [bold]{cmd}[/]",
            cmd = self.command
        ));

        // Result-specific content
        match &self.result {
            TestOutcome::Blocked { pattern_id, pack_id, severity, reason, confidence } => {
                if let Some(pattern) = pattern_id {
                    content.push_line(format!("[dim]Pattern:[/]     [magenta]{pattern}[/]"));
                }
                if let Some(pack) = pack_id {
                    let sev = severity.map(|s| format!(" [dim]({})[/]", severity_label(s)))
                        .unwrap_or_default();
                    content.push_line(format!("[dim]Pack:[/]        [cyan]{pack}[/]{sev}"));
                }
                if let Some(conf) = confidence {
                    let bar = render_confidence_bar(*conf);
                    content.push_line(format!("[dim]Confidence:[/]  {bar} {conf:.0}%", conf = conf * 100.0));
                }
                content.push_line(format!("[dim]Reason:[/]      {reason}"));
            }
            TestOutcome::Allowed { reason } => {
                let reason_text = match reason {
                    AllowedReason::NoPatternMatch => "No pattern matches".to_string(),
                    AllowedReason::AllowlistMatch { entry, layer } => {
                        format!("Allowlist: [italic]\"{entry}\"[/] ({layer})")
                    }
                    AllowedReason::BudgetExhausted => {
                        "[yellow]Budget exhausted (fail-open)[/]".to_string()
                    }
                };
                content.push_line(format!("[dim]Reason:[/]      {reason_text}"));
            }
        }

        Panel::from_text(content.to_string())
            .title(format!("[{header_color}]{title}[/]"))
            .box_style(border_style)
            .border_style(Style::parse(header_color).unwrap_or_default())
            .padding((1, 2))
            .to_string()
    }
}

/// Render a visual confidence bar using Unicode blocks
fn render_confidence_bar(confidence: f64) -> String {
    let filled = (confidence * 10.0).round() as usize;
    let empty = 10 - filled;

    let color = if confidence >= 0.8 {
        "red"
    } else if confidence >= 0.5 {
        "yellow"
    } else {
        "green"
    };

    format!(
        "[{color}]{}[/][dim]{}[/]",
        "â–ˆ".repeat(filled),
        "â–‘".repeat(empty)
    )
}
```

### 4.3 `src/output/tables.rs` - comfy-table â†’ rich_rust Table

**Current Implementation:** comfy-table with ratatui colors

**Target Implementation:**

```rust
use rich_rust::prelude::*;

/// Table renderer for scan results.
pub struct ScanResultsTable {
    rows: Vec<ScanResultRow>,
    theme: Option<DcgTheme>,
}

impl ScanResultsTable {
    pub fn render(&self) -> String {
        if self.rows.is_empty() {
            return "[dim]No findings.[/]".to_string();
        }

        let mut table = Table::new()
            .title("[bold]Scan Results[/]")
            .with_column(Column::new("File").style(Style::new().cyan()))
            .with_column(Column::new("Line").justify(JustifyMethod::Right))
            .with_column(Column::new("Severity").justify(JustifyMethod::Center))
            .with_column(Column::new("Pattern"));

        for row in &self.rows {
            let severity_cell = match row.severity {
                Severity::Critical => "[bold bright_red]CRIT[/]",
                Severity::High => "[red]HIGH[/]",
                Severity::Medium => "[yellow]MED[/]",
                Severity::Low => "[blue]LOW[/]",
            };

            table.add_row_cells([
                &row.file,
                &row.line.to_string(),
                severity_cell,
                &row.pattern_id,
            ]);
        }

        table.to_string()
    }
}

/// Pack listing table.
pub struct PackListTable {
    rows: Vec<PackRow>,
}

impl PackListTable {
    pub fn render(&self) -> String {
        if self.rows.is_empty() {
            return "[dim]No packs available.[/]".to_string();
        }

        let mut table = Table::new()
            .title("[bold]Available Packs[/]")
            .with_column(Column::new("Pack ID").style(Style::new().cyan()))
            .with_column(Column::new("Name"))
            .with_column(Column::new("Destructive").justify(JustifyMethod::Right))
            .with_column(Column::new("Safe").justify(JustifyMethod::Right))
            .with_column(Column::new("Status").justify(JustifyMethod::Center));

        for row in &self.rows {
            let status = if row.enabled {
                "[green]â—[/] enabled"
            } else {
                "[dim]â—‹[/] disabled"
            };

            table.add_row_cells([
                &row.id,
                &row.name,
                &row.destructive_count.to_string(),
                &row.safe_count.to_string(),
                status,
            ]);
        }

        table.to_string()
    }
}
```

### 4.4 `src/output/progress.rs` - indicatif â†’ rich_rust ProgressBar

```rust
use rich_rust::prelude::*;

/// Progress display for long-running operations.
pub struct ScanProgress {
    total: usize,
    current: usize,
    current_file: String,
}

impl ScanProgress {
    pub fn render(&self) -> String {
        let bar = ProgressBar::new()
            .completed(self.current)
            .total(self.total)
            .width(40)
            .style(Style::new().cyan());

        let pct = (self.current as f64 / self.total as f64 * 100.0) as usize;

        format!(
            "{bar}  [bold]{pct}%[/]  [dim]{file}[/]",
            bar = bar.to_string(),
            pct = pct,
            file = truncate(&self.current_file, 30)
        )
    }
}
```

### 4.5 `src/hook.rs` - print_colorful_warning Integration

**Critical:** This function outputs to stderr for human consumption while the JSON verdict goes to stdout.

```rust
use crate::output::console::console;
use rich_rust::prelude::*;

/// Print a colorful warning to stderr about a blocked command.
pub fn print_colorful_warning(
    command: &str,
    reason: &str,
    pack: Option<&str>,
    pattern: Option<&str>,
    explanation: Option<&str>,
    allow_once_code: Option<&str>,
    matched_span: Option<&MatchSpan>,
    pattern_suggestions: &[PatternSuggestion],
) {
    let console = console();

    // Build the denial panel
    let denial = DenialBox {
        command: command.to_string(),
        reason: reason.to_string(),
        pack: pack.map(String::from),
        pattern: pattern.map(String::from),
        explanation: explanation.map(String::from),
        severity: determine_severity(pack, pattern),
        allow_once_code: allow_once_code.map(String::from),
    };

    // Render to stderr via Console
    eprintln!("{}", denial.render(&DcgTheme::auto()));

    // Pattern suggestions as a secondary panel
    if !pattern_suggestions.is_empty() {
        let suggestions = render_suggestions_panel(pattern_suggestions);
        eprintln!("{}", suggestions);
    }
}

fn render_suggestions_panel(suggestions: &[PatternSuggestion]) -> String {
    let mut content = Text::new();

    for (i, suggestion) in suggestions.iter().enumerate() {
        content.push_line(format!(
            "[bold cyan]{i}.[/] {desc}",
            i = i + 1,
            desc = suggestion.description
        ));
        if let Some(example) = &suggestion.example {
            content.push_line(format!("   [dim]Example:[/] [italic]{example}[/]"));
        }
    }

    Panel::from_text(content.to_string())
        .title("[yellow bold] ðŸ’¡ Suggestions [/]")
        .box_style(BoxStyle::rounded())
        .border_style(Style::new().yellow())
        .to_string()
}
```

### 4.6 `src/cli.rs` - Command Output Formatting

#### doctor command

```rust
fn run_doctor(fix: bool, format: DoctorFormat) -> Result<()> {
    let console = console();

    console.rule(Some("[bold] dcg doctor [/]"));
    console.print("");

    let checks = vec![
        ("Configuration", check_config()),
        ("Hook Registration", check_hook()),
        ("Pack Loading", check_packs()),
        ("Permissions", check_permissions()),
    ];

    let mut all_passed = true;

    for (name, result) in checks {
        let (icon, status, color) = match result {
            CheckResult::Pass => ("âœ“", "PASS", "green"),
            CheckResult::Warn(msg) => {
                all_passed = false;
                ("âš ", &format!("WARN: {msg}"), "yellow")
            }
            CheckResult::Fail(msg) => {
                all_passed = false;
                ("âœ—", &format!("FAIL: {msg}"), "red")
            }
        };

        console.print(&format!(
            "  [{color}]{icon}[/] {name:<20} [{color}]{status}[/]"
        ));
    }

    console.print("");

    if all_passed {
        console.print("[bold green]All checks passed![/]");
    } else {
        console.print("[yellow]Some issues detected.[/] Run with --fix to attempt repairs.");
    }

    Ok(())
}
```

#### packs command

```rust
fn run_list_packs(enabled: bool, format: PacksFormat) -> Result<()> {
    match format {
        PacksFormat::Json => {
            // JSON output to stdout (agent-safe)
            let packs = collect_packs(enabled);
            println!("{}", serde_json::to_string_pretty(&packs)?);
        }
        PacksFormat::Pretty => {
            let console = console();

            console.rule(Some("[bold] Available Packs [/]"));
            console.print("");

            let rows = collect_pack_rows(enabled);
            let table = PackListTable::new(rows);

            console.print(&table.render());

            // Summary footer
            let total = rows.len();
            let enabled_count = rows.iter().filter(|r| r.enabled).count();

            console.print("");
            console.print(&format!(
                "[dim]Total:[/] {total} packs ({enabled_count} enabled, {} disabled)",
                total - enabled_count
            ));
        }
    }

    Ok(())
}
```

#### explain command

```rust
fn run_explain(command: &str, format: ExplainFormat) -> Result<()> {
    match format {
        ExplainFormat::Json => {
            // JSON to stdout
            let trace = explain_command(command)?;
            println!("{}", serde_json::to_string_pretty(&trace)?);
        }
        ExplainFormat::Pretty => {
            let console = console();

            console.rule(Some("[bold] Decision Trace [/]"));

            let trace = explain_command(command)?;

            // Render as a tree structure
            let mut tree = TreeNode::new(format!(
                "[bold]Command:[/] {}",
                truncate(command, 60)
            ));

            // Add decision stages
            let keyword_node = TreeNode::new(format!(
                "[{}]Keyword Gate[/]: {}",
                if trace.keyword_matched { "green" } else { "dim" },
                if trace.keyword_matched { "matched" } else { "no match" }
            ));
            tree.add_child(keyword_node);

            if let Some(pack_eval) = &trace.pack_evaluation {
                let mut pack_node = TreeNode::new(format!(
                    "[cyan]Pack Evaluation[/]: {}",
                    pack_eval.pack_id
                ));

                for pattern in &pack_eval.patterns_checked {
                    let (icon, color) = if pattern.matched {
                        ("â—", "red")
                    } else {
                        ("â—‹", "dim")
                    };
                    pack_node.add_child(TreeNode::new(format!(
                        "[{color}]{icon}[/] {}",
                        pattern.name
                    )));
                }

                tree.add_child(pack_node);
            }

            // Final decision
            let decision_node = TreeNode::new(format!(
                "[bold {}]Decision:[/] {}",
                if trace.decision == "deny" { "red" } else { "green" },
                trace.decision.to_uppercase()
            ));
            tree.add_child(decision_node);

            let tree_widget = Tree::new(tree);
            console.print_renderable(&tree_widget);
        }
    }

    Ok(())
}
```

---

## 5. Feature Mapping

### 5.1 rich_rust Feature â†’ dcg Usage

| rich_rust Feature | dcg Usage Area | Priority |
|-------------------|----------------|----------|
| `Console` | Global output coordinator | P0 |
| `Panel` | DenialBox, TestResultBox, help panels | P0 |
| `Table` | Pack listings, scan results, stats | P0 |
| `Rule` | Section dividers in CLI output | P1 |
| `Style` + Markup | All colored text (replaces `colored`) | P0 |
| `Tree` | explain command, decision traces | P1 |
| `ProgressBar` | scan command, long operations | P2 |
| `Columns` | Side-by-side comparisons | P2 |
| `Syntax` (feature) | Heredoc highlighting in explain | P3 |
| `Markdown` (feature) | Help text rendering | P3 |

### 5.2 Markup Syntax Reference

```rust
// Basic styles
"[bold]Bold text[/]"
"[italic]Italic text[/]"
"[underline]Underlined[/]"
"[dim]Muted text[/]"

// Colors
"[red]Red text[/]"
"[green]Green text[/]"
"[yellow]Warning[/]"
"[cyan]Info[/]"
"[magenta]Pattern name[/]"

// Combined
"[bold red]Critical error[/]"
"[dim italic]Explanatory text[/]"

// Backgrounds
"[on red]Highlighted[/]"
"[white on red] BLOCKED [/]"

// Hex/RGB (if terminal supports)
"[#ff6600]Orange text[/]"
"[rgb(100,150,200)]Custom color[/]"
```

---

## 6. Migration Strategy

### 6.1 Phase 1: Foundation (Week 1)

1. Add `rich_rust` dependency with `full` feature
2. Create `src/output/console.rs` abstraction
3. Create `src/output/rich_theme.rs` mapping dcg themes to rich_rust
4. Add `--legacy-output` flag for fallback

### 6.2 Phase 2: Core Components (Week 2)

1. Migrate `denial.rs` to use rich_rust Panel
2. Migrate `test.rs` to use rich_rust Panel
3. Update `hook.rs` `print_colorful_warning` function
4. Ensure all stderr output uses Console

### 6.3 Phase 3: Tables & Progress (Week 3)

1. Migrate `tables.rs` from comfy-table to rich_rust Table
2. Update `progress.rs` to use rich_rust ProgressBar
3. Update CLI commands: `packs`, `stats`, `scan`

### 6.4 Phase 4: Advanced Features (Week 4)

1. Add Tree rendering for `explain` command
2. Add Syntax highlighting for heredoc content
3. Add Markdown rendering for `--help` output
4. Performance optimization pass

### 6.5 Phase 5: Cleanup (Week 5)

1. Remove unused dependencies (comfy-table, indicatif if fully replaced)
2. Remove legacy output code paths
3. Update documentation
4. Final testing across terminal types

---

## 7. Agent Safety Measures

### 7.1 Output Channel Separation

**Rule:** JSON output to stdout MUST remain pure JSON. All rich output goes to stderr.

```rust
// CORRECT: Human output to stderr
eprintln!("{}", panel.render());

// CORRECT: Agent output to stdout
println!("{}", serde_json::to_string(&verdict)?);

// WRONG: Never mix
println!("{}", panel.render()); // âŒ Don't send rich output to stdout
```

### 7.2 Format Detection

```rust
impl Cli {
    /// Determine if we're in agent mode (JSON output expected).
    fn is_agent_mode(&self) -> bool {
        // Check for JSON format flag
        if self.json_output() {
            return true;
        }

        // Check for stdin from Claude Code hook
        if std::env::var("CLAUDE_CODE_HOOK").is_ok() {
            return true;
        }

        // Check for piped stdout (non-TTY)
        if !std::io::stdout().is_terminal() {
            return true;
        }

        false
    }
}
```

### 7.3 Conditional Output

```rust
fn output_result(result: &EvaluationResult, cli: &Cli) {
    if cli.is_agent_mode() {
        // Pure JSON to stdout
        let json = serde_json::to_string(result).unwrap();
        println!("{json}");
    } else {
        // Rich output to stderr
        let panel = TestResultBox::from_evaluation(&result.command, result);
        eprintln!("{}", panel.render(&DcgTheme::auto()));
    }
}
```

### 7.4 Environment Variable Controls

```rust
// Respect NO_COLOR (https://no-color.org/)
if std::env::var("NO_COLOR").is_ok() {
    console = Console::plain();
}

// Respect CI environments
if std::env::var("CI").is_ok() {
    console = Console::plain();
}

// dcg-specific disable
if std::env::var("DCG_NO_RICH").is_ok() {
    console = Console::plain();
}
```

---

## 8. Performance Considerations

### 8.1 Hook Mode Latency Budget

dcg operates under strict latency constraints:

| Tier | Budget | Current | Target |
|------|--------|---------|--------|
| Instant | <5ms | âœ“ | âœ“ |
| Fast | <15ms | âœ“ | âœ“ |
| Normal | <50ms | âœ“ | âœ“ |

**rich_rust Impact Assessment:**

- Console initialization: ~1ms (one-time)
- Panel rendering: <1ms per panel
- Table rendering: <2ms for typical sizes
- Markup parsing: <0.5ms per string

**Mitigation:**

1. Lazy initialization of Console
2. Pre-compute static panels at startup
3. Cache terminal width detection
4. Avoid rendering if output is suppressed

### 8.2 Memory Considerations

rich_rust uses heap allocation for:
- Segment vectors (per-line)
- Style structs (small, stack-optimizable)
- String building

For hook mode where memory matters:
- Reuse Console instance (already planned)
- Avoid repeated allocations in tight loops
- Consider `smallvec` for small segment lists

### 8.3 Benchmarking

Add benchmark comparing old vs new rendering:

```rust
// benches/output_perf.rs
use criterion::{criterion_group, criterion_main, Criterion};

fn bench_denial_box(c: &mut Criterion) {
    let denial = DenialBox::new(/* test data */);

    c.bench_function("denial_box_legacy", |b| {
        b.iter(|| denial.render_legacy(&theme))
    });

    c.bench_function("denial_box_rich", |b| {
        b.iter(|| denial.render_rich(&theme))
    });
}
```

---

## 9. Testing Strategy

### 9.1 Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn denial_box_renders_with_all_fields() {
        let denial = DenialBox {
            command: "rm -rf /".to_string(),
            reason: "Recursive deletion of root".to_string(),
            pack: Some("core.filesystem".to_string()),
            pattern: Some("rm-rf-root".to_string()),
            explanation: Some("This would destroy the system".to_string()),
            severity: Some(Severity::Critical),
            allow_once_code: Some("abc123".to_string()),
        };

        let output = denial.render(&DcgTheme::default());

        assert!(output.contains("COMMAND BLOCKED"));
        assert!(output.contains("rm -rf /"));
        assert!(output.contains("core.filesystem"));
        assert!(output.contains("dcg allow-once abc123"));
    }

    #[test]
    fn denial_box_respects_no_color() {
        let denial = DenialBox::minimal();
        let theme = DcgTheme::no_color();

        let output = denial.render(&theme);

        // No ANSI escape codes
        assert!(!output.contains("\x1b["));
    }

    #[test]
    fn table_handles_empty_input() {
        let table = ScanResultsTable::new(vec![]);
        let output = table.render();

        assert!(output.contains("No findings"));
    }
}
```

### 9.2 Integration Tests

```rust
#[test]
fn hook_mode_outputs_json_to_stdout() {
    let output = Command::new("dcg")
        .args(["hook"])
        .write_stdin(r#"{"tool_name":"Bash","tool_input":{"command":"rm -rf /"}}"#)
        .output()
        .unwrap();

    // stdout should be valid JSON
    let stdout = String::from_utf8_lossy(&output.stdout);
    let json: serde_json::Value = serde_json::from_str(&stdout).unwrap();

    assert_eq!(json["decision"], "deny");

    // stderr should have the colorful warning (for humans)
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(stderr.contains("BLOCKED") || stderr.contains("blocked"));
}
```

### 9.3 Visual Regression Tests

Create reference screenshots for different terminal types:
- iTerm2 (macOS)
- Windows Terminal
- GNOME Terminal (Linux)
- xterm (minimal)

### 9.4 Accessibility Tests

```rust
#[test]
fn output_works_with_screen_reader() {
    // Test with NO_COLOR set
    std::env::set_var("NO_COLOR", "1");

    let denial = DenialBox::minimal();
    let output = denial.render(&DcgTheme::auto());

    // Should be readable without color codes
    assert!(!output.contains("\x1b["));
    assert!(output.contains("BLOCKED")); // Key information preserved
}
```

---

## 10. Rollout Phases

### 10.1 Alpha (Internal Testing)

- Feature flag: `rich-output` (opt-in)
- Duration: 1 week
- Criteria: No regressions in existing tests

### 10.2 Beta (Opt-In Users)

- Environment variable: `DCG_RICH_OUTPUT=1`
- Duration: 2 weeks
- Collect feedback via GitHub issues

### 10.3 General Availability

- Default enabled
- Legacy fallback: `DCG_LEGACY_OUTPUT=1` or `--legacy-output`
- Remove legacy code after 1 release cycle

---

## Appendix A: Color Palette Mapping

| dcg Theme Color | rich_rust Equivalent | Hex |
|-----------------|---------------------|-----|
| `error_color` | `bright_red` | #FF5555 |
| `warning_color` | `yellow` | #F1FA8C |
| `success_color` | `bright_green` | #50FA7B |
| `info_color` | `cyan` | #8BE9FD |
| `muted_color` | `dim` | #6272A4 |
| `critical_severity` | `bold bright_red` | #FF5555 |
| `high_severity` | `red` | #FF6E6E |
| `medium_severity` | `yellow` | #F1FA8C |
| `low_severity` | `blue` | #8BE9FD |

---

## Appendix B: Box Style Reference

| dcg BorderStyle | rich_rust BoxStyle | Characters |
|-----------------|-------------------|------------|
| `Unicode` | `rounded()` | â•­â”€â•® â”‚ â•°â”€â•¯ |
| `Ascii` | `ascii()` | +-+ | +-+ |
| `None` | `minimal()` | (no borders) |
| (critical) | `double()` | â•”â•â•— â•‘ â•šâ•â• |
| (high) | `heavy()` | â”â”â”“ â”ƒ â”—â”â”› |

---

## Appendix C: Dependency Comparison

### Before Migration

```toml
colored = "2.1"           # Basic ANSI colors
comfy-table = "7.2"       # Table rendering
indicatif = "0.17"        # Progress bars
ratatui = "0.30"          # TUI colors (partial use)
console = "0.15"          # Terminal detection
```

### After Migration

```toml
rich_rust = { version = "0.1", features = ["full"] }
# ratatui removed (colors now via rich_rust)
# colored removed (markup syntax)
# comfy-table removed (rich_rust Table)
# indicatif removed (rich_rust ProgressBar)
console = "0.15"          # Keep for TTY detection (or use rich_rust's)
```

**Binary size impact:** Estimated neutral to slight reduction (removing multiple crates, adding one comprehensive one).

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-01-19 | Claude | Initial comprehensive plan |



================================================
FILE: docs/scan-precommit-guide.md
================================================
# dcg scan: Pre-Commit Integration Guide

> Protect your repositories from destructive commands **before** they're committed.

This guide covers how to integrate `dcg scan` into your pre-commit workflow safely, with a focus on gradual rollout and minimizing false positive friction.

---

## What dcg scan Is (and Is Not)

### What it is

**dcg scan** analyzes files for destructive commands in *executable contexts*:

- GitHub Actions workflows (`.github/workflows/*.yml`)
- Dockerfiles (`RUN` commands)
- Shell scripts (`*.sh`, `*.bash`)
- Makefiles (recipe lines)
- GitLab CI (`.gitlab-ci.yml`)
- Docker Compose (`command:` fields)
- Terraform (`local-exec` provisioners)

The key difference from the real-time hook (`dcg` on its own):

| Mode | Protects | When |
|------|----------|------|
| **Hook** (`dcg`) | Interactive agent commands | At execution time |
| **Scan** (`dcg scan`) | Commands in committed files | At commit/CI time |

### What it is NOT

- **Not a full static analysis engine.** It does not understand your shell logic, variable expansion, or conditional branches.
- **Not a naive grep.** It uses extractors that understand file formats and only matches commands in executable contexts (not comments, documentation, or string literals).
- **Not a replacement for the hook.** Use both: the hook protects interactive execution; scan protects your repository.

---

## Quick Start

### One-command installation

```bash
# Navigate to your git repository
cd /path/to/your/repo

# Install the pre-commit hook
dcg scan install-pre-commit
```

This creates `.git/hooks/pre-commit` with a dcg-managed hook that runs `dcg scan --staged` before each commit.

### Manual integration

If you already have a pre-commit hook or use a hook manager:

```bash
# Add this line to your existing hook
dcg scan --staged
```

For hook managers like Husky, Lefthook, or pre-commit.com, see [Hook Manager Examples](#hook-manager-examples) below.

### Uninstallation

```bash
dcg scan uninstall-pre-commit
```

---

## Recommended Rollout Plan (Warn-First)

> **TL;DR:** Start conservative, expand gradually. Don't turn on warning-as-fail on day one.

### Phase 1: Observe (1-2 weeks)

Enable scanning with defaults - only catastrophic rules (`fail_on = error`) block commits.

```toml
# .dcg/hooks.toml
[scan]
fail_on = "error"      # Only block on high-confidence catastrophic rules
format = "pretty"      # Human-readable output
```

During this phase:
- Collect feedback from the team on false positives
- Use `dcg explain "<command>"` to understand why something was flagged
- Build up your allowlist for legitimate use cases

### Phase 2: Expand scope

After the team is comfortable:

1. **Add more file types** to scanning:
   ```toml
   [scan.paths]
   include = [
     ".github/workflows/**",
     "Dockerfile*",
     "Makefile",
     "scripts/**/*.sh",
   ]
   ```

2. **Consider enabling warning-as-fail** for specific high-risk patterns:
   ```bash
   # Test locally before enforcing
   dcg scan --staged --fail-on warning
   ```

### Phase 3: Enforce in CI

Once local pre-commit is stable, add CI enforcement:

```yaml
# .github/workflows/dcg-scan.yml
name: DCG Scan
on: [pull_request]
jobs:
  scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - run: |
          curl -fsSL https://raw.githubusercontent.com/Dicklesworthstone/destructive_command_guard/master/install.sh | bash
      - run: dcg scan --git-diff origin/${{ github.base_ref }}...HEAD --fail-on error
```

---

## How to Interpret Findings

### Output format

```
[ERROR] .github/workflows/ci.yml:42
  Rule:     core.git:reset-hard
  Severity: critical
  Reason:   git reset --hard destroys uncommitted changes

  â†’ dcg allow core.git:reset-hard -r "CI cleanup" --project
```

### Field meanings

| Field | Description |
|-------|-------------|
| `[ERROR]`/`[WARN]`/`[INFO]` | Severity level - ERROR blocks by default |
| File path + line | Where the command was extracted from |
| `Rule:` | Stable rule ID (`pack_id:pattern_name`) for allowlisting |
| `Severity:` | `critical`, `high`, `medium`, `low` - how dangerous |
| `Reason:` | Why this command is flagged |
| `â†’` suggestion | How to fix or allowlist |

### Severity levels

| Severity | Default action | Examples |
|----------|---------------|----------|
| `critical` | Block (`error`) | `git reset --hard`, `rm -rf /`, `DROP DATABASE` |
| `high` | Block (`error`) | `git push --force`, `docker system prune -a` |
| `medium` | Warn | Context-dependent patterns |
| `low` | Inform | Advisory patterns, low confidence |

---

## How to Fix a Finding

### Option 1: Change the code (preferred)

Many destructive commands have safer alternatives:

| Instead of | Use |
|------------|-----|
| `git reset --hard` | `git stash` or targeted `git checkout` |
| `git push --force` | `git push --force-with-lease` |
| `rm -rf ./build` | Use build tool's clean (e.g., `cargo clean`, `make clean`) |
| `docker system prune -af` | `docker image prune --filter "until=24h"` |

### Option 2: Investigate with explain

```bash
# See why a command is flagged
dcg explain "git reset --hard HEAD~1"
```

This shows the full decision trace: which pack matched, what pattern triggered, and whether any allowlists applied.

### Option 3: Allowlist (if it's a false positive)

If the command is safe in your context (e.g., a CI cleanup step), allowlist it:

```bash
# Allowlist by rule ID (recommended - most stable)
dcg allow core.git:reset-hard -r "Used for CI cleanup after tests" --project

# Or allowlist a specific command (exact match)
dcg allowlist add-command "git reset --hard HEAD" -r "CI cleanup" --project
```

**Important safety notes:**

1. **Always provide a reason** (`-r "..."`) - document why this is safe
2. **Prefer `--project`** for project-specific overrides (stored in `.dcg/allowlist.toml`)
3. **Use expiration** for temporary overrides:
   ```bash
   dcg allow core.git:reset-hard -r "Migration" --expires "2026-02-01T00:00:00Z" --project
   ```

### Viewing and managing allowlists

```bash
# List all allowlist entries
dcg allowlist list

# List project-level only
dcg allowlist list --project

# Remove an entry
dcg allowlist remove core.git:reset-hard --project

# Validate allowlist files
dcg allowlist validate
```

---

## Privacy and Secrets

### Command redaction

By default, scan output shows full commands. In CI, this could expose secrets.

```toml
# .dcg/hooks.toml
[scan]
redact = "quoted"   # Redact quoted strings: rm -rf "[REDACTED]"
# redact = "aggressive"  # Redact more aggressively
# redact = "none"        # Show full commands (default, for local use)
```

### CI best practices

1. **Use `redact = "quoted"` in CI** to avoid printing secrets in logs
2. **Limit output** with `truncate` and `max_findings`:
   ```toml
   [scan]
   truncate = 100       # Truncate long command output
   max_findings = 50    # Limit total findings per scan
   ```
3. **Use JSON format** for machine parsing in CI:
   ```toml
   [scan]
   format = "json"
   ```

---

## Configuration Reference

### .dcg/hooks.toml

Create this file in your repository root to configure scan behavior:

```toml
[scan]
# Output format: "pretty" (human-readable) or "json"
format = "pretty"

# When to fail: "error", "warning", or "none"
fail_on = "error"

# Maximum file size to scan (bytes) - larger files are skipped
max_file_size = 1048576  # 1MB

# Maximum findings to report per run
max_findings = 100

# Command redaction: "none", "quoted", or "aggressive"
redact = "none"

# Truncate long command output (0 = no truncation)
truncate = 200

[scan.paths]
# Glob patterns to include (default: all supported file types)
include = [
  ".github/workflows/**",
  "Dockerfile*",
  "**/Makefile",
  "scripts/**/*.sh",
]

# Glob patterns to exclude
exclude = [
  "vendor/**",
  "node_modules/**",
  "**/testdata/**",
]
```

### CLI flags (override config)

```bash
dcg scan --staged \
  --format json \
  --fail-on warning \
  --max-file-size 2097152 \
  --exclude "tests/**" \
  --include "*.sh"
```

CLI flags always take precedence over `.dcg/hooks.toml`.

---

## Hook Manager Examples

### Husky (npm, v8+)

```bash
# .husky/pre-commit
dcg scan --staged
```

Create with: `npx husky add .husky/pre-commit "dcg scan --staged"`

### Lefthook

```yaml
# lefthook.yml
pre-commit:
  commands:
    dcg-scan:
      run: dcg scan --staged
```

### pre-commit.com

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: dcg-scan
        name: dcg scan
        entry: dcg scan --staged
        language: system
        pass_filenames: false
```

---

## Troubleshooting

### "dcg not found in PATH"

The pre-commit hook cannot find `dcg`. Either:

1. Install dcg globally: `cargo install destructive_command_guard`
2. Add dcg's location to PATH before running git commands
3. Use an absolute path in your hook configuration

### "Refusing to overwrite existing pre-commit hook"

You already have a pre-commit hook not installed by dcg. Options:

1. **Add dcg to your existing hook**: Add `dcg scan --staged` to your hook script
2. **Replace the hook**: Delete it manually, then re-run `dcg scan install-pre-commit`

### False positives

If dcg flags a command that's safe:

1. **Investigate**: `dcg explain "the-command"` to understand why
2. **Allowlist if needed**: `dcg allow <rule_id> -r "reason" --project`
3. **Report**: If it's a pattern bug, file an issue

### Hook is too slow

Scan performance depends on:

1. **Number of staged files** - only changed files are scanned
2. **File sizes** - use `max_file_size` to skip large files
3. **Pattern count** - enable only needed packs in your config

---

## Summary

1. **Install**: `dcg scan install-pre-commit`
2. **Configure**: Create `.dcg/hooks.toml` with your settings
3. **Start conservative**: `fail_on = "error"` initially
4. **Expand gradually**: Add more file types, consider warning-as-fail
5. **Allowlist false positives**: `dcg allow <rule_id> -r "reason" --project`
6. **Add CI enforcement**: Scan PR diffs in GitHub Actions/GitLab CI



================================================
FILE: docs/security-model.md
================================================
# Security Model: Interactive Mode

This document defines the threat model and security safeguards for dcg's interactive mode, which allows users to allowlist blocked commands through terminal interaction.

## Executive Summary

Interactive mode introduces a security-critical attack surface: if an AI agent can programmatically respond to interactive prompts, dcg's protection becomes ineffective. This document specifies a **dual-factor verification system** combining random verification codes with timing constraints to ensure only human users can bypass blocks.

---

## Threat Model

### Primary Threat: AI Agent Bypass

**Attack scenario:**
1. AI coding agent (Claude, GPT, Codex, etc.) issues a destructive command
2. dcg blocks the command and presents an interactive prompt
3. A malicious prompt injection causes the agent to respond automatically
4. The agent sends the required keystrokes to bypass the block
5. dcg's protection is defeated

**Why this matters:**
- dcg exists specifically to protect users from AI agent mistakes
- If agents can bypass dcg, the tool provides no security value
- Prompt injection attacks are a known vector for manipulating AI agents
- The attack requires no special privilegesâ€”just stdin/stdout access

### Threat Actors

| Actor | Capability | Motivation |
|-------|------------|------------|
| Malicious prompt injection | Control agent responses | Cause damage, exfiltrate data |
| Compromised context | Inject instructions via files | Bypass safety controls |
| Adversarial user | Craft prompts to bypass dcg | Intentional destructive actions |

### Trust Boundaries

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User's Terminal                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   AI Agent  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚     dcg     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   Shell   â”‚ â”‚
â”‚  â”‚  (untrusted)â”‚       â”‚  (trusted)  â”‚       â”‚ (trusted) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                    â”‚                              â”‚
â”‚         â–¼                    â–¼                              â”‚
â”‚    stdin/stdout         Interactive                         â”‚
â”‚    (controllable)       prompt (target)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The critical boundary is between dcg's interactive prompt and the AI agent's ability to send input. Any verification mechanism must ensure that only a human can successfully respond.

---

## Safeguard Analysis

### Option 1: Random Verification Code

```
âš ï¸  Command blocked: rm -rf ./src

To allowlist this command, type the verification code: 7x3k
>
```

**How it works:**
- Generate a random alphanumeric code each time
- User must type the exact code to proceed
- Code changes on each block event

**Security analysis:**

| Factor | Assessment |
|--------|------------|
| Brute force resistance | 4 chars (a-z, 0-9) = 1,679,616 combinations |
| Replay resistance | Code changes each time |
| OCR resistance | Lowâ€”advanced agents could theoretically OCR |
| Automation resistance | Highâ€”cannot pre-script the response |

**Strengths:**
- Simple to implement and understand
- High entropy prevents guessing
- Each attempt requires a new code

**Weaknesses:**
- A sufficiently advanced agent with vision capabilities could read the code
- Does not prevent automated timing attacks

**Verdict:** Strong but not sufficient alone.

### Option 2: Timeout Requirement

```
âš ï¸  Command blocked: rm -rf ./src

Press 'a' within 3 seconds to allowlist...
[3] [2] [1] - Timeout, command remains blocked
```

**How it works:**
- Short window for response (3-5 seconds)
- Countdown displayed to user
- Must respond within window

**Security analysis:**

| Factor | Assessment |
|--------|------------|
| Human reaction time | ~200-500ms typical, easily within window |
| Agent timing | Can potentially time responses programmatically |
| Automation resistance | Mediumâ€”timing can be scripted |

**Strengths:**
- Adds temporal constraint
- Humans can easily respond in time
- Prevents slow automated analysis

**Weaknesses:**
- Agents can potentially time their responses
- Does not prevent fast automated responses

**Verdict:** Useful as a secondary factor but not secure alone.

### Option 3: Full Command Retype

```
âš ï¸  Command blocked: rm -rf ./src

To allowlist, retype the full command:
> rm -rf ./src
```

**How it works:**
- User must retype the exact blocked command
- Character-by-character verification
- Forces acknowledgment of what will execute

**Security analysis:**

| Factor | Assessment |
|--------|------------|
| Automation resistance | Very highâ€”agent would need to echo dangerous command |
| User experience | Poor for long commands |
| Error potential | Highâ€”typos require retry |

**Strengths:**
- Forces explicit acknowledgment
- Very difficult for agents to automate safely
- Makes users think about what they're allowing

**Weaknesses:**
- Tedious for complex commands
- May frustrate legitimate users
- Typo-prone

**Verdict:** Highest security but poor UX. Consider as optional "paranoid mode."

### Option 4: Math/CAPTCHA Challenge

```
âš ï¸  Command blocked: rm -rf ./src

What is 7 + 3?
> 10
```

**Security analysis:**

| Factor | Assessment |
|--------|------------|
| LLM resistance | Noneâ€”trivial for any LLM to solve |
| Human UX | Good |
| Bot resistance | Traditional bots blocked, LLMs not |

**Verdict:** Ineffective against AI agents. Do not use.

### Option 5: Semantic Verification

```
âš ï¸  Command blocked: rm -rf ./src

Explain what this command does to confirm you understand:
> [free-form response analyzed for understanding]
```

**Security analysis:**
- Requires NLP to evaluate responses
- LLMs excel at generating plausible explanations
- Adds significant complexity

**Verdict:** Ineffective and overly complex. Do not use.

---

## Recommended Design: Dual-Factor Verification

Based on the analysis above, the recommended approach combines **random verification codes** with **timeout constraints**:

### Mechanism

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  BLOCKED: rm -rf ./src                                        â•‘
â•‘                                                                  â•‘
â•‘  Reason: Recursive forced deletion                               â•‘
â•‘  Rule: core.filesystem:rm-rf-general                             â•‘
â•‘                                                                  â•‘
â•‘  To allowlist, type this code within 5 seconds: 7x3k            â•‘
â•‘  [5] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   â•‘
â•‘                                                                  â•‘
â•‘  > _                                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Security Properties

1. **Randomness:** Code is cryptographically random, unpredictable
2. **Timing:** Response must occur within timeout window
3. **Freshness:** Code expires after timeout or single use
4. **Uniqueness:** Each block event generates a new code

### Why This Works

| Attack Vector | Mitigation |
|---------------|------------|
| Pre-scripted bypass | Code is random, cannot be predicted |
| Slow automated analysis | Timeout prevents lengthy computation |
| Replay attack | Code is single-use and time-limited |
| Brute force | Limited attempts within timeout |
| Simple bots | Cannot parse terminal output reliably |

### What This Does NOT Prevent

- Advanced multi-modal agents with vision + fast response capability
- Humans intentionally bypassing protections
- Physical access to the terminal

These are considered out-of-scope. The goal is to prevent *automated* bypass by standard AI coding agents, not to prevent all possible bypass scenarios.

---

## Specification

### Verification Code Generation

```rust
/// Generate a cryptographically secure verification code.
///
/// Properties:
/// - Characters: lowercase a-z and digits 0-9 (36 symbols)
/// - Length: configurable (default 4)
/// - Entropy: 4 chars = ~20.7 bits, 6 chars = ~31 bits
fn generate_verification_code(length: usize) -> String {
    use rand::Rng;
    const CHARSET: &[u8] = b"abcdefghijklmnopqrstuvwxyz0123456789";
    let mut rng = rand::thread_rng();
    (0..length)
        .map(|_| CHARSET[rng.gen_range(0..CHARSET.len())] as char)
        .collect()
}
```

### Timeout Behavior

1. Display code and start countdown
2. Read user input with timeout
3. On timeout: deny and exit
4. On input: validate code, then proceed or deny

### Input Validation

- Case-insensitive comparison (reduce typo frustration)
- Trim whitespace from input
- Single attempt per code (no retries with same code)
- On failure: generate new code, restart timeout

### Configuration

```toml
# ~/.config/dcg/config.toml

[interactive]
# Master switch for interactive mode
enabled = true

# Verification method: "code", "command", or "none"
# - code: Random verification code (recommended)
# - command: Full command retype (paranoid mode)
# - none: Single keypress (NOT RECOMMENDED - vulnerable)
verification = "code"

# Timeout in seconds (1-30, default 5)
timeout_seconds = 5

# Verification code length (4-8, default 4)
code_length = 4

# Allow fallback to non-interactive when stdin is not a tty
# When true: non-tty stdin causes immediate block (default)
# When false: error if stdin is not a tty
allow_non_tty_fallback = true

# Maximum attempts before lockout (1-10, default 3)
max_attempts = 3

# Lockout duration in seconds after max attempts (0 = no lockout)
lockout_seconds = 60
```

### Allowlist Scopes

When a command is allowlisted via interactive mode:

| Scope | Duration | Effect |
|-------|----------|--------|
| Once | Single execution | Command allowed this one time |
| Session | Until dcg process exits | Command allowed repeatedly |
| Temporary | 24 hours | Command allowed for 24 hours |
| Permanent | Indefinite | Added to allowlist file |

User selects scope after successful verification:

```
Verification successful!

Allowlist scope for this command:
  [o] Once (this execution only)
  [s] Session (until you close this terminal)
  [t] Temporary (24 hours)
  [p] Permanent (add to project allowlist)

Choice: _
```

---

## Implementation Requirements

### R1: Secure Random Generation

- MUST use cryptographically secure RNG (`rand::thread_rng()` or better)
- MUST NOT use predictable seeds (time-based, PID-based, etc.)

### R2: Constant-Time Comparison

- MUST use constant-time string comparison to prevent timing attacks
- Example: `subtle::ConstantTimeEq` or equivalent

### R3: TTY Detection

- MUST detect if stdin is a TTY
- If not a TTY: immediate block (agent cannot interact safely)
- This is a critical security check

### R4: Timeout Enforcement

- MUST enforce timeout on input reads
- MUST handle interrupt signals gracefully
- MUST NOT allow timeout bypass via signal manipulation

### R5: Visual Feedback

- MUST display countdown to user
- MUST clear/overwrite code after timeout (prevent lingering display)
- SHOULD use terminal colors for visibility (red for warning, etc.)

### R6: Audit Logging

- MUST log all interactive bypass attempts (success and failure)
- Log format: timestamp, command, code (hash only), result, TTY info
- Logs enable detection of automated bypass attempts

---

## Testing Requirements

### Unit Tests

| Test Case | Expected Behavior |
|-----------|------------------|
| Code generation | Correct length, valid characters |
| Timeout expires | Command blocked |
| Correct code in time | Command allowed |
| Incorrect code | New code generated, retry allowed |
| Non-TTY stdin | Immediate block, no prompt |
| Max attempts exceeded | Lockout triggered |

### Integration Tests

| Scenario | Expected Behavior |
|----------|------------------|
| Human user flow | Successful allowlist |
| Piped input (simulated agent) | Immediate block |
| Timeout edge cases | Graceful handling |
| Config variations | Respect all settings |

### Security Tests

| Test | Purpose |
|------|---------|
| RNG quality | Verify code randomness |
| Timing analysis | Verify constant-time comparison |
| TTY spoofing | Verify TTY detection robustness |

---

## Future Considerations

### Multi-Modal Agent Defense

As AI agents gain vision capabilities (screenshots, OCR), the verification code approach may become vulnerable. Future enhancements could include:

1. **Animated codes:** Code changes mid-display, requiring continuous attention
2. **Audio verification:** Speak a code that the user types
3. **Hardware tokens:** U2F/FIDO2 for high-security environments

These are not currently implemented but may be added if the threat landscape evolves.

### Honeypot Detection

Consider adding detectable "honeypot" patterns that agents might try to exploit:

```
# Fake easy bypass that logs attempt
Press 'y' to allow:
[Logged: automated bypass attempt detected]
```

This enables detection of compromised agents without providing actual bypass capability.

---

## Related Documents

- [docs/security.md](security.md) â€” Heredoc detection security model
- [docs/allow-once-usage.md](allow-once-usage.md) â€” Allow-once workflow documentation
- [docs/configuration.md](configuration.md) â€” Configuration reference

---

## Changelog

| Date | Change |
|------|--------|
| 2026-01-19 | Initial design document created |



================================================
FILE: docs/security.md
================================================
# Security Notes: Heredoc Detection

This document describes the threat model, assumptions, and incident response
for heredoc and inline-script scanning.

## Threat Model

Heredoc scanning is designed to catch destructive operations hidden inside
embedded scripts, including:

- Heredocs: `<<EOF ... EOF`
- Here-strings: `<<< "..."`
- Inline interpreter flags: `python -c`, `bash -c`, `node -e`
- Piped scripts: `cat <<EOF | bash`

The goal is to prevent accidental or automated destructive actions that the
outer command does not reveal.

## What It Protects Against

- Destructive filesystem commands inside scripts (for example, recursive delete)
- Destructive git operations embedded in scripts (for example, `git reset --hard`)
- Shell execution helpers in scripting languages (for example, `os.system`,
  `child_process.execSync`, `Kernel.system`)

## Out of Scope

- General malware detection
- Exploits that do not rely on heredocs or inline script payloads
- Non-shell destructive operations outside the supported language set
- Arbitrary interpreter behavior that is not represented in the AST patterns

These limits keep runtime overhead small and false positives manageable.

## Fail-Open Behavior

In hook mode, heredoc scanning is **fail-open** by design:

- Parse errors or timeouts result in ALLOW
- Unknown languages result in ALLOW

This prevents the hook from breaking legitimate workflows. Diagnostic markers
are emitted so that `dcg explain` or logs can surface the failure.

## Performance Budgets

The heredoc pipeline is strictly bounded:

- Tier 1 trigger: <100us
- Tier 2 extraction: <1ms typical, 50ms max
- Tier 3 AST match: <5ms typical, 20ms max

When budgets are exceeded, the system fails open and records a diagnostic.

## Bypass Considerations

Heredoc scanning is not intended to be a perfect malware detector. Known
limitations include:

- Obfuscated payloads that evade AST parsing or use unsupported languages
- Dynamic command construction that cannot be resolved to literal payloads
- Non-standard interpreters or runtime-generated code

Mitigations:

- Favor stable rule IDs and allowlisting for known-safe cases
- Keep patterns narrowly scoped to avoid broad false positives
- Expand language support and pattern coverage based on real-world feedback

## Incident Response

### If a safe command is blocked

1. Run `dcg explain` on the command or use the printed rule ID.
2. Add a scoped allowlist entry with a reason.
3. Consider reducing scope (project allowlist vs user/system allowlist).

### If a dangerous command is allowed

1. Capture the command text and environment context.
2. File a security issue with the rule ID or gap description.
3. Add or refine a heredoc pattern and tests.

## Reporting

Security issues should be reported via GitHub issues with:

- The command and any heredoc payload (redacted as needed)
- The language detected (if any)
- The observed behavior (blocked or allowed)
- Expected behavior and rationale




================================================
FILE: docs/tier-dependency-strategy.md
================================================
# Tier Dependency Strategy Rationale

This note explains why pack implementation follows strict tier ordering and
when exceptions are allowed.

## Current Structure

```
Tier 1 (P0) - Critical Security Gaps
    â†“ (blocks)
Tier 2 (P1) - High Value
    â†“ (blocks)
Tier 3 (P2) - Valuable
```

## Why Strict Sequential Dependencies

### Arguments FOR strict ordering
1. **Quality gates**: Tier 1 completion ensures critical security coverage first.
2. **Testing validation**: Tier 1 forces the testing infrastructure to mature early.
3. **Pattern refinement**: Lessons from Tier 1 inform Tier 2/3 patterns.
4. **Focus**: Prevents spreading effort across 57 packs simultaneously.
5. **Confidence**: A fully tested Tier 1 builds trust in the guardrail.

### Arguments AGAINST strict ordering
1. **Flexibility**: Teams may need Tier 2/3 packs earlier.
2. **Bottleneck risk**: One slow pack can block all downstream work.
3. **Parallelization**: Multiple teams could deliver more in parallel.

## Decision: Keep Strict Ordering

**Rationale**: This is a safety-critical system. Quality and test depth outweigh
the flexibility costs. It is better to ship 20 fully tested packs than 57
partially validated ones.

## Escape Hatch (Documented Exception)

If a specific Tier 2/3 pack is urgently needed:
1. Create a separate task with elevated priority.
2. Document the business justification.
3. Ensure full testing before merge.
4. Do not count it toward tier completion.

## Review Point

After Tier 1 completion, re-evaluate:
- Did strict ordering help or hinder?
- Should Tier 2/3 be partially parallelized?
- What process improvements are needed?



================================================
FILE: docs/troubleshooting.md
================================================
# Troubleshooting Guide

Common issues and how to resolve them.

## dcg is not blocking anything

1. Confirm the hook is installed correctly.
2. Ensure the dcg binary is on PATH.
3. Verify config loading (project/user/system) and pack enablement.

If available, run:
- `dcg doctor` for a structured diagnostics report.

## Packs are not enabled

Check your config files in order:
- `.dcg.toml` (project)
- `~/.config/dcg/config.toml` (user)
- `/etc/dcg/config.toml` (system)

Also verify environment overrides:
- `DCG_PACKS`
- `DCG_DISABLE`

## False positives (safe command blocked)

1. Add a safe allowlist entry (project or user).
2. If recurring, file a bug report with the exact command.
3. Add a test case to prevent regressions.

## False negatives (dangerous command allowed)

1. File a bug report with the exact command and context.
2. Add a destructive pattern + test case.
3. Update the packâ€™s safe pattern list to avoid over-broad allow rules.

## Hook errors or timeouts

For heredoc or large script parsing:
- Lower `max_body_bytes` or `max_body_lines`.
- Increase `timeout_ms` if needed.
- Ensure `fallback_on_parse_error` is true for hook mode.

## Performance concerns

If hook latency is high:
- Reduce enabled pack count.
- Disable expensive packs temporarily.
- Capture performance logs and open an issue.

## Reporting issues

When filing a report, include:
- The exact command
- Expected vs actual decision
- Your enabled packs list
- Relevant config snippets (redact secrets)



================================================
FILE: docs/architecture/pack-design.md
================================================
# Pack Architecture Decisions

This document captures the architectural decisions required before expanding
pack coverage. It is the canonical reference for pack authors and reviewers.

## 1) REST API Pattern Detection (curl/httpie)

**Decision**: Hybrid detection (keyword gate + lightweight argument parsing).

- **Gate** on `curl`, `http`, or `httpie` keywords to avoid touching every command.
- **Parse** method flags (`-X`, `--request`, `--method`) and extract the URL.
- **Pack-specific host filters**: each pack owns its hostnames or URL prefixes.
- **Decision rule**: only treat `DELETE` (and other explicitly destructive methods)
  as destructive when the host/path match a pack.

**Rationale**: A pure keyword scan is too noisy; full AST parsing is too slow.
The hybrid approach is fast, deterministic, and maintainable.

## 2) Pack Overlap Resolution

**Decision**: Keep packs separate but clarify boundaries.

From `git_safety_guard-qdhh`: `cicd.github_actions` is for CI operations
(secrets, variables, workflows, runs). `platform.github` is for broader platform
operations (repos, releases, deploy keys, webhooks, collaborators). Do not
duplicate patterns across packs; document scope in pack descriptions.

**Rationale**: Separation reduces regex scope and allows users to enable only
what they need. Clear boundaries avoid duplication and false positives.

## 3) Command Alias Handling

**Decision**: Explicit aliases for high-impact, common tools plus opt-in config.

- Include **well-known aliases** in keywords (e.g., `k` for `kubectl`).
- Avoid regex alias heuristics that cause false positives.
- Allow **user config** to add custom aliases via pack enablement/keywords.

**Rationale**: Minimizes noise while still covering common shortcuts.

## 4) Performance Budget Per Pack

**Decision**: Enforce a per-pack budget and pattern cap.

- **Budget**: < 500 microseconds per pack evaluation.
- **Pattern cap**: < 50 total patterns per pack.
- **Keywords**: minimal and specific; avoid broad single-letter keywords.

**Rationale**: Keeps pack expansion from degrading hook latency.

## 5) Safe vs Destructive Threshold

**Decision**: Flag-aware matching with explicit safe overrides.

- **Destructive by default**: commands known to delete or destroy data (e.g.,
  `rclone sync`, `aws s3 rm --recursive`) should be blocked even without flags.
- **Flag-sensitive**: allow **dry-run/preview** flags and safe variants.
- **Ambiguous commands**: only block when flags or subcommands are clearly
  destructive; otherwise allow with high-signal patterns.

**Rationale**: Reduces false positives while still blocking dangerous actions.

## Acceptance Criteria Mapping

- Decisions documented with rationale (this doc).
- Performance budget defined and referenced by pack checklist.
- Pack overlap resolution aligned with `git_safety_guard-qdhh`.

## Open Questions

- Which alias list should be system defaults vs per-user config?
- How to represent host allowlists for REST APIs in pack metadata?



================================================
FILE: docs/design/rule-metrics-struct-mapping.md
================================================
# Rule-Level Metrics: Struct Mapping & Reuse Strategy

> Design document for `git_safety_guard-1dri.1`
>
> This document inventories existing history analytics structs and maps rule-level
> metrics needs to them, ensuring no duplicate or competing analytics pipelines.

---

## Executive Summary

**Finding:** The existing history analytics structs in `src/history/schema.rs` are
well-designed and sufficient for rule-level metrics. No new analytics structs are
needed. The `PatternEffectiveness` struct already captures per-rule metrics, and
the `rule_id` field in `CommandEntry` provides stable rule identifiers.

**Recommendation:** Reuse existing structs. Extend query/aggregation logic only.

---

## Struct Inventory

### Core Data Types

| Struct | Location | Purpose | Rule-Metrics Relevance |
|--------|----------|---------|------------------------|
| `CommandEntry` | L133 | Single command record | **Primary data source** - contains `rule_id`, `pack_id`, `pattern_name`, `outcome` |
| `Outcome` | L81 | Enum: Allow/Deny/Warn/Bypass | Categorizes command outcomes for metrics |

### Statistics Types

| Struct | Location | Purpose | Rule-Metrics Relevance |
|--------|----------|---------|------------------------|
| `OutcomeStats` | L230 | Aggregate counts (allowed/denied/warned/bypassed) | Can aggregate by rule |
| `PerformanceStats` | L239 | Latency percentiles (p50/p95/p99/max) | Could extend for per-rule latency |
| `PatternStat` | L248 | Pattern name + count + pack_id | **Direct reuse** for top patterns |
| `HistoryStats` | L325 | Complete stats for time window | Contains `top_patterns: Vec<PatternStat>` |
| `StatsTrends` | L271 | Period-over-period comparison | Extendable for rule trends |

### Analytics Types (Key for Rule-Metrics)

| Struct | Location | Purpose | Rule-Metrics Relevance |
|--------|----------|---------|------------------------|
| `PatternEffectiveness` | L2177 | Per-pattern metrics with bypass analysis | **PERFECT FIT** - use directly |
| `PotentialGap` | L2195 | Dangerous commands that were allowed | Coverage gap analysis |
| `RecommendationType` | L2208 | Enum: RelaxPattern/EnablePack/etc. | Tuning recommendations |
| `PackRecommendation` | L2225 | Actionable recommendation with config | Extend for rule-specific recs |
| `PackEffectivenessAnalysis` | L2246 | Complete analysis result | Already groups by pattern |

---

## Rule Identifier Design

The `rule_id` is already defined in `CommandEntry`:

```rust
/// Stable rule identifier: `pack_id:pattern_name`
/// Present only for denied commands that matched a pattern.
/// Format: "core.git:reset-hard", "core.filesystem:rm-rf-root"
pub rule_id: Option<String>,
```

**Key methods in `CommandEntry`:**
- `compute_rule_id()` â†’ Constructs `pack_id:pattern_name`
- `get_rule_id()` â†’ Returns stored or computed value
- `ensure_rule_id()` â†’ Sets `rule_id` if computable

This provides stable, human-readable identifiers for:
- Allowlisting specific rules
- Aggregating metrics per rule
- Tracking rule effectiveness over time

---

## PatternEffectiveness: The Core Struct

This struct is the foundation for rule-level metrics:

```rust
pub struct PatternEffectiveness {
    /// Pattern name (e.g., "reset-hard")
    pub pattern: String,
    /// Pack ID the pattern belongs to (e.g., "core.git")
    pub pack_id: Option<String>,
    /// Total times this pattern triggered (deny + bypass)
    pub total_triggers: u64,
    /// Times the pattern blocked a command (deny)
    pub denied_count: u64,
    /// Times the pattern was bypassed (allow-once)
    pub bypassed_count: u64,
    /// Bypass rate as a percentage (0.0-100.0)
    pub bypass_rate: f64,
}
```

**Mapping to rule_id:** `rule_id = {pack_id}:{pattern}`

**Already computed in `PackEffectivenessAnalysis`:**
- `high_value_patterns: Vec<PatternEffectiveness>` - High volume, low bypass
- `potentially_aggressive: Vec<PatternEffectiveness>` - High bypass rate

---

## Reuse vs Extend Analysis

### Direct Reuse (No Changes)

| Struct | Usage |
|--------|-------|
| `CommandEntry` | Query by `rule_id` for per-rule history |
| `PatternEffectiveness` | Per-rule metrics with bypass analysis |
| `PatternStat` | Simple name+count for top rules |
| `OutcomeStats` | Aggregate outcomes per rule |

### Extend (Add Fields/Methods)

| Struct | Extension | Reason |
|--------|-----------|--------|
| `PatternEffectiveness` | Add `first_seen_ts`, `last_seen_ts` | Track rule activity timeline |
| `PatternEffectiveness` | Add `projects: Vec<String>` | See which projects trigger rule |
| `PackEffectivenessAnalysis` | Add `per_rule_metrics: HashMap<String, PatternEffectiveness>` | Direct rule_id lookup |

### Do NOT Create

To avoid competing pipelines, these should **NOT** be created:

- ~~`RuleMetrics`~~ â†’ Use `PatternEffectiveness`
- ~~`RuleEffectiveness`~~ â†’ Use `PatternEffectiveness`
- ~~`RuleStats`~~ â†’ Use `PatternStat` with pack_id
- ~~`RuleAnalysis`~~ â†’ Use `PackEffectivenessAnalysis`

---

## Query Patterns for Rule-Level Metrics

### Per-Rule Trigger Count

```sql
SELECT rule_id, COUNT(*) as triggers
FROM commands
WHERE rule_id IS NOT NULL
GROUP BY rule_id
ORDER BY triggers DESC;
```

### Per-Rule Bypass Rate

```sql
SELECT rule_id,
       COUNT(*) as total,
       SUM(CASE WHEN outcome = 'deny' THEN 1 ELSE 0 END) as denied,
       SUM(CASE WHEN outcome = 'bypass' THEN 1 ELSE 0 END) as bypassed,
       (bypassed * 100.0 / total) as bypass_rate
FROM commands
WHERE rule_id IS NOT NULL
GROUP BY rule_id;
```

### Rule Activity Over Time

```sql
SELECT rule_id,
       date(timestamp) as day,
       COUNT(*) as triggers
FROM commands
WHERE rule_id IS NOT NULL
GROUP BY rule_id, day
ORDER BY rule_id, day;
```

---

## Implementation Guidance

### For `dcg history stats --rule <rule_id>`

1. Query `commands` table filtered by `rule_id`
2. Compute `OutcomeStats` from results
3. Return `PatternEffectiveness` struct populated from query
4. No new structs needed

### For `dcg history analyze`

The existing `PackEffectivenessAnalysis` already computes `PatternEffectiveness`
for each pattern. To add rule-level access:

1. Add `rule_id` to `PatternEffectiveness` (computed from pack_id + pattern)
2. Add `by_rule_id: HashMap<String, PatternEffectiveness>` to analysis result
3. No new analysis pipeline needed

### For Rule-Specific Recommendations

Extend `PackRecommendation` with:

```rust
/// Rule ID this recommendation targets (if rule-specific)
#[serde(skip_serializing_if = "Option::is_none")]
pub rule_id: Option<String>,
```

---

## Acceptance Criteria Verification

| Criterion | Status | Evidence |
|-----------|--------|----------|
| Rule-metrics design references existing structs | âœ… | Uses `PatternEffectiveness`, `PatternStat`, `CommandEntry` |
| No duplicate analytics pipelines | âœ… | No new `Rule*` structs proposed |
| Clear mapping documented | âœ… | This document |

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-16 | Initial design document |

---

## Related Issues

- **Parent:** `git_safety_guard-1dri` (Rule-Level Metrics: Track per-rule stats)
- **Blocked by:** None
- **Blocks:** `git_safety_guard-1dri.2` (dcg history stats --rule)



================================================
FILE: docs/json-schema/error.json
================================================
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://github.com/Dicklesworthstone/destructive_command_guard/docs/json-schema/error.json",
  "title": "DCG Error Response",
  "description": "JSON error format used by dcg CLI commands when errors occur. Errors are typically written to stderr, but some commands include error fields in their JSON output.",
  "type": "object",
  "oneOf": [
    {
      "title": "CLI Error Output",
      "description": "Standard error output format for CLI commands",
      "type": "object",
      "required": ["error"],
      "properties": {
        "error": {
          "type": "string",
          "description": "Human-readable error message"
        },
        "code": {
          "type": "string",
          "enum": ["parse_error", "config_error", "io_error", "validation_error"],
          "description": "Machine-readable error code for programmatic handling"
        },
        "details": {
          "type": "object",
          "description": "Additional context about the error",
          "properties": {
            "file": {
              "type": "string",
              "description": "File path where the error occurred"
            },
            "line": {
              "type": "integer",
              "description": "Line number where the error occurred"
            },
            "column": {
              "type": "integer",
              "description": "Column number where the error occurred"
            }
          }
        }
      }
    },
    {
      "title": "Simulate Command Error",
      "description": "Error tracking in simulate command JSON output",
      "type": "object",
      "required": ["malformed_count", "ignored_count", "stopped_at_limit"],
      "properties": {
        "malformed_count": {
          "type": "integer",
          "minimum": 0,
          "description": "Number of malformed JSON entries that could not be parsed"
        },
        "ignored_count": {
          "type": "integer",
          "minimum": 0,
          "description": "Number of entries ignored due to filters or unsupported types"
        },
        "stopped_at_limit": {
          "type": "boolean",
          "description": "True if processing stopped early due to reaching error limit"
        }
      }
    },
    {
      "title": "Allowlist Error",
      "description": "Error in allowlist configuration",
      "type": "object",
      "required": ["layer", "path", "message"],
      "properties": {
        "layer": {
          "type": "string",
          "enum": ["project", "user", "system"],
          "description": "Which allowlist layer had the error"
        },
        "path": {
          "type": "string",
          "description": "Path to the allowlist file"
        },
        "entry_index": {
          "type": "integer",
          "minimum": 0,
          "description": "Index of the problematic entry in the allowlist"
        },
        "message": {
          "type": "string",
          "description": "Human-readable error message"
        }
      }
    }
  ],
  "examples": [
    {
      "error": "JSON parse error: expected ':' at line 1 column 15",
      "code": "parse_error"
    },
    {
      "error": "IO error: Permission denied (os error 13)",
      "code": "io_error",
      "details": {
        "file": "/etc/dcg/config.toml"
      }
    },
    {
      "malformed_count": 3,
      "ignored_count": 12,
      "stopped_at_limit": false
    },
    {
      "layer": "project",
      "path": ".dcg/allowlist.toml",
      "entry_index": 5,
      "message": "Invalid rule ID format: missing colon separator"
    }
  ]
}



================================================
FILE: docs/json-schema/hook-output.json
================================================
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://github.com/Dicklesworthstone/destructive_command_guard/docs/json-schema/hook-output.json",
  "title": "DCG Hook Output",
  "description": "JSON output format for dcg when used as a Claude Code PreToolUse hook. Only emitted when a command is denied; allowed commands produce no output.",
  "type": "object",
  "required": ["hookSpecificOutput"],
  "properties": {
    "hookSpecificOutput": {
      "type": "object",
      "description": "The hook-specific output payload for Claude Code",
      "required": ["hookEventName", "permissionDecision", "permissionDecisionReason"],
      "properties": {
        "hookEventName": {
          "type": "string",
          "const": "PreToolUse",
          "description": "The hook event type, always 'PreToolUse' for dcg"
        },
        "permissionDecision": {
          "type": "string",
          "enum": ["allow", "deny"],
          "description": "The permission decision: 'deny' blocks the command, 'allow' permits it"
        },
        "permissionDecisionReason": {
          "type": "string",
          "description": "Human-readable explanation of why the command was blocked, including the rule ID, reason, and remediation instructions"
        },
        "allowOnceCode": {
          "type": "string",
          "description": "Short alphanumeric code for one-time bypass via 'dcg allow-once <code>'",
          "pattern": "^[a-f0-9]{6}$"
        },
        "allowOnceFullHash": {
          "type": "string",
          "description": "Full SHA-256 hash of the command for verification, prefixed with 'sha256:'",
          "pattern": "^sha256:[a-f0-9]{64}$"
        },
        "ruleId": {
          "type": "string",
          "description": "Stable pattern identifier in format 'pack.category:pattern-name' for allowlisting",
          "examples": ["core.git:reset-hard", "core.filesystem:rm-rf-root"]
        },
        "packId": {
          "type": "string",
          "description": "The security pack that matched, in format 'category.name'",
          "examples": ["core.git", "core.filesystem", "database.postgresql"]
        },
        "severity": {
          "type": "string",
          "enum": ["critical", "high", "medium", "low"],
          "description": "Severity level of the blocked command"
        },
        "confidence": {
          "type": "number",
          "minimum": 0.0,
          "maximum": 1.0,
          "description": "Match confidence score from 0.0 to 1.0"
        },
        "remediation": {
          "type": "object",
          "description": "Suggested remediation for the blocked command",
          "required": ["explanation", "allowOnceCommand"],
          "properties": {
            "safeAlternative": {
              "type": "string",
              "description": "A safer alternative command that achieves similar results"
            },
            "explanation": {
              "type": "string",
              "description": "Explanation of why the alternative is safer or what the user should do"
            },
            "allowOnceCommand": {
              "type": "string",
              "description": "The full 'dcg allow-once <code>' command for one-time bypass"
            }
          }
        }
      }
    }
  },
  "examples": [
    {
      "hookSpecificOutput": {
        "hookEventName": "PreToolUse",
        "permissionDecision": "deny",
        "permissionDecisionReason": "BLOCKED by dcg\n\nTip: dcg explain \"git reset --hard HEAD~5\"\n\nReason: git reset --hard destroys uncommitted changes\n\nRule: core.git:reset-hard\n\nCommand: git reset --hard HEAD~5",
        "ruleId": "core.git:reset-hard",
        "packId": "core.git",
        "severity": "critical",
        "confidence": 0.95,
        "allowOnceCode": "a1b2c3",
        "allowOnceFullHash": "sha256:abc123def456abc123def456abc123def456abc123def456abc123def456abc1",
        "remediation": {
          "safeAlternative": "git stash",
          "explanation": "Use git stash to save your changes before resetting.",
          "allowOnceCommand": "dcg allow-once a1b2c3"
        }
      }
    }
  ]
}



================================================
FILE: docs/json-schema/scan-results.json
================================================
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://github.com/Dicklesworthstone/destructive_command_guard/docs/json-schema/scan-results.json",
  "title": "DCG Scan Results",
  "description": "JSON output format for 'dcg scan' command, which scans codebases for potentially destructive commands embedded in scripts, makefiles, and other files.",
  "type": "object",
  "required": ["schema_version", "summary", "findings"],
  "properties": {
    "schema_version": {
      "type": "integer",
      "const": 1,
      "description": "Schema version for forward compatibility"
    },
    "summary": {
      "type": "object",
      "description": "Aggregated statistics for the scan",
      "required": ["files_scanned", "files_skipped", "commands_extracted", "findings_total", "decisions", "severities", "max_findings_reached"],
      "properties": {
        "files_scanned": {
          "type": "integer",
          "minimum": 0,
          "description": "Number of files successfully scanned"
        },
        "files_skipped": {
          "type": "integer",
          "minimum": 0,
          "description": "Number of files skipped (binary, too large, permission denied)"
        },
        "commands_extracted": {
          "type": "integer",
          "minimum": 0,
          "description": "Total number of commands extracted from all files"
        },
        "findings_total": {
          "type": "integer",
          "minimum": 0,
          "description": "Total number of findings (warn + deny)"
        },
        "decisions": {
          "type": "object",
          "description": "Breakdown of findings by decision type",
          "required": ["allow", "warn", "deny"],
          "properties": {
            "allow": {
              "type": "integer",
              "minimum": 0,
              "description": "Commands that passed all checks"
            },
            "warn": {
              "type": "integer",
              "minimum": 0,
              "description": "Commands flagged as potentially dangerous but not blocked"
            },
            "deny": {
              "type": "integer",
              "minimum": 0,
              "description": "Commands that would be blocked by dcg"
            }
          }
        },
        "severities": {
          "type": "object",
          "description": "Breakdown of findings by severity level",
          "required": ["info", "warning", "error"],
          "properties": {
            "info": {
              "type": "integer",
              "minimum": 0,
              "description": "Informational findings (low severity)"
            },
            "warning": {
              "type": "integer",
              "minimum": 0,
              "description": "Warning-level findings (medium severity)"
            },
            "error": {
              "type": "integer",
              "minimum": 0,
              "description": "Error-level findings (high/critical severity)"
            }
          }
        },
        "max_findings_reached": {
          "type": "boolean",
          "description": "True if scan stopped early due to reaching the maximum findings limit"
        },
        "elapsed_ms": {
          "type": "integer",
          "minimum": 0,
          "description": "Total scan duration in milliseconds"
        }
      }
    },
    "findings": {
      "type": "array",
      "description": "List of individual findings",
      "items": {
        "type": "object",
        "required": ["file", "line", "extractor_id", "extracted_command", "decision", "severity"],
        "properties": {
          "file": {
            "type": "string",
            "description": "Relative path to the file containing the finding"
          },
          "line": {
            "type": "integer",
            "minimum": 1,
            "description": "Line number where the command was found (1-indexed)"
          },
          "col": {
            "type": "integer",
            "minimum": 1,
            "description": "Column number where the command starts (1-indexed)"
          },
          "extractor_id": {
            "type": "string",
            "description": "Identifier for the extractor that found this command",
            "examples": ["shell_script", "makefile", "dockerfile", "github_actions", "heredoc"]
          },
          "extracted_command": {
            "type": "string",
            "description": "The actual command text that was extracted and evaluated"
          },
          "decision": {
            "type": "string",
            "enum": ["Allow", "Warn", "Deny"],
            "description": "The evaluation decision for this command"
          },
          "severity": {
            "type": "string",
            "enum": ["Info", "Warning", "Error"],
            "description": "Severity level of the finding"
          },
          "rule_id": {
            "type": "string",
            "description": "The pattern rule ID that matched, if any",
            "examples": ["core.git:reset-hard", "core.filesystem:rm-rf-general"]
          },
          "reason": {
            "type": "string",
            "description": "Human-readable explanation of why the command was flagged"
          },
          "suggestion": {
            "type": "string",
            "description": "Suggested remediation or safer alternative"
          }
        }
      }
    }
  },
  "examples": [
    {
      "schema_version": 1,
      "summary": {
        "files_scanned": 42,
        "files_skipped": 3,
        "commands_extracted": 128,
        "findings_total": 5,
        "decisions": {
          "allow": 123,
          "warn": 2,
          "deny": 3
        },
        "severities": {
          "info": 0,
          "warning": 2,
          "error": 3
        },
        "max_findings_reached": false,
        "elapsed_ms": 156
      },
      "findings": [
        {
          "file": "scripts/deploy.sh",
          "line": 45,
          "col": 5,
          "extractor_id": "shell_script",
          "extracted_command": "rm -rf /var/cache/*",
          "decision": "Deny",
          "severity": "Error",
          "rule_id": "core.filesystem:rm-rf-general",
          "reason": "rm -rf outside temp directories can cause data loss",
          "suggestion": "Consider using 'rm -rf /tmp/*' for temporary files only"
        }
      ]
    }
  ]
}



================================================
FILE: docs/json-schema/stats-output.json
================================================
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://github.com/Dicklesworthstone/destructive_command_guard/docs/json-schema/stats-output.json",
  "title": "DCG Statistics Output",
  "description": "JSON output format for 'dcg stats' command, which displays aggregated statistics from dcg log files over a configurable time period.",
  "type": "object",
  "required": ["period_start", "period_end", "total_entries", "total_blocks", "total_allows", "total_bypasses", "total_warns", "by_pack"],
  "properties": {
    "period_start": {
      "type": "integer",
      "minimum": 0,
      "description": "Unix timestamp (seconds since epoch) for the start of the statistics period"
    },
    "period_end": {
      "type": "integer",
      "minimum": 0,
      "description": "Unix timestamp (seconds since epoch) for the end of the statistics period"
    },
    "total_entries": {
      "type": "integer",
      "minimum": 0,
      "description": "Total number of log entries processed in this period"
    },
    "total_blocks": {
      "type": "integer",
      "minimum": 0,
      "description": "Total number of commands blocked (denied without allowlist override)"
    },
    "total_allows": {
      "type": "integer",
      "minimum": 0,
      "description": "Total number of commands allowed (passed all checks)"
    },
    "total_bypasses": {
      "type": "integer",
      "minimum": 0,
      "description": "Total number of commands that were bypassed via allowlist or DCG_BYPASS"
    },
    "total_warns": {
      "type": "integer",
      "minimum": 0,
      "description": "Total number of commands that triggered warnings"
    },
    "by_pack": {
      "type": "array",
      "description": "Statistics broken down by security pack, sorted by block count descending",
      "items": {
        "type": "object",
        "required": ["pack_id", "blocks", "allows", "bypasses", "warns"],
        "properties": {
          "pack_id": {
            "type": "string",
            "description": "The security pack identifier",
            "examples": ["core.git", "core.filesystem", "database.postgresql", "unknown"]
          },
          "blocks": {
            "type": "integer",
            "minimum": 0,
            "description": "Number of commands blocked by this pack"
          },
          "allows": {
            "type": "integer",
            "minimum": 0,
            "description": "Number of commands allowed by this pack"
          },
          "bypasses": {
            "type": "integer",
            "minimum": 0,
            "description": "Number of commands bypassed for this pack"
          },
          "warns": {
            "type": "integer",
            "minimum": 0,
            "description": "Number of warnings from this pack"
          }
        }
      }
    }
  },
  "examples": [
    {
      "period_start": 1704672000,
      "period_end": 1707264000,
      "total_entries": 150,
      "total_blocks": 23,
      "total_allows": 120,
      "total_bypasses": 5,
      "total_warns": 2,
      "by_pack": [
        {
          "pack_id": "core.git",
          "blocks": 15,
          "allows": 80,
          "bypasses": 3,
          "warns": 1
        },
        {
          "pack_id": "core.filesystem",
          "blocks": 8,
          "allows": 40,
          "bypasses": 2,
          "warns": 1
        }
      ]
    }
  ]
}



================================================
FILE: docs/packs/README.md
================================================
# Pack Reference Documentation

This directory contains detailed reference documentation for all dcg packs.

## Quick Start

Enable packs in `~/.config/dcg/config.toml`:

```toml
[packs]
enabled = ["kubernetes", "database", "containers"]
```

## Categories

| Category | Packs | Description |
|----------|-------|-------------|
| [apigateway](apigateway.md) | 3 | AWS API Gateway, Kong API Gateway, Google Apigee |
| [backup](backup.md) | 4 | BorgBackup, Rclone, Restic, ... |
| [cdn](cdn.md) | 3 | Cloudflare Workers, Fastly CDN, AWS CloudFront |
| [cicd](cicd.md) | 4 | GitHub Actions, GitLab CI, Jenkins, ... |
| [cloud](cloud.md) | 3 | AWS CLI, Google Cloud SDK, Azure CLI |
| [containers](containers.md) | 3 | Docker, Docker Compose, Podman |
| [core](core.md) | 2 | Core Git, Core Filesystem |
| [database](database.md) | 5 | PostgreSQL, MySQL/MariaDB, MongoDB, ... |
| [dns](dns.md) | 3 | Cloudflare DNS, AWS Route53, Generic DNS Tools |
| [email](email.md) | 4 | AWS SES, SendGrid, Mailgun, ... |
| [featureflags](featureflags.md) | 4 | Flipt, LaunchDarkly, Split.io, ... |
| [infrastructure](infrastructure.md) | 3 | Terraform, Ansible, Pulumi |
| [kubernetes](kubernetes.md) | 3 | kubectl, Helm, Kustomize |
| [loadbalancer](loadbalancer.md) | 4 | HAProxy, nginx, Traefik, ... |
| [messaging](messaging.md) | 4 | Apache Kafka, RabbitMQ, NATS, ... |
| [monitoring](monitoring.md) | 5 | Splunk, Datadog, PagerDuty, ... |
| [package_managers](package_managers.md) | 1 | Package Managers |
| [payment](payment.md) | 3 | Stripe, Braintree, Square |
| [platform](platform.md) | 2 | GitHub Platform, GitLab Platform |
| [remote](remote.md) | 3 | rsync, ssh, scp |
| [search](search.md) | 4 | Elasticsearch, OpenSearch, Algolia, ... |
| [secrets](secrets.md) | 4 | HashiCorp Vault, AWS Secrets Manager, 1Password CLI, ... |
| [storage](storage.md) | 4 | AWS S3, Google Cloud Storage, MinIO, ... |
| [strict_git](strict_git.md) | 1 | Strict Git |
| [system](system.md) | 3 | Disk Operations, Permissions, Services |

## All Pack IDs

- [`core.git`](core.md#coregit)
- [`core.filesystem`](core.md#corefilesystem)
- [`storage.s3`](storage.md#storages3)
- [`storage.gcs`](storage.md#storagegcs)
- [`storage.minio`](storage.md#storageminio)
- [`storage.azure_blob`](storage.md#storageazure_blob)
- [`remote.rsync`](remote.md#remotersync)
- [`remote.ssh`](remote.md#remotessh)
- [`remote.scp`](remote.md#remotescp)
- [`cicd.github_actions`](cicd.md#cicdgithub_actions)
- [`cicd.gitlab_ci`](cicd.md#cicdgitlab_ci)
- [`cicd.jenkins`](cicd.md#cicdjenkins)
- [`cicd.circleci`](cicd.md#cicdcircleci)
- [`secrets.vault`](secrets.md#secretsvault)
- [`secrets.aws_secrets`](secrets.md#secretsaws_secrets)
- [`secrets.onepassword`](secrets.md#secretsonepassword)
- [`secrets.doppler`](secrets.md#secretsdoppler)
- [`platform.github`](platform.md#platformgithub)
- [`platform.gitlab`](platform.md#platformgitlab)
- [`dns.cloudflare`](dns.md#dnscloudflare)
- [`dns.route53`](dns.md#dnsroute53)
- [`dns.generic`](dns.md#dnsgeneric)
- [`email.ses`](email.md#emailses)
- [`email.sendgrid`](email.md#emailsendgrid)
- [`email.mailgun`](email.md#emailmailgun)
- [`email.postmark`](email.md#emailpostmark)
- [`featureflags.flipt`](featureflags.md#featureflagsflipt)
- [`featureflags.launchdarkly`](featureflags.md#featureflagslaunchdarkly)
- [`featureflags.split`](featureflags.md#featureflagssplit)
- [`featureflags.unleash`](featureflags.md#featureflagsunleash)
- [`loadbalancer.haproxy`](loadbalancer.md#loadbalancerhaproxy)
- [`loadbalancer.nginx`](loadbalancer.md#loadbalancernginx)
- [`loadbalancer.traefik`](loadbalancer.md#loadbalancertraefik)
- [`loadbalancer.elb`](loadbalancer.md#loadbalancerelb)
- [`monitoring.splunk`](monitoring.md#monitoringsplunk)
- [`monitoring.datadog`](monitoring.md#monitoringdatadog)
- [`monitoring.pagerduty`](monitoring.md#monitoringpagerduty)
- [`monitoring.newrelic`](monitoring.md#monitoringnewrelic)
- [`monitoring.prometheus`](monitoring.md#monitoringprometheus)
- [`payment.stripe`](payment.md#paymentstripe)
- [`payment.braintree`](payment.md#paymentbraintree)
- [`payment.square`](payment.md#paymentsquare)
- [`messaging.kafka`](messaging.md#messagingkafka)
- [`messaging.rabbitmq`](messaging.md#messagingrabbitmq)
- [`messaging.nats`](messaging.md#messagingnats)
- [`messaging.sqs_sns`](messaging.md#messagingsqs_sns)
- [`search.elasticsearch`](search.md#searchelasticsearch)
- [`search.opensearch`](search.md#searchopensearch)
- [`search.algolia`](search.md#searchalgolia)
- [`search.meilisearch`](search.md#searchmeilisearch)
- [`backup.borg`](backup.md#backupborg)
- [`backup.rclone`](backup.md#backuprclone)
- [`backup.restic`](backup.md#backuprestic)
- [`backup.velero`](backup.md#backupvelero)
- [`database.postgresql`](database.md#databasepostgresql)
- [`database.mysql`](database.md#databasemysql)
- [`database.mongodb`](database.md#databasemongodb)
- [`database.redis`](database.md#databaseredis)
- [`database.sqlite`](database.md#databasesqlite)
- [`containers.docker`](containers.md#containersdocker)
- [`containers.compose`](containers.md#containerscompose)
- [`containers.podman`](containers.md#containerspodman)
- [`kubernetes.kubectl`](kubernetes.md#kuberneteskubectl)
- [`kubernetes.helm`](kubernetes.md#kuberneteshelm)
- [`kubernetes.kustomize`](kubernetes.md#kuberneteskustomize)
- [`cloud.aws`](cloud.md#cloudaws)
- [`cloud.gcp`](cloud.md#cloudgcp)
- [`cloud.azure`](cloud.md#cloudazure)
- [`cdn.cloudflare_workers`](cdn.md#cdncloudflare_workers)
- [`cdn.fastly`](cdn.md#cdnfastly)
- [`cdn.cloudfront`](cdn.md#cdncloudfront)
- [`apigateway.aws`](apigateway.md#apigatewayaws)
- [`apigateway.kong`](apigateway.md#apigatewaykong)
- [`apigateway.apigee`](apigateway.md#apigatewayapigee)
- [`infrastructure.terraform`](infrastructure.md#infrastructureterraform)
- [`infrastructure.ansible`](infrastructure.md#infrastructureansible)
- [`infrastructure.pulumi`](infrastructure.md#infrastructurepulumi)
- [`system.disk`](system.md#systemdisk)
- [`system.permissions`](system.md#systempermissions)
- [`system.services`](system.md#systemservices)
- [`strict_git`](strict_git.md#strict_git)
- [`package_managers`](package_managers.md#package_managers)

## Notes

- Enable a whole category by specifying its prefix (e.g., `kubernetes`).
- Heredoc/inline-script scanning is configured under `[heredoc]`, not `[packs]`.
- See `docs/configuration.md` for full configuration details.

---

*This documentation is auto-generated from PackRegistry metadata.*



================================================
FILE: docs/packs/apigateway.md
================================================
# API Gateway Packs

This document describes packs in the `apigateway` category.

## Packs in this Category

- [AWS API Gateway](#apigatewayaws)
- [Kong API Gateway](#apigatewaykong)
- [Google Apigee](#apigatewayapigee)

---

## AWS API Gateway

**Pack ID:** `apigateway.aws`

Protects against destructive AWS API Gateway CLI operations for both REST APIs and HTTP APIs.

### Keywords

Commands containing these keywords are checked against this pack:

- `aws`
- `apigateway`
- `apigatewayv2`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `apigateway-get-rest-api` | `aws\s+apigateway\s+get-rest-api\b` |
| `apigateway-get-rest-apis` | `aws\s+apigateway\s+get-rest-apis\b` |
| `apigateway-get-resources` | `aws\s+apigateway\s+get-resources\b` |
| `apigateway-get-resource` | `aws\s+apigateway\s+get-resource\b` |
| `apigateway-get-method` | `aws\s+apigateway\s+get-method\b` |
| `apigateway-get-stages` | `aws\s+apigateway\s+get-stages\b` |
| `apigateway-get-stage` | `aws\s+apigateway\s+get-stage\b` |
| `apigateway-get-deployments` | `aws\s+apigateway\s+get-deployments\b` |
| `apigateway-get-deployment` | `aws\s+apigateway\s+get-deployment\b` |
| `apigateway-get-api-keys` | `aws\s+apigateway\s+get-api-keys\b` |
| `apigateway-get-api-key` | `aws\s+apigateway\s+get-api-key\b` |
| `apigateway-get-authorizers` | `aws\s+apigateway\s+get-authorizers\b` |
| `apigateway-get-models` | `aws\s+apigateway\s+get-models\b` |
| `apigateway-get-usage-plans` | `aws\s+apigateway\s+get-usage-plans\b` |
| `apigateway-get-domain-names` | `aws\s+apigateway\s+get-domain-names\b` |
| `apigatewayv2-get-apis` | `aws\s+apigatewayv2\s+get-apis\b` |
| `apigatewayv2-get-api` | `aws\s+apigatewayv2\s+get-api\b` |
| `apigatewayv2-get-routes` | `aws\s+apigatewayv2\s+get-routes\b` |
| `apigatewayv2-get-route` | `aws\s+apigatewayv2\s+get-route\b` |
| `apigatewayv2-get-integrations` | `aws\s+apigatewayv2\s+get-integrations\b` |
| `apigatewayv2-get-integration` | `aws\s+apigatewayv2\s+get-integration\b` |
| `apigatewayv2-get-stages` | `aws\s+apigatewayv2\s+get-stages\b` |
| `apigatewayv2-get-stage` | `aws\s+apigatewayv2\s+get-stage\b` |
| `apigatewayv2-get-authorizers` | `aws\s+apigatewayv2\s+get-authorizers\b` |
| `apigatewayv2-get-domain-names` | `aws\s+apigatewayv2\s+get-domain-names\b` |
| `apigateway-help` | `aws\s+apigateway\s+(?:help\|\-\-help)\b` |
| `apigatewayv2-help` | `aws\s+apigatewayv2\s+(?:help\|\-\-help)\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `apigateway-delete-rest-api` | aws apigateway delete-rest-api permanently removes a REST API and all its resources. | high |
| `apigateway-delete-resource` | aws apigateway delete-resource removes an API resource and its methods. | high |
| `apigateway-delete-method` | aws apigateway delete-method removes an HTTP method from a resource. | high |
| `apigateway-delete-stage` | aws apigateway delete-stage removes a deployment stage from an API. | high |
| `apigateway-delete-deployment` | aws apigateway delete-deployment removes a deployment from an API. | high |
| `apigateway-delete-api-key` | aws apigateway delete-api-key removes an API key. | high |
| `apigateway-delete-authorizer` | aws apigateway delete-authorizer removes an authorizer from an API. | high |
| `apigateway-delete-model` | aws apigateway delete-model removes a model from an API. | high |
| `apigateway-delete-domain-name` | aws apigateway delete-domain-name removes a custom domain name. | high |
| `apigateway-delete-usage-plan` | aws apigateway delete-usage-plan removes a usage plan. | high |
| `apigatewayv2-delete-api` | aws apigatewayv2 delete-api permanently removes an HTTP API. | high |
| `apigatewayv2-delete-route` | aws apigatewayv2 delete-route removes a route from an HTTP API. | high |
| `apigatewayv2-delete-integration` | aws apigatewayv2 delete-integration removes an integration from an HTTP API. | high |
| `apigatewayv2-delete-stage` | aws apigatewayv2 delete-stage removes a stage from an HTTP API. | high |
| `apigatewayv2-delete-authorizer` | aws apigatewayv2 delete-authorizer removes an authorizer from an HTTP API. | high |
| `apigatewayv2-delete-domain-name` | aws apigatewayv2 delete-domain-name removes a custom domain name from an HTTP API. | high |
| `apigatewayv2-delete-route-response` | aws apigatewayv2 delete-route-response removes a route response from an HTTP API. | high |
| `apigatewayv2-delete-integration-response` | aws apigatewayv2 delete-integration-response removes an integration response. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "apigateway.aws:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "apigateway.aws:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Kong API Gateway

**Pack ID:** `apigateway.kong`

Protects against destructive Kong Gateway CLI, deck CLI, and Admin API operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `kong`
- `deck`
- `8001`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `kong-version` | `kong\s+(?:version\|--version\|-v)\b` |
| `kong-help` | `kong\s+(?:help\|--help\|-h)\b` |
| `kong-health` | `kong\s+health\b` |
| `kong-check` | `kong\s+check\b` |
| `kong-config-parse` | `kong\s+config\s+(?:parse\|init)\b` |
| `deck-version` | `deck\s+(?:version\|--version)\b` |
| `deck-help` | `deck\s+(?:help\|--help\|-h)\b` |
| `deck-ping` | `deck\s+ping\b` |
| `deck-dump` | `deck\s+dump\b` |
| `deck-diff` | `deck\s+diff\b` |
| `deck-validate` | `deck\s+validate\b` |
| `deck-convert` | `deck\s+convert\b` |
| `deck-file` | `deck\s+file\b` |
| `kong-admin-explicit-get` | `curl\s+.*(?:-X\s+GET\|--request\s+GET)\s+.*(?:localhost\|127\.0\.0\.1):8001/` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `deck-reset` | deck reset removes ALL Kong configuration. This is extremely dangerous and irreversible. | high |
| `deck-sync-destructive` | deck sync with --select-tag can remove entities not matching the tag. | high |
| `kong-admin-delete-services` | DELETE request to Kong Admin API removes services. | high |
| `kong-admin-delete-routes` | DELETE request to Kong Admin API removes routes. | high |
| `kong-admin-delete-plugins` | DELETE request to Kong Admin API removes plugins. | high |
| `kong-admin-delete-consumers` | DELETE request to Kong Admin API removes consumers. | high |
| `kong-admin-delete-upstreams` | DELETE request to Kong Admin API removes upstreams. | high |
| `kong-admin-delete-targets` | DELETE request to Kong Admin API removes targets. | high |
| `kong-admin-delete-certificates` | DELETE request to Kong Admin API removes certificates. | high |
| `kong-admin-delete-snis` | DELETE request to Kong Admin API removes SNIs. | high |
| `kong-admin-delete-generic` | DELETE request to Kong Admin API can remove configuration. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "apigateway.kong:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "apigateway.kong:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Google Apigee

**Pack ID:** `apigateway.apigee`

Protects against destructive Google Apigee CLI and apigeecli operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `apigee`
- `apigeecli`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `gcloud-apigee-apis-list` | `gcloud\s+apigee\s+apis\s+list\b` |
| `gcloud-apigee-apis-describe` | `gcloud\s+apigee\s+apis\s+describe\b` |
| `gcloud-apigee-environments-list` | `gcloud\s+apigee\s+environments\s+list\b` |
| `gcloud-apigee-environments-describe` | `gcloud\s+apigee\s+environments\s+describe\b` |
| `gcloud-apigee-developers-list` | `gcloud\s+apigee\s+developers\s+list\b` |
| `gcloud-apigee-developers-describe` | `gcloud\s+apigee\s+developers\s+describe\b` |
| `gcloud-apigee-products-list` | `gcloud\s+apigee\s+products\s+list\b` |
| `gcloud-apigee-products-describe` | `gcloud\s+apigee\s+products\s+describe\b` |
| `gcloud-apigee-organizations-list` | `gcloud\s+apigee\s+organizations\s+list\b` |
| `gcloud-apigee-organizations-describe` | `gcloud\s+apigee\s+organizations\s+describe\b` |
| `gcloud-apigee-deployments-list` | `gcloud\s+apigee\s+deployments\s+list\b` |
| `gcloud-apigee-deployments-describe` | `gcloud\s+apigee\s+deployments\s+describe\b` |
| `apigeecli-apis-list` | `apigeecli\s+apis\s+list\b` |
| `apigeecli-apis-get` | `apigeecli\s+apis\s+get\b` |
| `apigeecli-products-list` | `apigeecli\s+products\s+list\b` |
| `apigeecli-products-get` | `apigeecli\s+products\s+get\b` |
| `apigeecli-developers-list` | `apigeecli\s+developers\s+list\b` |
| `apigeecli-developers-get` | `apigeecli\s+developers\s+get\b` |
| `apigeecli-envs-list` | `apigeecli\s+envs\s+list\b` |
| `apigeecli-envs-get` | `apigeecli\s+envs\s+get\b` |
| `apigeecli-orgs-list` | `apigeecli\s+orgs\s+list\b` |
| `apigeecli-orgs-get` | `apigeecli\s+orgs\s+get\b` |
| `gcloud-apigee-help` | `gcloud\s+apigee\s+(?:--help\|-h\|help)\b` |
| `apigeecli-help` | `apigeecli\s+(?:--help\|-h\|help\|version)\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `gcloud-apigee-apis-delete` | gcloud apigee apis delete removes an API proxy from Apigee. | high |
| `gcloud-apigee-environments-delete` | gcloud apigee environments delete removes an Apigee environment. | high |
| `gcloud-apigee-developers-delete` | gcloud apigee developers delete removes a developer from Apigee. | high |
| `gcloud-apigee-products-delete` | gcloud apigee products delete removes an API product from Apigee. | high |
| `gcloud-apigee-organizations-delete` | gcloud apigee organizations delete removes an entire Apigee organization. EXTREMELY DANGEROUS. | high |
| `gcloud-apigee-deployments-undeploy` | gcloud apigee deployments undeploy removes an API deployment. | high |
| `apigeecli-apis-delete` | apigeecli apis delete removes an API proxy from Apigee. | high |
| `apigeecli-products-delete` | apigeecli products delete removes an API product from Apigee. | high |
| `apigeecli-developers-delete` | apigeecli developers delete removes a developer from Apigee. | high |
| `apigeecli-envs-delete` | apigeecli envs delete removes an Apigee environment. | high |
| `apigeecli-orgs-delete` | apigeecli orgs delete removes an entire Apigee organization. EXTREMELY DANGEROUS. | high |
| `apigeecli-apps-delete` | apigeecli apps delete removes a developer app from Apigee. | high |
| `apigeecli-keyvaluemaps-delete` | apigeecli keyvaluemaps delete removes a key-value map from Apigee. | high |
| `apigeecli-targetservers-delete` | apigeecli targetservers delete removes a target server from Apigee. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "apigateway.apigee:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "apigateway.apigee:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/backup.md
================================================
# Backup Packs

This document describes packs in the `backup` category.

## Packs in this Category

- [BorgBackup](#backupborg)
- [Rclone](#backuprclone)
- [Restic](#backuprestic)
- [Velero](#backupvelero)

---

## BorgBackup

**Pack ID:** `backup.borg`

Protects against destructive borg operations like delete, prune, compact, and recreate.

### Keywords

Commands containing these keywords are checked against this pack:

- `borg`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `borg-list` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+list\b` |
| `borg-info` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+info\b` |
| `borg-diff` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+diff\b` |
| `borg-check` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+check\b` |
| `borg-create` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+create\b` |
| `borg-extract` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+extract\b` |
| `borg-mount` | `borg(?:\s+--?\S+(?:\s+\S+)?)*\s+mount\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `borg-delete` | borg delete removes archives or entire repositories. | high |
| `borg-prune` | borg prune removes archives based on retention rules. | high |
| `borg-compact` | borg compact reclaims space after deletions. | high |
| `borg-recreate` | borg recreate can drop data from archives. | high |
| `borg-break-lock` | borg break-lock forces removal of repository locks. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "backup.borg:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "backup.borg:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Rclone

**Pack ID:** `backup.rclone`

Protects against destructive rclone operations like sync, delete, purge, dedupe, and move.

### Keywords

Commands containing these keywords are checked against this pack:

- `rclone`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `rclone-copy` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+copy\b` |
| `rclone-ls` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+ls\b` |
| `rclone-lsd` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+lsd\b` |
| `rclone-lsl` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+lsl\b` |
| `rclone-size` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+size\b` |
| `rclone-check` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+check\b` |
| `rclone-config` | `rclone(?:\s+--?\S+(?:\s+\S+)?)*\s+config\b` |
| `rclone-dry-run` | `rclone\b(?:\s+\S+)*\s+--dry-run\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `rclone-sync` | rclone sync deletes destination files not present in the source. | high |
| `rclone-delete` | rclone delete removes files and directories from the target. | high |
| `rclone-deletefile` | rclone deletefile removes a single file from the target. | high |
| `rclone-purge` | rclone purge deletes a path and all its contents. | high |
| `rclone-cleanup` | rclone cleanup removes old/malformed uploads. | high |
| `rclone-dedupe` | rclone dedupe can delete or rename duplicate files. | high |
| `rclone-move` | rclone move deletes source files after copying. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "backup.rclone:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "backup.rclone:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Restic

**Pack ID:** `backup.restic`

Protects against destructive restic operations like forgetting snapshots, pruning data, removing keys, and cache cleanup.

### Keywords

Commands containing these keywords are checked against this pack:

- `restic`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `restic-snapshots` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+snapshots\b` |
| `restic-ls` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+ls\b` |
| `restic-stats` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+stats\b` |
| `restic-check` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+check\b` |
| `restic-diff` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+diff\b` |
| `restic-find` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+find\b` |
| `restic-backup` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+backup\b` |
| `restic-restore` | `restic(?:\s+--?\S+(?:\s+\S+)?)*\s+restore\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `restic-forget` | restic forget removes snapshots and can permanently delete backup data. | high |
| `restic-prune` | restic prune removes unreferenced data and is irreversible. | high |
| `restic-key-remove` | restic key remove deletes encryption keys and can make backups unrecoverable. | high |
| `restic-unlock-remove-all` | restic unlock --remove-all force-removes repository locks. | high |
| `restic-cache-cleanup` | restic cache --cleanup removes cached data from disk. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "backup.restic:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "backup.restic:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Velero

**Pack ID:** `backup.velero`

Protects against destructive velero operations like deleting backups, schedules, and locations.

### Keywords

Commands containing these keywords are checked against this pack:

- `velero`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `velero-backup-get` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+backup\s+get\b` |
| `velero-backup-describe` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+backup\s+describe\b` |
| `velero-backup-logs` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+backup\s+logs\b` |
| `velero-backup-create` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+backup\s+create\b` |
| `velero-schedule-get` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+schedule\s+get\b` |
| `velero-restore-create` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+restore\s+create\b` |
| `velero-version` | `velero(?:\s+--?\S+(?:\s+\S+)?)*\s+version\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `velero-backup-delete` | velero backup delete removes a backup and its data. | high |
| `velero-schedule-delete` | velero schedule delete removes scheduled backups. | high |
| `velero-restore-delete` | velero restore delete removes restore records. | high |
| `velero-backup-location-delete` | velero backup-location delete removes a backup storage location. | high |
| `velero-snapshot-location-delete` | velero snapshot-location delete removes a snapshot location. | high |
| `velero-uninstall` | velero uninstall removes the Velero deployment and related resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "backup.velero:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "backup.velero:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/cdn.md
================================================
# CDN Packs

This document describes packs in the `cdn` category.

## Packs in this Category

- [Cloudflare Workers](#cdncloudflare_workers)
- [Fastly CDN](#cdnfastly)
- [AWS CloudFront](#cdncloudfront)

---

## Cloudflare Workers

**Pack ID:** `cdn.cloudflare_workers`

Protects against destructive Cloudflare Workers, KV, R2, and D1 operations via the Wrangler CLI.

### Keywords

Commands containing these keywords are checked against this pack:

- `wrangler`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `wrangler-whoami` | `wrangler\s+whoami\b` |
| `wrangler-kv-get` | `wrangler\s+kv:key\s+get\b` |
| `wrangler-kv-list` | `wrangler\s+kv:key\s+list\b` |
| `wrangler-kv-namespace-list` | `wrangler\s+kv:namespace\s+list\b` |
| `wrangler-r2-object-get` | `wrangler\s+r2\s+object\s+get\b` |
| `wrangler-r2-bucket-list` | `wrangler\s+r2\s+bucket\s+list\b` |
| `wrangler-d1-list` | `wrangler\s+d1\s+list\b` |
| `wrangler-d1-info` | `wrangler\s+d1\s+info\b` |
| `wrangler-dev` | `wrangler\s+dev\b` |
| `wrangler-tail` | `wrangler\s+tail\b` |
| `wrangler-version` | `wrangler\s+(?:-v\|--version\|version)\b` |
| `wrangler-help` | `wrangler\s+(?:-h\|--help\|help)\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `wrangler-delete` | wrangler delete removes a Worker from Cloudflare. | high |
| `wrangler-deployments-rollback` | wrangler deployments rollback reverts to a previous Worker version. | high |
| `wrangler-kv-key-delete` | wrangler kv:key delete removes a key from KV storage. | high |
| `wrangler-kv-namespace-delete` | wrangler kv:namespace delete removes an entire KV namespace. | high |
| `wrangler-kv-bulk-delete` | wrangler kv:bulk delete removes multiple keys from KV storage. | high |
| `wrangler-r2-object-delete` | wrangler r2 object delete removes an object from R2 storage. | high |
| `wrangler-r2-bucket-delete` | wrangler r2 bucket delete removes an entire R2 bucket. | high |
| `wrangler-d1-delete` | wrangler d1 delete removes a D1 database. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cdn.cloudflare_workers:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cdn.cloudflare_workers:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Fastly CDN

**Pack ID:** `cdn.fastly`

Protects against destructive Fastly CLI operations like service, domain, backend, and VCL deletion.

### Keywords

Commands containing these keywords are checked against this pack:

- `fastly`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `fastly-service-list` | `fastly\s+service\s+list\b` |
| `fastly-service-describe` | `fastly\s+service\s+describe\b` |
| `fastly-service-search` | `fastly\s+service\s+search\b` |
| `fastly-domain-list` | `fastly\s+domain\s+list\b` |
| `fastly-domain-describe` | `fastly\s+domain\s+describe\b` |
| `fastly-backend-list` | `fastly\s+backend\s+list\b` |
| `fastly-backend-describe` | `fastly\s+backend\s+describe\b` |
| `fastly-vcl-list` | `fastly\s+vcl\s+list\b` |
| `fastly-vcl-describe` | `fastly\s+vcl\s+describe\b` |
| `fastly-version-list` | `fastly\s+version\s+list\b` |
| `fastly-whoami` | `fastly\s+whoami\b` |
| `fastly-profile` | `fastly\s+profile\b` |
| `fastly-version` | `fastly\s+(?:-v\|--version\|version)\b` |
| `fastly-help` | `fastly\s+(?:-h\|--help\|help)\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `fastly-service-delete` | fastly service delete removes a Fastly service entirely. | high |
| `fastly-domain-delete` | fastly domain delete removes a domain from a service. | high |
| `fastly-backend-delete` | fastly backend delete removes a backend origin server. | high |
| `fastly-vcl-delete` | fastly vcl delete removes VCL configuration. | high |
| `fastly-dictionary-delete` | fastly dictionary delete removes an edge dictionary. | high |
| `fastly-dictionary-item-delete` | fastly dictionary-item delete removes dictionary entries. | high |
| `fastly-acl-delete` | fastly acl delete removes an access control list. | high |
| `fastly-acl-entry-delete` | fastly acl-entry delete removes ACL entries. | high |
| `fastly-logging-delete` | fastly logging delete removes logging endpoints. | high |
| `fastly-version-activate` | fastly service version activate can cause service disruption if misconfigured. | high |
| `fastly-compute-delete` | fastly compute delete removes compute package. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cdn.fastly:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cdn.fastly:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## AWS CloudFront

**Pack ID:** `cdn.cloudfront`

Protects against destructive AWS CloudFront operations like deleting distributions, cache policies, and functions.

### Keywords

Commands containing these keywords are checked against this pack:

- `cloudfront`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `cloudfront-list-distributions` | `aws\s+cloudfront\s+list-distributions\b` |
| `cloudfront-list-cache-policies` | `aws\s+cloudfront\s+list-cache-policies\b` |
| `cloudfront-list-origin-request-policies` | `aws\s+cloudfront\s+list-origin-request-policies\b` |
| `cloudfront-list-functions` | `aws\s+cloudfront\s+list-functions\b` |
| `cloudfront-list-invalidations` | `aws\s+cloudfront\s+list-invalidations\b` |
| `cloudfront-get-distribution` | `aws\s+cloudfront\s+get-distribution\b` |
| `cloudfront-get-distribution-config` | `aws\s+cloudfront\s+get-distribution-config\b` |
| `cloudfront-get-cache-policy` | `aws\s+cloudfront\s+get-cache-policy\b` |
| `cloudfront-get-origin-request-policy` | `aws\s+cloudfront\s+get-origin-request-policy\b` |
| `cloudfront-get-function` | `aws\s+cloudfront\s+get-function\b` |
| `cloudfront-get-invalidation` | `aws\s+cloudfront\s+get-invalidation\b` |
| `cloudfront-describe-function` | `aws\s+cloudfront\s+describe-function\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `cloudfront-delete-distribution` | aws cloudfront delete-distribution removes a CloudFront distribution. | high |
| `cloudfront-delete-cache-policy` | aws cloudfront delete-cache-policy removes a cache policy. | high |
| `cloudfront-delete-origin-request-policy` | aws cloudfront delete-origin-request-policy removes an origin request policy. | high |
| `cloudfront-delete-function` | aws cloudfront delete-function removes a CloudFront function. | high |
| `cloudfront-delete-response-headers-policy` | aws cloudfront delete-response-headers-policy removes a response headers policy. | high |
| `cloudfront-delete-key-group` | aws cloudfront delete-key-group removes a key group used for signed URLs. | high |
| `cloudfront-create-invalidation` | aws cloudfront create-invalidation creates a cache invalidation (has cost implications). | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cdn.cloudfront:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cdn.cloudfront:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/cicd.md
================================================
# CI/CD Packs

This document describes packs in the `cicd` category.

## Packs in this Category

- [GitHub Actions](#cicdgithub_actions)
- [GitLab CI](#cicdgitlab_ci)
- [Jenkins](#cicdjenkins)
- [CircleCI](#cicdcircleci)

---

## GitHub Actions

**Pack ID:** `cicd.github_actions`

Protects against destructive GitHub Actions operations like deleting secrets/variables or using gh api DELETE against /actions endpoints.

### Keywords

Commands containing these keywords are checked against this pack:

- `gh`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `gh-actions-secret-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+secret\s+list\b` |
| `gh-actions-variable-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+variable\s+list\b` |
| `gh-actions-workflow-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+workflow\s+list\b` |
| `gh-actions-workflow-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+workflow\s+view\b` |
| `gh-actions-run-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+run\s+list\b` |
| `gh-actions-run-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+run\s+view\b` |
| `gh-actions-api-explicit-get` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:secret\|variable\|workflow\|run\|api)\b)\S+)?)*\s+api\b.*(?:-X\|--method)\s+GET\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `gh-actions-secret-remove` | gh secret delete/remove deletes GitHub Actions secrets. This can break CI and may be hard to recover. | high |
| `gh-actions-variable-remove` | gh variable delete/remove deletes GitHub Actions variables. This can break workflows. | high |
| `gh-actions-workflow-disable` | gh workflow disable disables workflows. This is reversible, but can disrupt CI. | high |
| `gh-actions-run-cancel` | gh run cancel cancels a running workflow. This is reversible, but may disrupt deployments. | high |
| `gh-actions-api-delete-secrets` | gh api DELETE against /actions/secrets deletes GitHub Actions secrets. | high |
| `gh-actions-api-delete-variables` | gh api DELETE against /actions/variables deletes GitHub Actions variables. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cicd.github_actions:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cicd.github_actions:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## GitLab CI

**Pack ID:** `cicd.gitlab_ci`

Protects against destructive GitLab CI/CD operations like deleting variables, removing artifacts, and unregistering runners.

### Keywords

Commands containing these keywords are checked against this pack:

- `glab`
- `gitlab-runner`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `glab-variable-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+variable\s+list\b` |
| `glab-ci-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+ci\s+list\b` |
| `glab-ci-view` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+ci\s+view\b` |
| `glab-ci-status` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+ci\s+status\b` |
| `gitlab-runner-list` | `gitlab-runner(?:\s+--?\S+(?:\s+\S+)?)*\s+list\b` |
| `gitlab-runner-status` | `gitlab-runner(?:\s+--?\S+(?:\s+\S+)?)*\s+status\b` |
| `glab-api-explicit-get` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+api\b.*(?:-X\|--method)\s+GET\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `glab-variable-delete` | glab variable delete removes CI variables and can break pipelines. | high |
| `glab-ci-delete` | glab ci delete removes pipeline artifacts or pipelines. | high |
| `glab-api-delete-variables` | glab api DELETE against variables endpoints removes CI variables. | high |
| `gitlab-runner-unregister` | gitlab-runner unregister removes runners and can halt CI. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cicd.gitlab_ci:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cicd.gitlab_ci:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Jenkins

**Pack ID:** `cicd.jenkins`

Protects against destructive Jenkins CLI/API operations like deleting jobs, nodes, credentials, or build history.

### Keywords

Commands containing these keywords are checked against this pack:

- `jenkins-cli`
- `jenkins`
- `doDelete`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `jenkins-cli-list-jobs` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+list-jobs\b` |
| `jenkins-cli-get-job` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+get-job\b` |
| `jenkins-cli-build` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+build\b` |
| `jenkins-cli-who-am-i` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+who-am-i\b` |
| `jenkins-cli-list-views` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+list-views\b` |
| `jenkins-cli-list-plugins` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+list-plugins\b` |
| `jenkins-cli-get-node` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+get-node\b` |
| `jenkins-cli-get-credentials` | `(?:jenkins-cli\|java\s+-jar\s+\S*jenkins-cli\.jar)(?:\s+--?\S+(?:\s+\S+)?)*\s+get-credentials\b` |
| `jenkins-curl-explicit-get` | `curl(?:\s+--?\S+(?:\s+\S+)?)*\s+(?:-X\|--request)\s+GET\b.*(?:jenkins\|/job/\|/api/)` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `jenkins-cli-delete-job` | jenkins-cli delete-job deletes Jenkins jobs and can break pipelines. | high |
| `jenkins-cli-delete-node` | jenkins-cli delete-node deletes Jenkins nodes and can halt CI. | high |
| `jenkins-cli-delete-credentials` | jenkins-cli delete-credentials removes stored credentials. | high |
| `jenkins-cli-delete-builds` | jenkins-cli delete-builds removes build history and artifacts. | high |
| `jenkins-cli-delete-view` | jenkins-cli delete-view removes Jenkins views. | high |
| `jenkins-curl-do-delete` | curl POST to Jenkins doDelete endpoints deletes jobs or resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cicd.jenkins:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cicd.jenkins:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## CircleCI

**Pack ID:** `cicd.circleci`

Protects against destructive CircleCI operations like deleting contexts, removing secrets, deleting orbs/namespaces, or removing pipelines.

### Keywords

Commands containing these keywords are checked against this pack:

- `circleci`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `circleci-context-list` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+context\s+list\b` |
| `circleci-orb-list` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+orb\s+list\b` |
| `circleci-orb-info` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+orb\s+info\b` |
| `circleci-pipeline-list` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+pipeline\s+list\b` |
| `circleci-project-list` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+project\s+list\b` |
| `circleci-namespace-list` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+namespace\s+list\b` |
| `circleci-config-validate` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+config\s+validate\b` |
| `circleci-local-execute` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+local\s+execute\b` |
| `circleci-policy-status` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+policy\s+status\b` |
| `circleci-diagnostic` | `circleci(?:\s+--?\S+(?:\s+\S+)?)*\s+diagnostic\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `circleci-context-delete` | circleci context delete removes contexts and their secrets. | high |
| `circleci-context-remove-secret` | circleci context remove-secret deletes secrets from a context. | high |
| `circleci-orb-delete` | circleci orb delete removes an orb from the registry. | high |
| `circleci-namespace-delete` | circleci namespace delete removes an orb namespace. | high |
| `circleci-pipeline-delete` | circleci pipeline delete removes pipeline history. | high |
| `circleci-api-delete-envvar` | curl DELETE against CircleCI envvar endpoints removes environment variables. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cicd.circleci:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cicd.circleci:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/cloud.md
================================================
# Cloud Provider Packs

This document describes packs in the `cloud` category.

## Packs in this Category

- [AWS CLI](#cloudaws)
- [Google Cloud SDK](#cloudgcp)
- [Azure CLI](#cloudazure)

---

## AWS CLI

**Pack ID:** `cloud.aws`

Protects against destructive AWS CLI operations like terminate-instances, delete-db-instance, and s3 rm --recursive

### Keywords

Commands containing these keywords are checked against this pack:

- `aws`
- `terminate`
- `delete`
- `s3`
- `ec2`
- `rds`
- `ecr`
- `logs`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `aws-describe` | `aws\s+\S+\s+describe-` |
| `aws-list` | `aws\s+\S+\s+list-` |
| `aws-get` | `aws\s+\S+\s+get-` |
| `s3-ls` | `aws\s+s3\s+ls` |
| `s3-cp` | `aws\s+s3\s+cp` |
| `aws-dry-run` | `aws\s+.*--dry-run` |
| `sts-identity` | `aws\s+sts\s+get-caller-identity` |
| `cfn-describe` | `aws\s+cloudformation\s+(?:describe\|list)-` |
| `ecr-login` | `aws\s+ecr\s+get-login` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `ec2-terminate` | aws ec2 terminate-instances permanently destroys EC2 instances. | high |
| `removes AWS resources` | aws ec2 delete-* permanently removes AWS resources. | high |
| `s3-rm-recursive` | aws s3 rm --recursive permanently deletes all objects in the path. | high |
| `s3-rb` | aws s3 rb removes the entire S3 bucket. | high |
| `s3api-delete-bucket` | aws s3api delete-bucket removes the entire S3 bucket. | high |
| `rds-delete` | aws rds delete-db-instance/cluster permanently destroys the database. | high |
| `cfn-delete-stack` | aws cloudformation delete-stack removes the entire stack and its resources. | high |
| `lambda-delete` | aws lambda delete-function permanently removes the Lambda function. | high |
| `iam-delete` | aws iam delete-* removes IAM resources. Verify dependencies first. | high |
| `dynamodb-delete` | aws dynamodb delete-table permanently deletes the table and all data. | high |
| `eks-delete` | aws eks delete-cluster removes the entire EKS cluster. | high |
| `ecr-delete-repository` | aws ecr delete-repository permanently deletes the repository and its images. | high |
| `ecr-batch-delete-image` | aws ecr batch-delete-image permanently deletes one or more images. | high |
| `ecr-delete-lifecycle-policy` | aws ecr delete-lifecycle-policy removes the repository lifecycle policy. | high |
| `logs-delete-log-group` | aws logs delete-log-group permanently deletes a log group and all events. | high |
| `logs-delete-log-stream` | aws logs delete-log-stream permanently deletes a log stream and all events. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cloud.aws:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cloud.aws:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Google Cloud SDK

**Pack ID:** `cloud.gcp`

Protects against destructive gcloud operations like instances delete, sql instances delete, and gsutil rm -r

### Keywords

Commands containing these keywords are checked against this pack:

- `gcloud`
- `gsutil`
- `delete`
- `instances`
- `artifacts`
- `images`
- `repositories`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `gcloud-describe` | `gcloud\s+\S+\s+\S+\s+describe` |
| `gcloud-list` | `gcloud\s+\S+\s+\S+\s+list` |
| `gsutil-ls` | `gsutil\s+ls` |
| `gsutil-cp` | `gsutil\s+cp` |
| `gcloud-config` | `gcloud\s+config` |
| `gcloud-auth` | `gcloud\s+auth` |
| `gcloud-info` | `gcloud\s+info` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `compute-delete` | gcloud compute instances delete permanently destroys VM instances. | high |
| `disk-delete` | gcloud compute disks delete permanently destroys disk data. | high |
| `sql-delete` | gcloud sql instances delete permanently destroys the Cloud SQL instance. | high |
| `gsutil-rm-recursive` | gsutil rm -r permanently deletes all objects in the path. | high |
| `gsutil-rb` | gsutil rb removes the entire GCS bucket. | high |
| `gke-delete` | gcloud container clusters delete removes the entire GKE cluster. | high |
| `project-delete` | gcloud projects delete removes the entire GCP project and ALL its resources! | high |
| `functions-delete` | gcloud functions delete removes the Cloud Function. | high |
| `pubsub-delete` | gcloud pubsub delete removes Pub/Sub topics or subscriptions. | high |
| `firestore-delete` | gcloud firestore delete removes Firestore data. | high |
| `container-images-delete` | gcloud container images delete permanently deletes container images. | high |
| `artifacts-docker-images-delete` | gcloud artifacts docker images delete permanently deletes container images. | high |
| `artifacts-repositories-delete` | gcloud artifacts repositories delete permanently deletes the repository. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cloud.gcp:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cloud.gcp:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Azure CLI

**Pack ID:** `cloud.azure`

Protects against destructive Azure CLI operations like vm delete, storage account delete, and resource group delete

### Keywords

Commands containing these keywords are checked against this pack:

- `az`
- `delete`
- `vm`
- `storage`
- `acr`
- `registry`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `az-show` | `az\s+\S+\s+show` |
| `az-list` | `az\s+\S+\s+list` |
| `az-account` | `az\s+account` |
| `az-configure` | `az\s+configure` |
| `az-login` | `az\s+login` |
| `az-version` | `az\s+version` |
| `az-help` | `az\s+.*--help` |
| `az-what-if` | `az\s+.*--what-if` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `vm-delete` | az vm delete permanently destroys virtual machines. | high |
| `storage-delete` | az storage account delete permanently destroys the storage account and all data. | high |
| `blob-delete` | az storage blob/container delete permanently removes data. | high |
| `sql-delete` | az sql server/db delete permanently destroys the database. | high |
| `group-delete` | az group delete removes the entire resource group and ALL resources within it! | high |
| `aks-delete` | az aks delete removes the entire AKS cluster. | high |
| `webapp-delete` | az webapp delete removes the App Service. | high |
| `functionapp-delete` | az functionapp delete removes the Azure Function App. | high |
| `cosmosdb-delete` | az cosmosdb delete permanently destroys the Cosmos DB resource. | high |
| `keyvault-delete` | az keyvault delete removes the Key Vault. Secrets may be unrecoverable. | high |
| `vnet-delete` | az network vnet delete removes the virtual network. | high |
| `acr-delete` | az acr delete removes the container registry and all images. | high |
| `acr-repository-delete` | az acr repository delete permanently deletes the repository and its images. | high |
| `acr-repository-untag` | az acr repository untag removes tags from images. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "cloud.azure:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "cloud.azure:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/containers.md
================================================
# Container Packs

This document describes packs in the `containers` category.

## Packs in this Category

- [Docker](#containersdocker)
- [Docker Compose](#containerscompose)
- [Podman](#containerspodman)

---

## Docker

**Pack ID:** `containers.docker`

Protects against destructive Docker operations like system prune, volume prune, and force removal

### Keywords

Commands containing these keywords are checked against this pack:

- `docker`
- `prune`
- `rmi`
- `volume`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `docker-ps` | `docker\s+ps` |
| `docker-images` | `docker\s+images` |
| `docker-logs` | `docker\s+logs` |
| `docker-inspect` | `docker\s+inspect` |
| `docker-build` | `docker\s+build` |
| `docker-pull` | `docker\s+pull` |
| `docker-run` | `docker\s+run` |
| `docker-exec` | `docker\s+exec` |
| `docker-stats` | `docker\s+stats` |
| `docker-dry-run` | `docker\s+.*--dry-run` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `system-prune` | docker system prune removes ALL unused containers, networks, images. Use 'docker system df' to preview. | high |
| `volume-prune` | docker volume prune removes ALL unused volumes and their data permanently. | high |
| `network-prune` | docker network prune removes ALL unused networks. | high |
| `image-prune` | docker image prune removes unused images. Use 'docker images' to review first. | medium |
| `container-prune` | docker container prune removes ALL stopped containers. | medium |
| `rm-force` | docker rm -f forcibly removes containers, potentially losing data. | high |
| `rmi-force` | docker rmi -f forcibly removes images even if in use. | high |
| `volume-rm` | docker volume rm permanently deletes volumes and their data. | high |
| `stop-all` | Stopping/killing all containers can disrupt services. Be specific about which containers. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "containers.docker:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "containers.docker:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Docker Compose

**Pack ID:** `containers.compose`

Protects against destructive Docker Compose operations like 'down -v' which removes volumes

### Keywords

Commands containing these keywords are checked against this pack:

- `docker-compose`
- `docker compose`
- `compose`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `compose-config` | `(?:docker-compose\|docker\s+compose)\s+config` |
| `compose-ps` | `(?:docker-compose\|docker\s+compose)\s+ps` |
| `compose-logs` | `(?:docker-compose\|docker\s+compose)\s+logs` |
| `compose-up` | `(?:docker-compose\|docker\s+compose)\s+up` |
| `compose-build` | `(?:docker-compose\|docker\s+compose)\s+build` |
| `compose-pull` | `(?:docker-compose\|docker\s+compose)\s+pull` |
| `compose-down-no-volumes` | `(?:docker-compose\|docker\s+compose)\s+down(?!\s+.*(?:-v\|--volumes))` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `down-volumes` | docker-compose down -v removes volumes and their data permanently. | high |
| `down-rmi-all` | docker-compose down --rmi all removes all images used by services. | high |
| `rm-volumes` | docker-compose rm -v removes volumes attached to containers. | high |
| `rm-force` | docker-compose rm -f forcibly removes containers without confirmation. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "containers.compose:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "containers.compose:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Podman

**Pack ID:** `containers.podman`

Protects against destructive Podman operations like system prune, volume prune, and force removal

### Keywords

Commands containing these keywords are checked against this pack:

- `podman`
- `prune`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `podman-ps` | `podman\s+ps` |
| `podman-images` | `podman\s+images` |
| `podman-logs` | `podman\s+logs` |
| `podman-inspect` | `podman\s+inspect` |
| `podman-build` | `podman\s+build` |
| `podman-pull` | `podman\s+pull` |
| `podman-run` | `podman\s+run` |
| `podman-exec` | `podman\s+exec` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `system-prune` | podman system prune removes ALL unused containers, pods, images. Use 'podman system df' to preview. | high |
| `volume-prune` | podman volume prune removes ALL unused volumes and their data permanently. | high |
| `pod-prune` | podman pod prune removes ALL stopped pods. | high |
| `image-prune` | podman image prune removes unused images. Use 'podman images' to review first. | medium |
| `container-prune` | podman container prune removes ALL stopped containers. | medium |
| `rm-force` | podman rm -f forcibly removes containers, potentially losing data. | high |
| `rmi-force` | podman rmi -f forcibly removes images even if in use. | high |
| `volume-rm` | podman volume rm permanently deletes volumes and their data. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "containers.podman:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "containers.podman:*"
reason = "Your reason here"
risk_acknowledged = true
```

---



================================================
FILE: docs/packs/core.md
================================================
# Core Packs

This document describes packs in the `core` category.

## Packs in this Category

- [Core Git](#coregit)
- [Core Filesystem](#corefilesystem)

---

## Core Git

**Pack ID:** `core.git`

Protects against destructive git commands that can lose uncommitted work, rewrite history, or destroy stashes

### Keywords

Commands containing these keywords are checked against this pack:

- `git`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `checkout-new-branch` | `git\s+(?:\S+\s+)*checkout\s+-b\s+` |
| `checkout-orphan` | `git\s+(?:\S+\s+)*checkout\s+--orphan\s+` |
| `restore-staged-long` | `git\s+(?:\S+\s+)*restore\s+--staged\s+(?!.*--worktree)(?!.*-W\b)` |
| `restore-staged-short` | `git\s+(?:\S+\s+)*restore\s+-S\s+(?!.*--worktree)(?!.*-W\b)` |
| `clean-dry-run-short` | `git\s+(?:\S+\s+)*clean\s+-[a-z]*n[a-z]*` |
| `clean-dry-run-long` | `git\s+(?:\S+\s+)*clean\s+--dry-run` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `checkout-discard` | git checkout -- discards uncommitted changes permanently. Use 'git stash' first. | high |
| `checkout-ref-discard` | git checkout <ref> -- <path> overwrites working tree. Use 'git stash' first. | high |
| `restore-worktree` | git restore discards uncommitted changes. Use 'git stash' or 'git diff' first. | high |
| `restore-worktree-explicit` | git restore --worktree/-W discards uncommitted changes permanently. | high |
| `reset-hard` | git reset --hard destroys uncommitted changes. Use 'git stash' first. | critical |
| `reset-merge` | git reset --merge can lose uncommitted changes. | high |
| `clean-force` | git clean -f/--force removes untracked files permanently. Review with 'git clean -n' first. | critical |
| `push-force-long` | Force push can destroy remote history. Use --force-with-lease if necessary. | critical |
| `push-force-short` | Force push (-f) can destroy remote history. Use --force-with-lease if necessary. | critical |
| `branch-force-delete` | git branch -D/--force deletes branches without checks. Recoverable via 'git reflog'. | medium |
| `stash-drop` | git stash drop deletes a single stash. Recoverable via `git fsck` (unreachable objects). | medium |
| `stash-clear` | git stash clear permanently deletes ALL stashed changes. | critical |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "core.git:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "core.git:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Core Filesystem

**Pack ID:** `core.filesystem`

Protects against dangerous rm -rf commands outside temp directories

### Keywords

Commands containing these keywords are checked against this pack:

- `rm`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `rm-rf-tmp` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-fr-tmp` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-rf-var-tmp` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-fr-var-tmp` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-rf-tmpdir` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-fr-tmpdir` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-rf-tmpdir-brace` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-fr-tmpdir-brace` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-rf-tmpdir-quoted` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:"\$TMPDIR/(?!(?:[^"]*/)?\.\.(?:/\|"))[^"]*"(?:\s+\|$))+$` |
| `rm-fr-tmpdir-quoted` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:"\$TMPDIR/(?!(?:[^"]*/)?\.\.(?:/\|"))[^"]*"(?:\s+\|$))+$` |
| `rm-rf-tmpdir-brace-quoted` | `^rm\s+-[a-zA-Z]*[rR][a-zA-Z]*f[a-zA-Z]*\s+(?:"\$\{TMPDIR(?!(?:[^"]*/)?\.\.(?:/\|"))[^"]*"(?:\s+\|$))+$` |
| `rm-fr-tmpdir-brace-quoted` | `^rm\s+-[a-zA-Z]*f[a-zA-Z]*[rR][a-zA-Z]*\s+(?:"\$\{TMPDIR(?!(?:[^"]*/)?\.\.(?:/\|"))[^"]*"(?:\s+\|$))+$` |
| `rm-r-f-tmp` | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-f-r-tmp` | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-r-f-var-tmp` | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-f-r-var-tmp` | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-r-f-tmpdir` | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-f-r-tmpdir` | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-r-f-tmpdir-brace` | `^rm\s+(-[a-zA-Z]+\s+)*-[rR]\s+(-[a-zA-Z]+\s+)*-f\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-f-r-tmpdir-brace` | `^rm\s+(-[a-zA-Z]+\s+)*-f\s+(-[a-zA-Z]+\s+)*-[rR]\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-recursive-force-tmp` | `^rm\s+.*--recursive.*--force\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-force-recursive-tmp` | `^rm\s+.*--force.*--recursive\s+(?:/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-recursive-force-var-tmp` | `^rm\s+.*--recursive.*--force\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-force-recursive-var-tmp` | `^rm\s+.*--force.*--recursive\s+(?:/var/tmp/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-recursive-force-tmpdir` | `^rm\s+.*--recursive.*--force\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-force-recursive-tmpdir` | `^rm\s+.*--force.*--recursive\s+(?:\$TMPDIR/(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-recursive-force-tmpdir-brace` | `^rm\s+.*--recursive.*--force\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |
| `rm-force-recursive-tmpdir-brace` | `^rm\s+.*--force.*--recursive\s+(?:\$\{TMPDIR(?!\.\.(?:/\|\s\|$)\|[^\s]*/\.\.(?:/\|\s\|$))\S*(?:\s+\|$))+$` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `rm-rf-root-home` | rm -rf on root or home paths is EXTREMELY DANGEROUS. This command will NOT be executed. Ask the user to run it manually if truly needed. | critical |
| `rm-rf-general` | rm -rf is destructive and requires human approval. Explain what you want to delete and why, then ask the user to run the command manually. | high |
| `rm-r-f-separate` | rm with separate -r -f flags is destructive and requires human approval. | high |
| `rm-recursive-force-long` | rm --recursive --force is destructive and requires human approval. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "core.filesystem:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "core.filesystem:*"
reason = "Your reason here"
risk_acknowledged = true
```

---



================================================
FILE: docs/packs/database.md
================================================
# Database Packs

This document describes packs in the `database` category.

## Packs in this Category

- [PostgreSQL](#databasepostgresql)
- [MySQL/MariaDB](#databasemysql)
- [MongoDB](#databasemongodb)
- [Redis](#databaseredis)
- [SQLite](#databasesqlite)

---

## PostgreSQL

**Pack ID:** `database.postgresql`

Protects against destructive PostgreSQL operations like DROP DATABASE, TRUNCATE, and dropdb

### Keywords

Commands containing these keywords are checked against this pack:

- `psql`
- `dropdb`
- `DROP`
- `TRUNCATE`
- `pg_dump`
- `postgres`
- `DELETE`
- `delete`
- `drop`
- `truncate`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `pg-dump-no-clean` | `pg_dump\s+(?!.*--clean)(?!.*-c\b)` |
| `psql-dry-run` | `psql\s+.*--dry-run` |
| `select-query` | `(?i)^\s*SELECT\s+` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `drop-database` | DROP DATABASE permanently deletes the entire database (even with IF EXISTS). Verify and back up first. | high |
| `drop-table` | DROP TABLE permanently deletes the table (even with IF EXISTS). Verify and back up first. | high |
| `drop-schema` | DROP SCHEMA permanently deletes the schema and all its objects (even with IF EXISTS). | high |
| `truncate-table` | TRUNCATE permanently deletes all rows without logging individual deletions. | high |
| `delete-without-where` | DELETE without WHERE clause deletes ALL rows. Add a WHERE clause or use TRUNCATE intentionally. | high |
| `dropdb-cli` | dropdb permanently deletes the entire database. Verify the database name carefully. | high |
| `pg-dump-clean` | pg_dump --clean drops objects before creating them. This can be destructive on restore. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "database.postgresql:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "database.postgresql:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## MySQL/MariaDB

**Pack ID:** `database.mysql`

MySQL/MariaDB guard

### Keywords

Commands containing these keywords are checked against this pack:

- `mysql`
- `DROP`

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "database.mysql:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "database.mysql:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## MongoDB

**Pack ID:** `database.mongodb`

Protects against destructive MongoDB operations like dropDatabase, dropCollection, and remove without criteria

### Keywords

Commands containing these keywords are checked against this pack:

- `mongo`
- `mongosh`
- `dropDatabase`
- `dropCollection`
- `deleteMany`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `mongo-find` | `\.find\s*\(` |
| `mongo-count` | `\.count(?:Documents)?\s*\(` |
| `mongo-aggregate` | `\.aggregate\s*\(` |
| `mongodump-no-drop` | `mongodump\s+(?!.*--drop)` |
| `mongo-explain` | `\.explain\s*\(` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `drop-database` | dropDatabase permanently deletes the entire database. | high |
| `drop-collection` | drop/dropCollection permanently deletes the collection. | high |
| `delete-all` | remove({}) or deleteMany({}) deletes ALL documents. Add filter criteria. | high |
| `mongorestore-drop` | mongorestore --drop deletes existing data before restoring. | high |
| `collection-drop` | collection.drop() permanently deletes the collection. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "database.mongodb:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "database.mongodb:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Redis

**Pack ID:** `database.redis`

Protects against destructive Redis operations like FLUSHALL, FLUSHDB, and mass key deletion

### Keywords

Commands containing these keywords are checked against this pack:

- `redis`
- `FLUSHALL`
- `FLUSHDB`
- `DEBUG`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `redis-get` | `(?i)\b(?:GET\|MGET)\b` |
| `redis-scan` | `(?i)\bSCAN\b` |
| `redis-info` | `(?i)\bINFO\b` |
| `redis-keys` | `(?i)\bKEYS\b` |
| `redis-dbsize` | `(?i)\bDBSIZE\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `flushall` | FLUSHALL permanently deletes ALL keys in ALL databases. | high |
| `flushdb` | FLUSHDB permanently deletes ALL keys in the current database. | high |
| `debug-crash` | DEBUG SEGFAULT/CRASH will crash the Redis server. | high |
| `debug-sleep` | DEBUG SLEEP blocks the Redis server and can cause availability issues. | high |
| `shutdown` | SHUTDOWN stops the Redis server. Use carefully. | high |
| `config-dangerous` | CONFIG SET for dir/dbfilename/slaveof can be used for security attacks. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "database.redis:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "database.redis:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## SQLite

**Pack ID:** `database.sqlite`

Protects against destructive SQLite operations like DROP TABLE, DELETE without WHERE, and accidental data loss

### Keywords

Commands containing these keywords are checked against this pack:

- `sqlite`
- `sqlite3`
- `DROP`
- `TRUNCATE`
- `DELETE`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `select-query` | `(?i)^\s*SELECT\s+` |
| `dot-schema` | `\.schema` |
| `dot-tables` | `\.tables` |
| `dot-dump` | `\.dump` |
| `dot-backup` | `\.backup` |
| `explain` | `(?i)^\s*EXPLAIN\s+` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `drop-table` | DROP TABLE permanently deletes the table (even with IF EXISTS). Verify it is intended. | high |
| `delete-without-where` | DELETE without WHERE deletes ALL rows. Add a WHERE clause. | high |
| `vacuum-into` | VACUUM INTO overwrites the target file if it exists. | high |
| `sqlite3-stdin` | Running SQL from file could contain destructive commands. Review the file first. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "database.sqlite:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "database.sqlite:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/dns.md
================================================
# DNS Packs

This document describes packs in the `dns` category.

## Packs in this Category

- [Cloudflare DNS](#dnscloudflare)
- [AWS Route53](#dnsroute53)
- [Generic DNS Tools](#dnsgeneric)

---

## Cloudflare DNS

**Pack ID:** `dns.cloudflare`

Protects against destructive Cloudflare DNS operations like record deletion, zone deletion, and targeted Terraform destroy.

### Keywords

Commands containing these keywords are checked against this pack:

- `wrangler`
- `cloudflare`
- `api.cloudflare.com`
- `dns-records`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `cloudflare-wrangler-dns-list` | `wrangler(?:\s+--?\S+(?:\s+\S+)?)*\s+dns-records\s+list\b` |
| `cloudflare-wrangler-whoami` | `wrangler(?:\s+--?\S+(?:\s+\S+)?)*\s+whoami\b` |
| `cloudflare-api-get` | `curl\b.*\s-X\s*GET\b.*\bapi\.cloudflare\.com\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `cloudflare-wrangler-dns-delete` | wrangler dns-records delete removes a Cloudflare DNS record. | high |
| `cloudflare-api-delete-dns-record` | curl -X DELETE against /dns_records/{id} deletes a Cloudflare DNS record. | high |
| `cloudflare-api-delete-zone` | curl -X DELETE against /zones/{id} deletes a Cloudflare zone. | high |
| `cloudflare-terraform-destroy-record` | terraform destroy -target=cloudflare_record deletes specific DNS records. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "dns.cloudflare:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "dns.cloudflare:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## AWS Route53

**Pack ID:** `dns.route53`

Protects against destructive AWS Route53 DNS operations like hosted zone deletion and record set DELETE changes.

### Keywords

Commands containing these keywords are checked against this pack:

- `aws`
- `route53`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `route53-list-hosted-zones` | `aws\s+route53\s+list-hosted-zones\b` |
| `route53-list-resource-record-sets` | `aws\s+route53\s+list-resource-record-sets\b` |
| `route53-get-hosted-zone` | `aws\s+route53\s+get-hosted-zone\b` |
| `route53-test-dns-answer` | `aws\s+route53\s+test-dns-answer\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `route53-delete-hosted-zone` | aws route53 delete-hosted-zone permanently deletes a Route53 hosted zone. | high |
| `route53-change-resource-record-sets-delete` | aws route53 change-resource-record-sets with DELETE removes DNS records. | high |
| `route53-delete-health-check` | aws route53 delete-health-check permanently deletes a Route53 health check. | high |
| `route53-delete-query-logging-config` | aws route53 delete-query-logging-config removes a Route53 query logging configuration. | high |
| `route53-delete-traffic-policy` | aws route53 delete-traffic-policy permanently deletes a Route53 traffic policy. | high |
| `route53-delete-reusable-delegation-set` | aws route53 delete-reusable-delegation-set permanently deletes a reusable delegation set. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "dns.route53:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "dns.route53:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Generic DNS Tools

**Pack ID:** `dns.generic`

Protects against destructive or risky DNS tooling usage (nsupdate deletes, zone transfers).

### Keywords

Commands containing these keywords are checked against this pack:

- `nsupdate`
- `dig`
- `host`
- `nslookup`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `dns-dig-safe` | `\bdig\b(?!.*\baxfr\b)(?!.*\bixfr\b)` |
| `dns-host-safe` | `\bhost\b` |
| `dns-nslookup-safe` | `\bnslookup\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `dns-nsupdate-delete` | nsupdate delete commands remove DNS records. | high |
| `dns-nsupdate-local` | nsupdate -l applies local updates which can modify DNS records. | high |
| `dns-dig-zone-transfer` | dig AXFR/IXFR zone transfers can exfiltrate full zone data. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "dns.generic:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "dns.generic:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/email.md
================================================
# Email Packs

This document describes packs in the `email` category.

## Packs in this Category

- [AWS SES](#emailses)
- [SendGrid](#emailsendgrid)
- [Mailgun](#emailmailgun)
- [Postmark](#emailpostmark)

---

## AWS SES

**Pack ID:** `email.ses`

Protects against destructive AWS Simple Email Service operations like identity deletion, template deletion, and configuration set removal.

### Keywords

Commands containing these keywords are checked against this pack:

- `ses`
- `sesv2`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `ses-list-identities` | `\baws\s+ses\s+list-identities\b` |
| `ses-list-templates` | `\baws\s+ses\s+list-templates\b` |
| `ses-list-configuration-sets` | `\baws\s+ses\s+list-configuration-sets\b` |
| `ses-list-receipt-rules` | `\baws\s+ses\s+list-receipt-rules\b` |
| `ses-list-receipt-rule-sets` | `\baws\s+ses\s+list-receipt-rule-sets\b` |
| `ses-get-identity-verification-attributes` | `\baws\s+ses\s+get-identity-verification-attributes\b` |
| `ses-get-identity-dkim-attributes` | `\baws\s+ses\s+get-identity-dkim-attributes\b` |
| `ses-get-identity-notification-attributes` | `\baws\s+ses\s+get-identity-notification-attributes\b` |
| `ses-get-template` | `\baws\s+ses\s+get-template\b` |
| `ses-describe-configuration-set` | `\baws\s+ses\s+describe-configuration-set\b` |
| `ses-describe-receipt-rule` | `\baws\s+ses\s+describe-receipt-rule\b` |
| `ses-describe-receipt-rule-set` | `\baws\s+ses\s+describe-receipt-rule-set\b` |
| `ses-get-send-quota` | `\baws\s+ses\s+get-send-quota\b` |
| `ses-get-send-statistics` | `\baws\s+ses\s+get-send-statistics\b` |
| `sesv2-list-email-identities` | `\baws\s+sesv2\s+list-email-identities\b` |
| `sesv2-list-email-templates` | `\baws\s+sesv2\s+list-email-templates\b` |
| `sesv2-list-configuration-sets` | `\baws\s+sesv2\s+list-configuration-sets\b` |
| `sesv2-list-contact-lists` | `\baws\s+sesv2\s+list-contact-lists\b` |
| `sesv2-list-dedicated-ip-pools` | `\baws\s+sesv2\s+list-dedicated-ip-pools\b` |
| `sesv2-get-email-identity` | `\baws\s+sesv2\s+get-email-identity\b` |
| `sesv2-get-email-template` | `\baws\s+sesv2\s+get-email-template\b` |
| `sesv2-get-configuration-set` | `\baws\s+sesv2\s+get-configuration-set\b` |
| `sesv2-get-contact-list` | `\baws\s+sesv2\s+get-contact-list\b` |
| `sesv2-get-dedicated-ip-pool` | `\baws\s+sesv2\s+get-dedicated-ip-pool\b` |
| `sesv2-get-account` | `\baws\s+sesv2\s+get-account\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `ses-delete-identity` | aws ses delete-identity removes a verified email identity. | high |
| `ses-delete-template` | aws ses delete-template removes an email template. | high |
| `ses-delete-configuration-set` | aws ses delete-configuration-set removes a configuration set. | high |
| `ses-delete-receipt-rule-set` | aws ses delete-receipt-rule-set removes a receipt rule set. | high |
| `ses-delete-receipt-rule` | aws ses delete-receipt-rule removes a receipt rule. | high |
| `sesv2-delete-email-identity` | aws sesv2 delete-email-identity removes a verified email identity. | high |
| `sesv2-delete-email-template` | aws sesv2 delete-email-template removes an email template. | high |
| `sesv2-delete-configuration-set` | aws sesv2 delete-configuration-set removes a configuration set. | high |
| `sesv2-delete-contact-list` | aws sesv2 delete-contact-list removes a contact list. | high |
| `sesv2-delete-dedicated-ip-pool` | aws sesv2 delete-dedicated-ip-pool removes a dedicated IP pool. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "email.ses:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "email.ses:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## SendGrid

**Pack ID:** `email.sendgrid`

Protects against destructive SendGrid API operations like template deletion, API key deletion, and domain authentication removal.

### Keywords

Commands containing these keywords are checked against this pack:

- `sendgrid`
- `api.sendgrid.com`

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `sendgrid-delete-template` | DELETE to SendGrid /v3/templates removes a transactional template. | high |
| `sendgrid-delete-api-key` | DELETE to SendGrid /v3/api_keys removes an API key. | high |
| `sendgrid-delete-whitelabel-domain` | DELETE to SendGrid /v3/whitelabel/domains removes domain authentication. | high |
| `sendgrid-delete-sender` | DELETE to SendGrid /v3/senders or /v3/verified_senders removes a sender identity. | high |
| `sendgrid-delete-teammate` | DELETE to SendGrid /v3/teammates removes a teammate from the account. | high |
| `sendgrid-delete-suppression` | DELETE to SendGrid suppression endpoints removes entries from suppression lists. | high |
| `sendgrid-delete-webhook` | DELETE to SendGrid /v3/user/webhooks removes a webhook configuration. | high |
| `sendgrid-delete-subuser` | DELETE to SendGrid /v3/subusers removes a subuser account. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "email.sendgrid:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "email.sendgrid:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Mailgun

**Pack ID:** `email.mailgun`

Protects against destructive Mailgun API operations like domain deletion, route deletion, and mailing list removal.

### Keywords

Commands containing these keywords are checked against this pack:

- `mailgun`
- `api.mailgun.net`

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `mailgun-delete-domain` | DELETE to Mailgun /v3/domains removes a domain configuration. | high |
| `mailgun-delete-route` | DELETE to Mailgun /v3/routes removes an email route. | high |
| `mailgun-delete-list` | DELETE to Mailgun /v3/lists removes a mailing list. | high |
| `mailgun-delete-template` | DELETE to Mailgun templates endpoint removes an email template. | high |
| `mailgun-delete-webhook` | DELETE to Mailgun webhooks endpoint removes a webhook. | high |
| `mailgun-delete-credential` | DELETE to Mailgun credentials endpoint removes SMTP credentials. | high |
| `mailgun-delete-tag` | DELETE to Mailgun tags endpoint removes a tag. | high |
| `mailgun-delete-suppression` | DELETE to Mailgun suppression endpoints removes suppression entries. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "email.mailgun:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "email.mailgun:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Postmark

**Pack ID:** `email.postmark`

Protects against destructive Postmark API operations like server deletion, template deletion, and sender signature removal.

### Keywords

Commands containing these keywords are checked against this pack:

- `postmark`
- `api.postmarkapp.com`

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `postmark-delete-server` | DELETE to Postmark /servers removes a server configuration. | high |
| `postmark-delete-template` | DELETE to Postmark /templates removes an email template. | high |
| `postmark-delete-domain` | DELETE to Postmark /domains removes a domain configuration. | high |
| `postmark-delete-sender-signature` | DELETE to Postmark /senders removes a sender signature. | high |
| `postmark-delete-webhook` | DELETE to Postmark /webhooks removes a webhook configuration. | high |
| `postmark-delete-suppression` | DELETE to Postmark suppressions endpoint removes suppression entries. | high |
| `postmark-delete-message-stream` | DELETE to Postmark /message-streams removes a message stream. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "email.postmark:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "email.postmark:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/featureflags.md
================================================
# Feature Flags Packs

This document describes packs in the `featureflags` category.

## Packs in this Category

- [Flipt](#featureflagsflipt)
- [LaunchDarkly](#featureflagslaunchdarkly)
- [Split.io](#featureflagssplit)
- [Unleash](#featureflagsunleash)

---

## Flipt

**Pack ID:** `featureflags.flipt`

Protects against destructive Flipt CLI and API operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `flipt`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `flipt-flag-list` | `flipt\s+flag\s+list\b` |
| `flipt-flag-get` | `flipt\s+flag\s+get\b` |
| `flipt-flag-create` | `flipt\s+flag\s+create\b` |
| `flipt-flag-update` | `flipt\s+flag\s+update\b` |
| `flipt-segment-list` | `flipt\s+segment\s+list\b` |
| `flipt-segment-get` | `flipt\s+segment\s+get\b` |
| `flipt-segment-create` | `flipt\s+segment\s+create\b` |
| `flipt-namespace-list` | `flipt\s+namespace\s+list\b` |
| `flipt-namespace-get` | `flipt\s+namespace\s+get\b` |
| `flipt-namespace-create` | `flipt\s+namespace\s+create\b` |
| `flipt-rule-list` | `flipt\s+rule\s+list\b` |
| `flipt-rule-get` | `flipt\s+rule\s+get\b` |
| `flipt-rule-create` | `flipt\s+rule\s+create\b` |
| `flipt-evaluate` | `flipt\s+evaluate\b` |
| `flipt-help` | `flipt\s+(?:--help\|-h\|help)\b` |
| `flipt-version` | `flipt\s+(?:--version\|version)\b` |
| `flipt-server` | `flipt\s+(?:server\|serve)\b` |
| `flipt-config` | `flipt\s+config\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `flipt-flag-delete` | flipt flag delete permanently removes a feature flag. This cannot be undone. | high |
| `flipt-segment-delete` | flipt segment delete removes a segment and its constraints. | high |
| `flipt-namespace-delete` | flipt namespace delete removes a namespace and all its flags, segments, and rules. | high |
| `flipt-rule-delete` | flipt rule delete removes a targeting rule from a flag. | high |
| `flipt-constraint-delete` | flipt constraint delete removes a constraint from a segment. | high |
| `flipt-variant-delete` | flipt variant delete removes a variant from a flag. | high |
| `flipt-distribution-delete` | flipt distribution delete removes a distribution from a rule. | high |
| `flipt-api-delete` | DELETE request to Flipt API can remove flags, segments, or rules. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "featureflags.flipt:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "featureflags.flipt:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## LaunchDarkly

**Pack ID:** `featureflags.launchdarkly`

Protects against destructive LaunchDarkly CLI and API operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `ldcli`
- `launchdarkly`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `ldcli-flags-list` | `ldcli\s+flags\s+list\b` |
| `ldcli-flags-get` | `ldcli\s+flags\s+get\b` |
| `ldcli-flags-create` | `ldcli\s+flags\s+create\b` |
| `ldcli-flags-update` | `ldcli\s+flags\s+update\b` |
| `ldcli-projects-list` | `ldcli\s+projects\s+list\b` |
| `ldcli-projects-get` | `ldcli\s+projects\s+get\b` |
| `ldcli-projects-create` | `ldcli\s+projects\s+create\b` |
| `ldcli-environments-list` | `ldcli\s+environments\s+list\b` |
| `ldcli-environments-get` | `ldcli\s+environments\s+get\b` |
| `ldcli-environments-create` | `ldcli\s+environments\s+create\b` |
| `ldcli-segments-list` | `ldcli\s+segments\s+list\b` |
| `ldcli-segments-get` | `ldcli\s+segments\s+get\b` |
| `ldcli-segments-create` | `ldcli\s+segments\s+create\b` |
| `ldcli-metrics-list` | `ldcli\s+metrics\s+list\b` |
| `ldcli-metrics-get` | `ldcli\s+metrics\s+get\b` |
| `ldcli-help` | `ldcli\s+(?:--help\|-h\|help)\b` |
| `ldcli-version` | `ldcli\s+(?:--version\|version)\b` |
| `launchdarkly-api-get` | `curl\s+.*(?:-X\s+GET\|--request\s+GET)\s+.*app\.launchdarkly\.com/api` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `ldcli-flags-delete` | ldcli flags delete permanently removes a feature flag. This cannot be undone. | high |
| `ldcli-flags-archive` | ldcli flags archive soft-deletes a feature flag. While recoverable, this affects all environments. | high |
| `ldcli-projects-delete` | ldcli projects delete removes an entire project and all its flags, environments, and settings. | high |
| `ldcli-environments-delete` | ldcli environments delete removes an environment and all its flag configurations. | high |
| `ldcli-segments-delete` | ldcli segments delete removes a user segment and its targeting rules. | high |
| `ldcli-metrics-delete` | ldcli metrics delete removes a metric and its experiment data. | high |
| `launchdarkly-api-delete-environments` | DELETE request to LaunchDarkly API removes environments. | high |
| `launchdarkly-api-delete-flags` | DELETE request to LaunchDarkly API removes feature flags. | high |
| `launchdarkly-api-delete-segments` | DELETE request to LaunchDarkly API removes segments. | high |
| `launchdarkly-api-delete-projects` | DELETE request to LaunchDarkly API removes projects. | high |
| `launchdarkly-api-delete-generic` | DELETE request to LaunchDarkly API can remove resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "featureflags.launchdarkly:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "featureflags.launchdarkly:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Split.io

**Pack ID:** `featureflags.split`

Protects against destructive Split.io CLI and API operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `split`
- `api.split.io`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `split-splits-list` | `split\s+splits\s+list\b` |
| `split-splits-get` | `split\s+splits\s+get\b` |
| `split-splits-create` | `split\s+splits\s+create\b` |
| `split-splits-update` | `split\s+splits\s+update\b` |
| `split-environments-list` | `split\s+environments\s+list\b` |
| `split-environments-get` | `split\s+environments\s+get\b` |
| `split-environments-create` | `split\s+environments\s+create\b` |
| `split-segments-list` | `split\s+segments\s+list\b` |
| `split-segments-get` | `split\s+segments\s+get\b` |
| `split-segments-create` | `split\s+segments\s+create\b` |
| `split-traffic-types-list` | `split\s+traffic-types\s+list\b` |
| `split-traffic-types-get` | `split\s+traffic-types\s+get\b` |
| `split-workspaces-list` | `split\s+workspaces\s+list\b` |
| `split-workspaces-get` | `split\s+workspaces\s+get\b` |
| `split-help` | `split\s+(?:--help\|-h\|help)\b` |
| `split-version` | `split\s+(?:--version\|version)\b` |
| `split-api-get` | `curl\s+.*(?:-X\s+GET\|--request\s+GET)\s+.*api\.split\.io` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `split-splits-delete` | split splits delete permanently removes a split definition. This cannot be undone. | high |
| `split-splits-kill` | split splits kill terminates a split, stopping all traffic to treatments. | high |
| `split-environments-delete` | split environments delete removes an environment and all its configurations. | high |
| `split-segments-delete` | split segments delete removes a segment and its targeting rules. | high |
| `split-traffic-types-delete` | split traffic-types delete removes a traffic type. This affects all splits using it. | high |
| `split-workspaces-delete` | split workspaces delete removes a workspace and all its resources. | high |
| `split-api-delete-splits` | DELETE request to Split.io API removes split definitions. | high |
| `split-api-delete-environments` | DELETE request to Split.io API removes environments. | high |
| `split-api-delete-segments` | DELETE request to Split.io API removes segments. | high |
| `split-api-delete-generic` | DELETE request to Split.io API can remove resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "featureflags.split:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "featureflags.split:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Unleash

**Pack ID:** `featureflags.unleash`

Protects against destructive Unleash CLI and API operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `unleash`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `unleash-features-list` | `unleash\s+features?\s+list\b` |
| `unleash-features-get` | `unleash\s+features?\s+get\b` |
| `unleash-features-create` | `unleash\s+features?\s+create\b` |
| `unleash-features-update` | `unleash\s+features?\s+update\b` |
| `unleash-features-enable` | `unleash\s+features?\s+enable\b` |
| `unleash-features-disable` | `unleash\s+features?\s+disable\b` |
| `unleash-projects-list` | `unleash\s+projects?\s+list\b` |
| `unleash-projects-get` | `unleash\s+projects?\s+get\b` |
| `unleash-projects-create` | `unleash\s+projects?\s+create\b` |
| `unleash-environments-list` | `unleash\s+environments?\s+list\b` |
| `unleash-environments-get` | `unleash\s+environments?\s+get\b` |
| `unleash-strategies-list` | `unleash\s+strategies?\s+list\b` |
| `unleash-strategies-get` | `unleash\s+strategies?\s+get\b` |
| `unleash-help` | `unleash\s+(?:--help\|-h\|help)\b` |
| `unleash-version` | `unleash\s+(?:--version\|version)\b` |
| `unleash-api-get` | `curl\s+.*(?:-X\s+GET\|--request\s+GET)\s+.*/api/admin/` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `unleash-features-delete` | unleash features delete permanently removes a feature toggle. This cannot be undone. | high |
| `unleash-features-archive` | unleash features archive soft-deletes a feature toggle. | high |
| `unleash-projects-delete` | unleash projects delete removes a project and all its feature toggles. | high |
| `unleash-environments-delete` | unleash environments delete removes an environment. | high |
| `unleash-strategies-delete` | unleash strategies delete removes a custom strategy. | high |
| `unleash-api-keys-delete` | unleash api-keys delete removes an API key. | high |
| `unleash-api-delete-features` | DELETE request to Unleash API removes feature toggles. | high |
| `unleash-api-delete-projects` | DELETE request to Unleash API removes projects. | high |
| `unleash-api-delete-generic` | DELETE request to Unleash API can remove resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "featureflags.unleash:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "featureflags.unleash:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/infrastructure.md
================================================
# Infrastructure as Code Packs

This document describes packs in the `infrastructure` category.

## Packs in this Category

- [Terraform](#infrastructureterraform)
- [Ansible](#infrastructureansible)
- [Pulumi](#infrastructurepulumi)

---

## Terraform

**Pack ID:** `infrastructure.terraform`

Protects against destructive Terraform operations like destroy, taint, and apply with -auto-approve

### Keywords

Commands containing these keywords are checked against this pack:

- `terraform`
- `destroy`
- `taint`
- `state`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `terraform-plan` | `terraform\s+plan(?!\s+.*-destroy)` |
| `terraform-init` | `terraform\s+init` |
| `terraform-validate` | `terraform\s+validate` |
| `terraform-fmt` | `terraform\s+fmt` |
| `terraform-show` | `terraform\s+show` |
| `terraform-output` | `terraform\s+output` |
| `terraform-state-list` | `terraform\s+state\s+list` |
| `terraform-state-show` | `terraform\s+state\s+show` |
| `terraform-graph` | `terraform\s+graph` |
| `terraform-version` | `terraform\s+version` |
| `terraform-providers` | `terraform\s+providers` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `destroy` | terraform destroy removes ALL managed infrastructure. Use 'terraform plan -destroy' first. | high |
| `plan-destroy` | terraform plan -destroy shows what would be destroyed. Review carefully before applying. | high |
| `apply-auto-approve` | terraform apply -auto-approve skips confirmation. Remove -auto-approve for safety. | high |
| `taint` | terraform taint marks a resource to be destroyed and recreated on next apply. | high |
| `state-rm` | terraform state rm removes resource from state without destroying it. Resource becomes unmanaged. | high |
| `state-mv` | terraform state mv moves resources in state. Incorrect moves can cause resource recreation. | high |
| `force-unlock` | terraform force-unlock removes state lock. Only use if lock is stale. | high |
| `workspace-delete` | terraform workspace delete removes a workspace. Ensure it's not in use. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "infrastructure.terraform:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "infrastructure.terraform:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Ansible

**Pack ID:** `infrastructure.ansible`

Protects against destructive Ansible operations like dangerous shell commands and unchecked playbook runs

### Keywords

Commands containing these keywords are checked against this pack:

- `ansible`
- `playbook`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `ansible-check` | `ansible(?:-playbook)?\s+.*--check` |
| `ansible-diff` | `ansible(?:-playbook)?\s+.*--diff` |
| `ansible-list-hosts` | `ansible(?:-playbook)?\s+.*--list-hosts` |
| `ansible-list-tasks` | `ansible(?:-playbook)?\s+.*--list-tasks` |
| `ansible-syntax` | `ansible(?:-playbook)?\s+.*--syntax-check` |
| `ansible-inventory` | `ansible-inventory` |
| `ansible-doc` | `ansible-doc` |
| `ansible-config` | `ansible-config` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `shell-rm-rf` | Ansible shell/command with 'rm -rf' is destructive. Review carefully. | high |
| `shell-reboot` | Ansible shell/command with reboot/shutdown affects system availability. | high |
| `playbook-all-hosts` | ansible-playbook without --check or --limit may affect all hosts. Use --check first. | high |
| `extra-vars-delete` | Ansible extra-vars contains potentially destructive keywords. Review carefully. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "infrastructure.ansible:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "infrastructure.ansible:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Pulumi

**Pack ID:** `infrastructure.pulumi`

Protects against destructive Pulumi operations like destroy and up with -y (auto-approve)

### Keywords

Commands containing these keywords are checked against this pack:

- `pulumi`
- `destroy`
- `state`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `pulumi-preview` | `pulumi\s+preview` |
| `pulumi-stack-ls` | `pulumi\s+stack\s+ls` |
| `pulumi-stack-select` | `pulumi\s+stack\s+select` |
| `pulumi-stack-init` | `pulumi\s+stack\s+init` |
| `pulumi-config` | `pulumi\s+config` |
| `pulumi-whoami` | `pulumi\s+whoami` |
| `pulumi-version` | `pulumi\s+version` |
| `pulumi-about` | `pulumi\s+about` |
| `pulumi-logs` | `pulumi\s+logs` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `destroy` | pulumi destroy removes ALL managed infrastructure. Use 'pulumi preview --diff' first. | high |
| `up-yes` | pulumi up -y skips confirmation. Remove -y flag for safety. | high |
| `state-delete` | pulumi state delete removes resource from state without destroying it. | high |
| `stack-rm` | pulumi stack rm removes the stack. Use --force only if stack is empty. | high |
| `refresh-yes` | pulumi refresh -y auto-approves state changes. Review changes first. | high |
| `cancel` | pulumi cancel terminates an in-progress update, which may leave resources in inconsistent state. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "infrastructure.pulumi:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "infrastructure.pulumi:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/kubernetes.md
================================================
# Kubernetes Packs

This document describes packs in the `kubernetes` category.

## Packs in this Category

- [kubectl](#kuberneteskubectl)
- [Helm](#kuberneteshelm)
- [Kustomize](#kuberneteskustomize)

---

## kubectl

**Pack ID:** `kubernetes.kubectl`

Protects against destructive kubectl operations like delete namespace, drain, and mass deletion

### Keywords

Commands containing these keywords are checked against this pack:

- `kubectl`
- `delete`
- `drain`
- `cordon`
- `taint`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `kubectl-get` | `kubectl\s+get` |
| `kubectl-describe` | `kubectl\s+describe` |
| `kubectl-logs` | `kubectl\s+logs` |
| `kubectl-dry-run` | `kubectl\s+.*--dry-run(?:=(?:client\|server\|none))?` |
| `kubectl-diff` | `kubectl\s+diff` |
| `kubectl-explain` | `kubectl\s+explain` |
| `kubectl-top` | `kubectl\s+top` |
| `kubectl-config` | `kubectl\s+config` |
| `kubectl-api` | `kubectl\s+api-(?:resources\|versions)` |
| `kubectl-version` | `kubectl\s+version` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `delete-namespace` | kubectl delete namespace removes the entire namespace and ALL resources within it. | high |
| `delete-all` | kubectl delete --all removes ALL resources of that type. Use --dry-run=client first. | high |
| `delete-all-namespaces` | kubectl delete with -A/--all-namespaces affects ALL namespaces. Very dangerous! | high |
| `drain-node` | kubectl drain evicts all pods from a node. Ensure proper pod disruption budgets. | high |
| `cordon-node` | kubectl cordon marks a node unschedulable. Existing pods continue running. | high |
| `taint-noexecute` | kubectl taint with NoExecute evicts existing pods that don't tolerate the taint. | high |
| `delete-workload` | kubectl delete deployment/statefulset/daemonset removes the workload. Use --dry-run first. | high |
| `delete-pvc` | kubectl delete pvc may permanently delete data if ReclaimPolicy is Delete. | high |
| `delete-pv` | kubectl delete pv may permanently delete the underlying storage. | high |
| `scale-to-zero` | kubectl scale --replicas=0 stops all pods for the workload. | high |
| `delete-force` | kubectl delete --force --grace-period=0 immediately removes resources without graceful shutdown. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "kubernetes.kubectl:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "kubernetes.kubectl:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Helm

**Pack ID:** `kubernetes.helm`

Protects against destructive Helm operations like uninstall and rollback without dry-run

### Keywords

Commands containing these keywords are checked against this pack:

- `helm`
- `uninstall`
- `delete`
- `rollback`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `helm-list` | `helm\s+list` |
| `helm-status` | `helm\s+status` |
| `helm-history` | `helm\s+history` |
| `helm-show` | `helm\s+show` |
| `helm-inspect` | `helm\s+inspect` |
| `helm-get` | `helm\s+get` |
| `helm-search` | `helm\s+search` |
| `helm-repo` | `helm\s+repo` |
| `helm-dry-run` | `helm\s+.*--dry-run` |
| `helm-template` | `helm\s+template` |
| `helm-lint` | `helm\s+lint` |
| `helm-diff` | `helm\s+diff` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `uninstall` | helm uninstall removes the release and all its resources. Use --dry-run first. | high |
| `rollback` | helm rollback reverts to a previous release. Use --dry-run to preview changes. | high |
| `upgrade-force` | helm upgrade --force deletes and recreates resources, causing downtime. | high |
| `upgrade-reset-values` | helm upgrade --reset-values discards all previously set values. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "kubernetes.helm:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "kubernetes.helm:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Kustomize

**Pack ID:** `kubernetes.kustomize`

Protects against destructive Kustomize operations when combined with kubectl delete or applied without review

### Keywords

Commands containing these keywords are checked against this pack:

- `kustomize`
- `kubectl`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `kustomize-build` | `kustomize\s+build(?!\s*\\|)` |
| `kubectl-kustomize` | `kubectl\s+kustomize(?!\s*\\|)` |
| `kustomize-diff` | `kustomize\s+build\s+.*\\|\s*kubectl\s+diff` |
| `kustomize-dry-run` | `kustomize\s+build\s+.*\\|\s*kubectl\s+.*--dry-run` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `kustomize-delete` | kustomize build \| kubectl delete removes all resources in the kustomization. | high |
| `kubectl-kustomize-delete` | kubectl kustomize \| kubectl delete removes all resources in the kustomization. | high |
| `kubectl-delete-k` | kubectl delete -k removes all resources defined in the kustomization. Use --dry-run first. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "kubernetes.kustomize:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "kubernetes.kustomize:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/loadbalancer.md
================================================
# Load Balancer Packs

This document describes packs in the `loadbalancer` category.

## Packs in this Category

- [HAProxy](#loadbalancerhaproxy)
- [nginx](#loadbalancernginx)
- [Traefik](#loadbalancertraefik)
- [AWS ELB](#loadbalancerelb)

---

## HAProxy

**Pack ID:** `loadbalancer.haproxy`

Protects against destructive HAProxy load balancer operations like stopping the service or disabling backends via runtime API.

### Keywords

Commands containing these keywords are checked against this pack:

- `haproxy`
- `socat`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `haproxy-config-check` | `\bhaproxy\s+-c\b` |
| `haproxy-version` | `\bhaproxy\s+-v+\b` |
| `systemctl-status-haproxy` | `systemctl\s+status\s+haproxy(?:\.service)?\b` |
| `service-status-haproxy` | `service\s+haproxy\s+status\b` |
| `haproxy-socat-show` | `(?:echo\|printf)\s+['"]?show\s+(?:stat\|info\|servers\|backend\|pools\|sess\|errors\|table)['"]?\s*\\|\s*socat\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `haproxy-soft-stop` | haproxy -sf sends a soft stop signal, terminating the load balancer gracefully. | high |
| `haproxy-hard-stop` | haproxy -st sends a hard stop signal, immediately terminating the load balancer. | high |
| `haproxy-systemctl-stop` | systemctl stop haproxy stops the HAProxy service. | high |
| `haproxy-service-stop` | service haproxy stop stops the HAProxy service. | high |
| `haproxy-socat-disable-server` | Disabling a server via HAProxy runtime API removes it from the load balancer pool. | high |
| `haproxy-socat-shutdown-sessions` | Shutting down sessions via HAProxy runtime API terminates active connections. | high |
| `haproxy-socat-disable-frontend` | Disabling a frontend via HAProxy runtime API stops accepting new connections. | high |
| `haproxy-socat-shutdown-frontend` | Shutting down a frontend via HAProxy runtime API terminates it immediately. | high |
| `haproxy-config-delete` | Removing files from /etc/haproxy deletes HAProxy configuration. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "loadbalancer.haproxy:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "loadbalancer.haproxy:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## nginx

**Pack ID:** `loadbalancer.nginx`

Protects against destructive nginx load balancer operations like stopping the service or deleting config files.

### Keywords

Commands containing these keywords are checked against this pack:

- `nginx`
- `/etc/nginx`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `nginx-config-test` | `nginx\s+-t\b` |
| `nginx-config-dump` | `nginx\s+-T\b` |
| `nginx-version` | `nginx\s+-v\b` |
| `nginx-version-full` | `nginx\s+-V\b` |
| `nginx-reload` | `nginx\s+-s\s+reload\b` |
| `systemctl-status-nginx` | `systemctl\s+status\s+nginx(?:\.service)?\b` |
| `service-status-nginx` | `service\s+nginx\s+status\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `nginx-stop` | nginx -s stop shuts down nginx and stops the load balancer. | high |
| `nginx-quit` | nginx -s quit gracefully stops nginx and halts traffic handling. | high |
| `systemctl-stop-nginx` | systemctl stop nginx stops the nginx service and disrupts traffic. | high |
| `service-stop-nginx` | service nginx stop stops the nginx service and disrupts traffic. | high |
| `nginx-config-delete` | Removing files from /etc/nginx deletes nginx configuration. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "loadbalancer.nginx:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "loadbalancer.nginx:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Traefik

**Pack ID:** `loadbalancer.traefik`

Protects against destructive Traefik load balancer operations like stopping containers, deleting config, or API deletions.

### Keywords

Commands containing these keywords are checked against this pack:

- `traefik`
- `ingressroute`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `traefik-version` | `\btraefik\s+version\b` |
| `traefik-healthcheck` | `\btraefik\s+healthcheck\b` |
| `traefik-api-get` | `curl\b.*\s-X\s*GET\b.*\btraefik\b.*\b/api/` |
| `traefik-api-read` | `curl\b.*\btraefik\b.*\b/api/(?:overview\|entrypoints\|routers\|services\|middlewares\|version\|rawdata)` |
| `docker-traefik-inspect` | `docker\s+(?:inspect\|logs)\s+.*\btraefik\b` |
| `kubectl-traefik-get` | `kubectl\s+(?:get\|describe)\s+.*\bingressroute` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `traefik-docker-stop` | Stopping the Traefik container halts all traffic routing. | high |
| `traefik-docker-rm` | Removing the Traefik container destroys the load balancer. | high |
| `traefik-compose-down` | docker-compose down on Traefik stops and removes the load balancer. | high |
| `traefik-kubectl-delete-pod` | Deleting Traefik pods/deployments disrupts traffic routing. | high |
| `traefik-kubectl-delete-ingressroute` | Deleting IngressRoute CRDs removes Traefik routing rules. | high |
| `traefik-config-delete` | Removing Traefik config files disrupts load balancer configuration. | high |
| `traefik-api-delete` | DELETE operations against Traefik API can remove routing configuration. | high |
| `traefik-systemctl-stop` | systemctl stop traefik stops the Traefik service. | high |
| `traefik-service-stop` | service traefik stop stops the Traefik service. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "loadbalancer.traefik:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "loadbalancer.traefik:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## AWS ELB

**Pack ID:** `loadbalancer.elb`

Protects against destructive AWS Elastic Load Balancing (ELB/ALB/NLB) operations like deleting load balancers, target groups, or deregistering targets from live traffic.

### Keywords

Commands containing these keywords are checked against this pack:

- `elbv2`
- `delete-load-balancer`
- `delete-target-group`
- `deregister-targets`
- `delete-listener`
- `delete-rule`
- `deregister-instances-from-load-balancer`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `elbv2-describe-load-balancers` | `\baws\b(?:\s+(?:--profile\|--region\|--output\|--endpoint-url)\s+\S+\|\s+--\S+)*\s+elbv2\s+describe-load-balancers\b` |
| `elbv2-describe-target-groups` | `\baws\b(?:\s+(?:--profile\|--region\|--output\|--endpoint-url)\s+\S+\|\s+--\S+)*\s+elbv2\s+describe-target-groups\b` |
| `elbv2-describe-target-health` | `\baws\b(?:\s+(?:--profile\|--region\|--output\|--endpoint-url)\s+\S+\|\s+--\S+)*\s+elbv2\s+describe-target-health\b` |
| `elb-describe-load-balancers` | `\baws\b(?:\s+(?:--profile\|--region\|--output\|--endpoint-url)\s+\S+\|\s+--\S+)*\s+elb\s+describe-load-balancers\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `elbv2-delete-load-balancer` | aws elbv2 delete-load-balancer permanently deletes the load balancer. | high |
| `elbv2-delete-target-group` | aws elbv2 delete-target-group permanently deletes the target group. | high |
| `elbv2-deregister-targets` | aws elbv2 deregister-targets removes targets from the load balancer, impacting live traffic. | high |
| `elbv2-delete-listener` | aws elbv2 delete-listener deletes a listener, potentially breaking traffic routing. | high |
| `elbv2-delete-rule` | aws elbv2 delete-rule deletes a listener rule, potentially breaking routing. | high |
| `elb-delete-load-balancer` | aws elb delete-load-balancer permanently deletes the classic load balancer. | high |
| `elb-deregister-instances` | aws elb deregister-instances-from-load-balancer removes instances from the load balancer, impacting live traffic. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "loadbalancer.elb:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "loadbalancer.elb:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/messaging.md
================================================
# Messaging Packs

This document describes packs in the `messaging` category.

## Packs in this Category

- [Apache Kafka](#messagingkafka)
- [RabbitMQ](#messagingrabbitmq)
- [NATS](#messagingnats)
- [AWS SQS/SNS](#messagingsqs_sns)

---

## Apache Kafka

**Pack ID:** `messaging.kafka`

Protects against destructive Kafka CLI operations like deleting topics, removing consumer groups, resetting offsets, and deleting records.

### Keywords

Commands containing these keywords are checked against this pack:

- `kafka-topics`
- `kafka-topics.sh`
- `kafka-consumer-groups`
- `kafka-consumer-groups.sh`
- `kafka-configs`
- `kafka-configs.sh`
- `kafka-acls`
- `kafka-acls.sh`
- `kafka-delete-records`
- `kafka-delete-records.sh`
- `kafka-console-consumer`
- `kafka-console-producer`
- `kafka-broker-api-versions`
- `rpk`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `kafka-topics-list` | `kafka-topics(?:\.sh)?\b.*\s--list\b` |
| `kafka-topics-describe` | `kafka-topics(?:\.sh)?\b.*\s--describe\b` |
| `kafka-consumer-groups-list` | `kafka-consumer-groups(?:\.sh)?\b.*\s--list\b` |
| `kafka-consumer-groups-describe` | `kafka-consumer-groups(?:\.sh)?\b.*\s--describe\b` |
| `kafka-acls-list` | `kafka-acls(?:\.sh)?\b.*\s--list\b` |
| `kafka-configs-describe` | `kafka-configs(?:\.sh)?\b.*\s--describe\b` |
| `kafka-console-consumer` | `kafka-console-consumer(?:\.sh)?\b` |
| `kafka-console-producer` | `kafka-console-producer(?:\.sh)?\b` |
| `kafka-broker-api-versions` | `kafka-broker-api-versions(?:\.sh)?\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `kafka-topics-delete` | kafka-topics --delete removes Kafka topics and data. | high |
| `kafka-consumer-groups-delete` | kafka-consumer-groups --delete removes consumer groups and offsets. | high |
| `kafka-consumer-groups-reset-offsets` | kafka-consumer-groups --reset-offsets rewinds offsets and can cause reprocessing. | high |
| `kafka-configs-delete-config` | kafka-configs --alter --delete-config removes broker/topic configs. | high |
| `kafka-acls-remove` | kafka-acls --remove deletes ACLs and can break access controls. | high |
| `kafka-delete-records` | kafka-delete-records deletes records up to specified offsets. | high |
| `rpk-topic-delete` | rpk topic delete removes topics (Kafka-compatible). | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "messaging.kafka:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "messaging.kafka:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## RabbitMQ

**Pack ID:** `messaging.rabbitmq`

Protects against destructive RabbitMQ operations like deleting queues/exchanges, purging queues, deleting vhosts, and resetting cluster state.

### Keywords

Commands containing these keywords are checked against this pack:

- `rabbitmqadmin`
- `rabbitmqctl`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `rabbitmqadmin-list` | `rabbitmqadmin(?:\s+--?\S+(?:\s+\S+)?)*\s+list\b` |
| `rabbitmqadmin-show` | `rabbitmqadmin(?:\s+--?\S+(?:\s+\S+)?)*\s+show\b` |
| `rabbitmqctl-status` | `rabbitmqctl(?:\s+--?\S+(?:\s+\S+)?)*\s+status\b` |
| `rabbitmqctl-list-queues` | `rabbitmqctl(?:\s+--?\S+(?:\s+\S+)?)*\s+list_queues\b` |
| `rabbitmqctl-cluster-status` | `rabbitmqctl(?:\s+--?\S+(?:\s+\S+)?)*\s+cluster_status\b` |
| `rabbitmqctl-report` | `rabbitmqctl(?:\s+--?\S+(?:\s+\S+)?)*\s+report\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `rabbitmqadmin-delete-queue` | rabbitmqadmin delete queue permanently deletes a queue. | high |
| `rabbitmqadmin-delete-exchange` | rabbitmqadmin delete exchange removes an exchange and its bindings. | high |
| `rabbitmqadmin-purge-queue` | rabbitmqadmin purge queue deletes ALL messages in the queue. | high |
| `rabbitmqctl-delete-vhost` | rabbitmqctl delete_vhost removes a vhost and all its resources. | high |
| `rabbitmqctl-forget-cluster-node` | rabbitmqctl forget_cluster_node permanently removes a node from the cluster. | high |
| `rabbitmqctl-reset` | rabbitmqctl reset wipes all configuration, queues, and bindings on the node. | high |
| `rabbitmqctl-force-reset` | rabbitmqctl force_reset wipes node data and can break cluster state. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "messaging.rabbitmq:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "messaging.rabbitmq:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## NATS

**Pack ID:** `messaging.nats`

Protects against destructive NATS/JetStream operations like deleting streams, consumers, key-value entries, objects, and accounts.

### Keywords

Commands containing these keywords are checked against this pack:

- `nats`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `nats-stream-info` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+stream\s+info\b` |
| `nats-stream-ls` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+stream\s+ls\b` |
| `nats-consumer-info` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+consumer\s+info\b` |
| `nats-consumer-ls` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+consumer\s+ls\b` |
| `nats-kv-get` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+kv\s+get\b` |
| `nats-kv-ls` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+kv\s+ls\b` |
| `nats-pub` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+pub\b` |
| `nats-sub` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+sub\b` |
| `nats-server-info` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+server\s+info\b` |
| `nats-bench` | `nats(?:\s+--?\S+(?:\s+\S+)?)*\s+bench\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `nats-stream-delete` | nats stream delete/rm removes a JetStream stream and all its messages. | high |
| `nats-stream-purge` | nats stream purge deletes ALL messages from the stream. | high |
| `nats-consumer-delete` | nats consumer delete/rm removes a JetStream consumer. | high |
| `nats-kv-delete` | nats kv del/rm deletes key-value entries. | high |
| `nats-object-delete` | nats object delete removes an object from the store. | high |
| `nats-account-delete` | nats account delete removes an account and its resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "messaging.nats:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "messaging.nats:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## AWS SQS/SNS

**Pack ID:** `messaging.sqs_sns`

Protects against destructive AWS SQS and SNS operations like deleting queues, purging messages, deleting topics, and removing subscriptions.

### Keywords

Commands containing these keywords are checked against this pack:

- `aws`
- `sqs`
- `sns`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `aws-sqs-list-queues` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sqs\s+list-queues\b` |
| `aws-sqs-get-queue-attributes` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sqs\s+get-queue-attributes\b` |
| `aws-sqs-receive-message` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sqs\s+receive-message\b` |
| `aws-sns-list-topics` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sns\s+list-topics\b` |
| `aws-sns-list-subscriptions` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sns\s+list-subscriptions\b` |
| `aws-sns-get-topic-attributes` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+sns\s+get-topic-attributes\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `aws-sqs-delete-queue` | aws sqs delete-queue permanently deletes an SQS queue. | high |
| `aws-sqs-purge-queue` | aws sqs purge-queue deletes ALL messages in the queue. | high |
| `aws-sqs-delete-message-batch` | aws sqs delete-message-batch removes multiple messages from the queue. | high |
| `aws-sqs-delete-message` | aws sqs delete-message removes a message from the queue. | high |
| `aws-sns-delete-topic` | aws sns delete-topic removes an SNS topic and its subscriptions. | high |
| `aws-sns-unsubscribe` | aws sns unsubscribe removes a subscription and stops message delivery. | high |
| `aws-sns-remove-permission` | aws sns remove-permission revokes permissions on a topic. | high |
| `aws-sns-delete-platform-application` | aws sns delete-platform-application removes a platform application. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "messaging.sqs_sns:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "messaging.sqs_sns:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/monitoring.md
================================================
# Monitoring Packs

This document describes packs in the `monitoring` category.

## Packs in this Category

- [Splunk](#monitoringsplunk)
- [Datadog](#monitoringdatadog)
- [PagerDuty](#monitoringpagerduty)
- [New Relic](#monitoringnewrelic)
- [Prometheus/Grafana](#monitoringprometheus)

---

## Splunk

**Pack ID:** `monitoring.splunk`

Protects against destructive Splunk CLI/API operations like index removal and REST API DELETE calls

### Keywords

Commands containing these keywords are checked against this pack:

- `splunk`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `splunk-list` | `splunk\s+list\b` |
| `splunk-show` | `splunk\s+show\b` |
| `splunk-search` | `splunk\s+search\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `splunk-remove-index` | splunk remove index deletes an index and its data permanently. | high |
| `splunk-clean-eventdata` | splunk clean eventdata permanently deletes indexed data. | high |
| `splunk-delete-user-role` | splunk delete user/role removes access configurations. Verify before deleting. | high |
| `splunk-api-delete` | Splunk REST DELETE calls can permanently remove objects. Verify the endpoint. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "monitoring.splunk:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "monitoring.splunk:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Datadog

**Pack ID:** `monitoring.datadog`

Protects against destructive Datadog CLI/API operations like deleting monitors and dashboards.

### Keywords

Commands containing these keywords are checked against this pack:

- `datadog-ci`
- `datadoghq`
- `datadog`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `datadog-ci-monitors-list` | `datadog-ci\s+monitors\s+(?:get\|list)\b` |
| `datadog-ci-dashboards-list` | `datadog-ci\s+dashboards\s+(?:get\|list)\b` |
| `datadog-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*api\.datadoghq\.com` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `datadog-ci-monitors-delete` | datadog-ci monitors delete removes a Datadog monitor. | high |
| `datadog-ci-dashboards-delete` | datadog-ci dashboards delete removes a Datadog dashboard. | high |
| `datadog-api-delete` | Datadog API DELETE calls remove monitors/dashboards/synthetics. | high |
| `terraform-datadog-destroy` | terraform destroy targeting Datadog resources removes monitoring infrastructure. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "monitoring.datadog:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "monitoring.datadog:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## PagerDuty

**Pack ID:** `monitoring.pagerduty`

Protects against destructive PagerDuty CLI/API operations like deleting services and schedules (which can break incident routing).

### Keywords

Commands containing these keywords are checked against this pack:

- `pd`
- `pagerduty`
- `api.pagerduty.com`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `pd-service-read` | `\bpd\b(?:\s+--?\S+(?:\s+\S+)?)*\s+service\s+(?:list\|get)\b` |
| `pd-schedule-read` | `\bpd\b(?:\s+--?\S+(?:\s+\S+)?)*\s+schedule\s+(?:list\|get)\b` |
| `pd-incident-list` | `\bpd\b(?:\s+--?\S+(?:\s+\S+)?)*\s+incident\s+list\b` |
| `pagerduty-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*api\.pagerduty\.com` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `pd-service-delete` | pd service delete removes a PagerDuty service, which can break incident routing. | high |
| `pd-schedule-delete` | pd schedule delete removes a PagerDuty schedule. | high |
| `pd-escalation-policy-delete` | pd escalation-policy delete removes a PagerDuty escalation policy. | high |
| `pd-user-delete` | pd user delete removes a PagerDuty user. | high |
| `pd-team-delete` | pd team delete removes a PagerDuty team. | high |
| `pagerduty-api-delete-service` | PagerDuty API DELETE /services/{id} deletes a PagerDuty service. | high |
| `pagerduty-api-delete-schedule` | PagerDuty API DELETE /schedules/{id} deletes a PagerDuty schedule. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "monitoring.pagerduty:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "monitoring.pagerduty:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## New Relic

**Pack ID:** `monitoring.newrelic`

Protects against destructive New Relic CLI/API operations like deleting entities or alerting resources.

### Keywords

Commands containing these keywords are checked against this pack:

- `newrelic`
- `api.newrelic.com`
- `graphql`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `newrelic-entity-search` | `\bnewrelic\b(?:\s+--?\S+(?:\s+\S+)?)*\s+entity\s+search\b` |
| `newrelic-apm-app-get` | `\bnewrelic\b(?:\s+--?\S+(?:\s+\S+)?)*\s+apm\s+application\s+get\b` |
| `newrelic-query` | `\bnewrelic\b(?:\s+--?\S+(?:\s+\S+)?)*\s+query\b` |
| `newrelic-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*api\.newrelic\.com` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `newrelic-entity-delete` | newrelic entity delete removes a New Relic entity, impacting observability. | high |
| `newrelic-apm-app-delete` | newrelic apm application delete removes an APM application. | high |
| `newrelic-workload-delete` | newrelic workload delete removes a workload definition. | high |
| `newrelic-synthetics-delete` | newrelic synthetics delete removes a synthetics monitor. | high |
| `newrelic-api-delete` | New Relic API DELETE calls remove monitoring/alerting resources. | high |
| `newrelic-graphql-delete-mutation` | New Relic GraphQL delete mutations can remove monitoring resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "monitoring.newrelic:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "monitoring.newrelic:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Prometheus/Grafana

**Pack ID:** `monitoring.prometheus`

Protects against destructive Prometheus/Grafana operations like deleting time series data or dashboards/datasources.

### Keywords

Commands containing these keywords are checked against this pack:

- `promtool`
- `grafana-cli`
- `/api/v1/admin/tsdb/delete_series`
- `delete_series`
- `/api/dashboards`
- `/api/datasources`
- `/api/alert-notifications`
- `/etc/prometheus`
- `rules.d`
- `prometheusrule`
- `servicemonitor`
- `podmonitor`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `promtool-check-rules` | `\bpromtool\b(?:\s+--?\S+(?:\s+\S+)?)*\s+check\s+rules\b` |
| `promtool-query` | `\bpromtool\b(?:\s+--?\S+(?:\s+\S+)?)*\s+query\b` |
| `prometheus-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*\/api\/v1\/` |
| `grafana-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*\/api\/` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `prometheus-rules-file-delete` | Deleting Prometheus rule/config files can break alerting and monitoring coverage. | high |
| `prometheus-tsdb-delete-series` | Prometheus TSDB delete_series permanently deletes time series data. | high |
| `kubectl-delete-prometheus-operator-resources` | kubectl delete of Prometheus Operator resources (PrometheusRule/ServiceMonitor/PodMonitor) removes alerting/target configuration. | high |
| `grafana-cli-plugins-uninstall` | grafana-cli plugins uninstall removes a Grafana plugin, potentially breaking dashboards. | high |
| `grafana-api-delete-dashboard` | Grafana API DELETE /api/dashboards/... deletes dashboards. | high |
| `grafana-api-delete-datasource` | Grafana API DELETE /api/datasources/... deletes datasources. | high |
| `grafana-api-delete-alert-notification` | Grafana API DELETE /api/alert-notifications/... deletes alert notification channels. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "monitoring.prometheus:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "monitoring.prometheus:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/package_managers.md
================================================
# Package Manager Packs

This document describes packs in the `package_managers` category.

## Packs in this Category

- [Package Managers](#package_managers)

---

## Package Managers

**Pack ID:** `package_managers`

Protects against dangerous package manager operations like publishing packages and removing critical system packages

### Keywords

Commands containing these keywords are checked against this pack:

- `npm`
- `yarn`
- `pnpm`
- `pip`
- `apt`
- `yum`
- `dnf`
- `cargo`
- `gem`
- `brew`
- `poetry`
- `mvn`
- `mvnw`
- `gradle`
- `gradlew`
- `publish`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `npm-install` | `npm\s+(?:install\|i\|ci)\b` |
| `yarn-add` | `yarn\s+(?:add\|install)\b` |
| `pnpm-install` | `pnpm\s+(?:add\|install\|i)\b` |
| `npm-list` | `npm\s+(?:list\|ls\|info\|view)\b` |
| `yarn-list` | `yarn\s+(?:list\|info\|why)\b` |
| `npm-audit` | `npm\s+audit` |
| `yarn-audit` | `yarn\s+audit` |
| `pip-list` | `pip\s+(?:list\|show\|freeze)\b` |
| `poetry-show` | `poetry\s+show\b` |
| `poetry-env-list` | `poetry\s+env\s+list\b` |
| `cargo-safe` | `cargo\s+(?:build\|test\|check\|clippy\|fmt\|doc\|bench)\b` |
| `apt-list` | `apt\s+(?:list\|show\|search)\b` |
| `apt-get-list` | `apt-get\s+(?:update\|upgrade)(?!\s+.*-y)` |
| `npm-dry-run` | `npm\s+.*--dry-run` |
| `cargo-dry-run` | `cargo\s+.*--dry-run` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `npm-publish` | npm publish releases a package publicly. Use --dry-run first. | high |
| `yarn-publish` | yarn publish releases a package publicly. Verify package.json first. | high |
| `pnpm-publish` | pnpm publish releases a package publicly. | high |
| `npm-unpublish` | npm unpublish removes a published package. This can break dependent projects. | high |
| `pip-uninstall` | pip uninstall removes installed packages. Verify dependencies before removing. | high |
| `pip-url` | pip install from URL can install unvetted code. Verify the source first. | high |
| `pip-system` | pip install to system directories requires careful review. | high |
| `apt-remove` | apt remove/purge removes packages. Verify no critical packages are affected. | high |
| `yum-remove` | yum/dnf remove removes packages. Verify no critical packages are affected. | high |
| `cargo-publish` | cargo publish releases a crate to crates.io. Use --dry-run first. | high |
| `cargo-yank` | cargo yank marks a version as unavailable. This can break dependent projects. | high |
| `gem-push` | gem push releases a gem to rubygems.org. Verify before publishing. | high |
| `brew-uninstall` | brew uninstall removes packages. Verify no dependent packages are affected. | high |
| `poetry-publish` | poetry publish releases a package. Use --dry-run first. | high |
| `poetry-remove` | poetry remove uninstalls a dependency. Verify no critical packages are affected. | high |
| `maven-deploy` | mvn deploy publishes artifacts to a remote repository. Verify target repository. | high |
| `maven-release-perform` | mvn release:perform publishes a release. Verify version and repository. | high |
| `gradle-publish` | gradle publish uploads artifacts. Use --dry-run first when possible. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "package_managers:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "package_managers:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/payment.md
================================================
# Payment Packs

This document describes packs in the `payment` category.

## Packs in this Category

- [Stripe](#paymentstripe)
- [Braintree](#paymentbraintree)
- [Square](#paymentsquare)

---

## Stripe

**Pack ID:** `payment.stripe`

Protects against destructive Stripe CLI/API operations like deleting webhook endpoints and customers, or rotating API keys without coordination.

### Keywords

Commands containing these keywords are checked against this pack:

- `stripe`
- `api.stripe.com`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `stripe-listen` | `\bstripe\b(?:\s+--?\S+(?:\s+\S+)?)*\s+listen\b` |
| `stripe-customers-list` | `\bstripe\b(?:\s+--?\S+(?:\s+\S+)?)*\s+customers\s+list\b` |
| `stripe-products-list` | `\bstripe\b(?:\s+--?\S+(?:\s+\S+)?)*\s+products\s+list\b` |
| `stripe-payments-list` | `\bstripe\b(?:\s+--?\S+(?:\s+\S+)?)*\s+payments\s+list\b` |
| `stripe-logs-tail` | `\bstripe\b(?:\s+--?\S+(?:\s+\S+)?)*\s+logs\s+tail\b` |
| `stripe-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*api\.stripe\.com.*\/v1\/` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `stripe-webhook-endpoints-delete` | stripe webhook_endpoints delete removes a Stripe webhook endpoint, breaking notifications. | high |
| `stripe-customers-delete` | stripe customers delete permanently deletes a customer. | high |
| `stripe-products-delete` | stripe products delete permanently deletes a product. | high |
| `stripe-prices-delete` | stripe prices delete permanently deletes a price. | high |
| `stripe-coupons-delete` | stripe coupons delete permanently deletes a coupon. | high |
| `stripe-api-keys-roll` | stripe api_keys roll rotates API keys; coordinate to avoid outages. | medium |
| `stripe-api-delete` | Stripe API DELETE calls remove Stripe resources. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "payment.stripe:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "payment.stripe:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Braintree

**Pack ID:** `payment.braintree`

Protects against destructive Braintree/PayPal payment operations like deleting customers or cancelling subscriptions via API/SDK calls.

### Keywords

Commands containing these keywords are checked against this pack:

- `braintree`
- `braintreegateway.com`
- `braintree.`
- `gateway.customer.`
- `gateway.merchant_account.`
- `gateway.payment_method.`
- `gateway.subscription.`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `braintree-customer-find` | `\bbraintree\.Customer\.find\b` |
| `braintree-customer-search` | `\bgateway\.customer\.search\b` |
| `braintree-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*braintreegateway\.com` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `braintree-api-delete` | Braintree API DELETE calls remove payment resources (customers, webhooks, etc.). | high |
| `braintree-customer-delete` | braintree.Customer.delete permanently deletes a Braintree customer. | high |
| `braintree-gateway-customer-delete` | gateway.customer.delete permanently deletes a Braintree customer. | high |
| `braintree-merchant-account-delete` | gateway.merchant_account.delete removes a Braintree merchant account. | high |
| `braintree-payment-method-delete` | gateway.payment_method.delete removes a stored payment method. | high |
| `braintree-subscription-cancel` | gateway.subscription.cancel cancels a subscription, impacting billing. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "payment.braintree:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "payment.braintree:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Square

**Pack ID:** `payment.square`

Protects against destructive Square CLI/API operations like deleting catalog objects or customers (which can break payment flows).

### Keywords

Commands containing these keywords are checked against this pack:

- `square`
- `api.squareup.com`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `square-catalog-list` | `\bsquare\b(?:\s+--?\S+(?:\s+\S+)?)*\s+catalog\s+list\b` |
| `square-customers-list` | `\bsquare\b(?:\s+--?\S+(?:\s+\S+)?)*\s+customers\s+list\b` |
| `square-api-get` | `(?i)curl\s+.*(?:-X\|--request)\s+GET\b.*api\.squareup\.com` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `square-catalog-delete` | square catalog delete removes catalog objects, impacting products and inventory. | high |
| `square-api-delete-catalog-object` | Square API DELETE /v2/catalog/object/{id} deletes a catalog object. | high |
| `square-api-delete-customer` | Square API DELETE /v2/customers/{id} deletes a customer. | high |
| `square-api-delete-location` | Square API DELETE /v2/locations/{id} deletes a location. | high |
| `square-api-delete-webhook-subscription` | Square API DELETE /v2/webhooks/subscriptions/{id} deletes a webhook subscription. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "payment.square:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "payment.square:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/platform.md
================================================
# Platform Packs

This document describes packs in the `platform` category.

## Packs in this Category

- [GitHub Platform](#platformgithub)
- [GitLab Platform](#platformgitlab)

---

## GitHub Platform

**Pack ID:** `platform.github`

Protects against destructive GitHub CLI operations like deleting repositories, gists, releases, or SSH keys.

### Keywords

Commands containing these keywords are checked against this pack:

- `gh`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `gh-repo-list-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+repo\s+(?:list\|view)\b` |
| `gh-gist-list-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+gist\s+(?:list\|view)\b` |
| `gh-release-list-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+release\s+(?:list\|view)\b` |
| `gh-issue-list-view` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+issue\s+(?:list\|view)\b` |
| `gh-ssh-key-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+ssh-key\s+list\b` |
| `gh-secret-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+secret\s+list\b` |
| `gh-variable-list` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+variable\s+list\b` |
| `gh-auth-status` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+auth\s+status\b` |
| `gh-status` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+status\b` |
| `gh-api-explicit-get` | `gh(?:\s+--?[A-Za-z][A-Za-z0-9-]*\b(?:\s+(?!(?:repo\|gist\|release\|issue\|ssh-key\|secret\|variable\|run\|auth\|status\|api)\b)(?:(?:\x22[^\x22]*\x22)\|(?:'[^']*')\|\S+))?)*\s+api\b.*(?:-X\|--method)\s+GET\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `gh-repo-delete` | gh repo delete permanently deletes a GitHub repository. This cannot be undone. | high |
| `gh-repo-archive` | gh repo archive makes a repository read-only. While reversible, it stops all write access. | high |
| `gh-gist-delete` | gh gist delete permanently deletes a Gist. | high |
| `gh-release-delete` | gh release delete permanently deletes a release. | high |
| `gh-issue-delete` | gh issue delete permanently deletes an issue. | high |
| `gh-ssh-key-delete` | gh ssh-key delete removes an SSH key, potentially breaking access. | high |
| `gh-secret-delete` | gh secret delete removes GitHub Actions secrets. | high |
| `gh-variable-delete` | gh variable delete removes GitHub Actions variables. | high |
| `gh-repo-deploy-key-delete` | gh repo deploy-key delete removes a deploy key and can break access. | high |
| `gh-run-cancel` | gh run cancel stops a workflow run and may interrupt deployments. | high |
| `gh-api-delete-actions-secret` | gh api DELETE actions/secrets removes GitHub Actions secrets. | high |
| `gh-api-delete-actions-variable` | gh api DELETE actions/variables removes GitHub Actions variables. | high |
| `gh-api-delete-hook` | gh api DELETE hooks removes repository webhooks. | high |
| `gh-api-delete-deploy-key` | gh api DELETE keys removes deploy keys. | high |
| `gh-api-delete-release` | gh api DELETE releases removes GitHub releases. | high |
| `gh-api-delete-repo` | gh api DELETE calls can be destructive. Please verify the endpoint. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "platform.github:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "platform.github:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## GitLab Platform

**Pack ID:** `platform.gitlab`

Protects against destructive GitLab platform operations like deleting projects, releases, protected branches, and webhooks.

### Keywords

Commands containing these keywords are checked against this pack:

- `glab`
- `gitlab-rails`
- `gitlab-rake`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `glab-repo-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+repo\s+list\b` |
| `glab-repo-view` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+repo\s+view\b` |
| `glab-repo-clone` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+repo\s+clone\b` |
| `glab-mr-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+mr\s+list\b` |
| `glab-mr-view` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+mr\s+view\b` |
| `glab-issue-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+issue\s+list\b` |
| `glab-issue-view` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+issue\s+view\b` |
| `glab-variable-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+variable\s+list\b` |
| `glab-release-list` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+release\s+list\b` |
| `glab-release-view` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+release\s+view\b` |
| `glab-api-explicit-get` | `glab(?:\s+--?\S+(?:\s+\S+)?)*\s+api\b.*(?:-X\|--method)\s+GET\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `glab-repo-delete` | glab repo delete permanently deletes a GitLab project. | high |
| `glab-repo-archive` | glab repo archive makes a GitLab project read-only. | high |
| `glab-release-delete` | glab release delete removes GitLab releases. | high |
| `glab-variable-delete` | glab variable delete removes GitLab CI/CD variables. | high |
| `glab-api-delete-project` | glab api DELETE /projects/* deletes a GitLab project. | high |
| `glab-api-delete-release` | glab api DELETE releases removes GitLab releases. | high |
| `glab-api-delete-variable` | glab api DELETE variables removes CI/CD variables. | high |
| `glab-api-delete-protected-branch` | glab api DELETE protected_branches removes branch protections. | high |
| `glab-api-delete-hook` | glab api DELETE hooks removes GitLab webhooks. | high |
| `gitlab-rails-runner-destructive` | gitlab-rails runner destructive operations can remove data. | high |
| `gitlab-rake-destructive` | gitlab-rake destructive maintenance tasks can delete or replace data. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "platform.gitlab:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "platform.gitlab:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/remote.md
================================================
# Remote Access Packs

This document describes packs in the `remote` category.

## Packs in this Category

- [rsync](#remotersync)
- [ssh](#remotessh)
- [scp](#remotescp)

---

## rsync

**Pack ID:** `remote.rsync`

Protects against destructive rsync operations like --delete and its variants.

### Keywords

Commands containing these keywords are checked against this pack:

- `rsync`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `rsync-dry-run` | `rsync\b.*\s--dry-run\b` |
| `rsync-short-dry-run` | `rsync\b.*\s+-[A-Za-z]*n[A-Za-z]*\b` |
| `rsync-list-only` | `rsync\b.*\s--list-only\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `rsync-delete` | rsync --delete removes destination files not present in source. | high |
| `rsync-del-short` | rsync --del is a short alias for --delete and is destructive. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "remote.rsync:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "remote.rsync:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## ssh

**Pack ID:** `remote.ssh`

Protects against destructive SSH operations like remote command execution and key management.

### Keywords

Commands containing these keywords are checked against this pack:

- `ssh`
- `ssh-keygen`
- `ssh-keyscan`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `ssh-version` | `ssh\s+-V\b` |
| `ssh-version-long` | `ssh\s+--version\b` |
| `ssh-keygen-list` | `ssh-keygen\s+.*-l\b` |
| `ssh-keygen-fingerprint` | `ssh-keygen\s+.*-lf?\b` |
| `ssh-keyscan` | `ssh-keyscan\b` |
| `ssh-add-list` | `ssh-add\s+-[lL]\b` |
| `ssh-agent` | `ssh-agent\b` |
| `ssh-help` | `ssh\s+--?h(elp)?\b` |
| `ssh-keygen-help` | `ssh-keygen\s+--?h(elp)?\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `ssh-remote-rm-rf` | SSH remote execution contains destructive rm -rf command. | high |
| `ssh-remote-git-reset-hard` | SSH remote execution contains destructive git reset --hard command. | high |
| `ssh-remote-git-clean` | SSH remote execution contains destructive git clean -f command. | high |
| `ssh-keygen-remove-host` | ssh-keygen -R removes entries from known_hosts file. | high |
| `ssh-add-delete-all` | ssh-add -d/-D removes identities from the SSH agent. | high |
| `ssh-remote-sudo-rm` | SSH remote execution with sudo rm is high-risk. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "remote.ssh:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "remote.ssh:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## scp

**Pack ID:** `remote.scp`

Protects against destructive SCP operations like overwrites to system paths.

### Keywords

Commands containing these keywords are checked against this pack:

- `scp`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `scp-help` | `scp\b.*\s--?h(elp)?\b` |
| `scp-download` | `scp\b.*\s(?:\S+@)?\S+:\S+\s+\.\S*\s*$` |
| `scp-to-home` | `scp\b.*\s(?:(?:\S+@)?\S+:)?~/\S+\s*$` |
| `scp-to-tmp` | `scp\b.*\s(?:(?:\S+@)?\S+:)?/tmp/\S*\s*$` |
| `scp-to-var-tmp` | `scp\b.*\s(?:(?:\S+@)?\S+:)?/var/tmp(?:/\S*)?\s*$` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `scp-recursive-root` | scp -r to root (/) is extremely dangerous. | high |
| `scp-to-etc` | scp to /etc/ can overwrite system configuration. | high |
| `scp-to-var` | scp to /var/ can overwrite system data. | high |
| `scp-to-boot` | scp to /boot/ can corrupt boot configuration. | high |
| `scp-to-usr` | scp to /usr/ can overwrite system binaries. | high |
| `scp-to-bin` | scp to /bin/ or /sbin/ can overwrite system binaries. | high |
| `scp-to-lib` | scp to /lib/ can overwrite system libraries. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "remote.scp:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "remote.scp:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/search.md
================================================
# Search Packs

This document describes packs in the `search` category.

## Packs in this Category

- [Elasticsearch](#searchelasticsearch)
- [OpenSearch](#searchopensearch)
- [Algolia](#searchalgolia)
- [Meilisearch](#searchmeilisearch)

---

## Elasticsearch

**Pack ID:** `search.elasticsearch`

Protects against destructive Elasticsearch REST API operations like index deletion, delete-by-query, index close, and cluster setting changes.

### Keywords

Commands containing these keywords are checked against this pack:

- `elasticsearch`
- `curl`
- `http`
- `9200`
- `_search`
- `_cluster`
- `_cat`
- `_doc`
- `_all`
- `_delete_by_query`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `es-curl-get-search` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:elastic\|:9200)[^\s'\"]*/(?:[^\s/]+/)?(?:_search\|_count\|_mapping\|_settings)\b` |
| `es-curl-get-cat` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:elastic\|:9200)[^\s'\"]*/_cat/\S+` |
| `es-curl-get-cluster-health` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:elastic\|:9200)[^\s'\"]*/_cluster/health\b` |
| `es-http-get-search` | `http\s+GET\s+(?:https?://)?\S*(?:elastic\|:9200)\S*/(?:\S+/)?(?:_search\|_count\|_mapping\|_settings)\b` |
| `es-http-get-cat` | `http\s+GET\s+(?:https?://)?\S*(?:elastic\|:9200)\S*/_cat/\S+` |
| `es-http-get-cluster-health` | `http\s+GET\s+(?:https?://)?\S*(?:elastic\|:9200)\S*/_cluster/health\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `es-curl-delete-doc` | curl -X DELETE against /_doc deletes a document from Elasticsearch. | high |
| `es-curl-delete-by-query` | curl -X POST to _delete_by_query deletes documents matching the query. | high |
| `es-curl-close-index` | curl -X POST to _close closes an index, making it unavailable for reads/writes. | high |
| `es-curl-delete-index` | curl -X DELETE against an Elasticsearch index (or _all/*) deletes data permanently. | high |
| `es-curl-cluster-settings` | curl -X PUT to /_cluster/settings changes cluster settings and can be dangerous. | high |
| `es-http-delete-doc` | http DELETE against /_doc deletes a document from Elasticsearch. | high |
| `es-http-delete-by-query` | http POST to _delete_by_query deletes documents matching the query. | high |
| `es-http-close-index` | http POST to _close closes an index, making it unavailable for reads/writes. | high |
| `es-http-delete-index` | http DELETE against an Elasticsearch index (or _all/*) deletes data permanently. | high |
| `es-http-cluster-settings` | http PUT to /_cluster/settings changes cluster settings and can be dangerous. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "search.elasticsearch:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "search.elasticsearch:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## OpenSearch

**Pack ID:** `search.opensearch`

Protects against destructive OpenSearch REST API operations and AWS CLI domain deletions.

### Keywords

Commands containing these keywords are checked against this pack:

- `opensearch`
- `aws`
- `curl`
- `http`
- `9200`
- `_search`
- `_cluster`
- `_cat`
- `_doc`
- `_all`
- `_delete_by_query`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `os-curl-get-search` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:opensearch\|:9200)[^\s'\"]*/(?:[^\s/]+/)?(?:_search\|_count\|_mapping\|_settings)\b` |
| `os-curl-get-cat` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:opensearch\|:9200)[^\s'\"]*/_cat/\S+` |
| `os-curl-get-cluster-health` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:opensearch\|:9200)[^\s'\"]*/_cluster/health\b` |
| `os-http-get-search` | `http\s+GET\s+(?:https?://)?\S*(?:opensearch\|:9200)\S*/(?:\S+/)?(?:_search\|_count\|_mapping\|_settings)\b` |
| `os-http-get-cat` | `http\s+GET\s+(?:https?://)?\S*(?:opensearch\|:9200)\S*/_cat/\S+` |
| `os-http-get-cluster-health` | `http\s+GET\s+(?:https?://)?\S*(?:opensearch\|:9200)\S*/_cluster/health\b` |
| `aws-opensearch-describe-domain` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+opensearch\s+describe-domain\b` |
| `aws-opensearch-list-domain-names` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+opensearch\s+list-domain-names\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `os-curl-delete-doc` | curl -X DELETE against /_doc deletes a document from OpenSearch. | high |
| `os-curl-delete-by-query` | curl -X POST to _delete_by_query deletes documents matching the query. | high |
| `os-curl-close-index` | curl -X POST to _close closes an index, making it unavailable for reads/writes. | high |
| `os-curl-delete-index` | curl -X DELETE against an OpenSearch index (or _all/*) deletes data permanently. | high |
| `os-http-delete-doc` | http DELETE against /_doc deletes a document from OpenSearch. | high |
| `os-http-delete-by-query` | http POST to _delete_by_query deletes documents matching the query. | high |
| `os-http-close-index` | http POST to _close closes an index, making it unavailable for reads/writes. | high |
| `os-http-delete-index` | http DELETE against an OpenSearch index (or _all/*) deletes data permanently. | high |
| `aws-opensearch-delete-domain` | aws opensearch delete-domain permanently deletes an OpenSearch domain. | high |
| `aws-opensearch-delete-inbound-connection` | aws opensearch delete-inbound-connection removes an OpenSearch connection. | high |
| `aws-opensearch-delete-outbound-connection` | aws opensearch delete-outbound-connection removes an OpenSearch connection. | high |
| `aws-opensearch-delete-package` | aws opensearch delete-package removes an OpenSearch package. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "search.opensearch:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "search.opensearch:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Algolia

**Pack ID:** `search.algolia`

Protects against destructive Algolia operations like deleting indices, clearing objects, removing rules/synonyms, and deleting API keys.

### Keywords

Commands containing these keywords are checked against this pack:

- `algolia`
- `algoliasearch`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `algolia-indices-browse` | `algolia(?:\s+--?\S+(?:\s+\S+)?)*\s+indices\s+browse\b` |
| `algolia-indices-list` | `algolia(?:\s+--?\S+(?:\s+\S+)?)*\s+indices\s+list\b` |
| `algolia-search` | `algolia(?:\s+--?\S+(?:\s+\S+)?)*\s+search\b` |
| `algolia-settings-get` | `algolia(?:\s+--?\S+(?:\s+\S+)?)*\s+settings\s+get\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `algolia-indices-delete` | algolia indices delete permanently removes an Algolia index. | high |
| `algolia-indices-clear` | algolia indices clear removes all objects from an Algolia index. | high |
| `algolia-rules-delete` | algolia rules delete removes index rules. | high |
| `algolia-synonyms-delete` | algolia synonyms delete removes synonym entries. | high |
| `algolia-apikeys-delete` | algolia apikeys delete removes API keys and can break integrations. | high |
| `algolia-sdk-delete-index` | Algolia SDK deleteIndex removes an index. | high |
| `algolia-sdk-clear-objects` | Algolia SDK clearObjects removes all records from an index. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "search.algolia:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "search.algolia:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Meilisearch

**Pack ID:** `search.meilisearch`

Protects against destructive Meilisearch REST API operations like index deletion, document deletion, delete-batch, and API key removal.

### Keywords

Commands containing these keywords are checked against this pack:

- `meili`
- `meilisearch`
- `7700`
- `/indexes`
- `/keys`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `meili-curl-get-stats` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:meili\|:7700)[^\s'\"]*/stats\b` |
| `meili-curl-get-health` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:meili\|:7700)[^\s'\"]*/health\b` |
| `meili-curl-get-version` | `curl\b.*-X\s*GET\b.*\b(?:https?://)?[^\s'\"]*(?:meili\|:7700)[^\s'\"]*/version\b` |
| `meili-curl-search` | `curl\b.*-X\s*POST\b.*\b(?:https?://)?[^\s'\"]*(?:meili\|:7700)[^\s'\"]*/indexes/[^\s/]+/search\b` |
| `meili-http-get-stats` | `http\s+GET\s+(?:https?://)?\S*(?:meili\|:7700)\S*/stats\b` |
| `meili-http-get-health` | `http\s+GET\s+(?:https?://)?\S*(?:meili\|:7700)\S*/health\b` |
| `meili-http-get-version` | `http\s+GET\s+(?:https?://)?\S*(?:meili\|:7700)\S*/version\b` |
| `meili-http-search` | `http\s+POST\s+(?:https?://)?\S*(?:meili\|:7700)\S*/indexes/\S+/search\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `meili-curl-delete-document` | curl -X DELETE against /documents/{id} removes a document from Meilisearch. | high |
| `meili-curl-delete-documents` | curl -X DELETE against /documents removes documents from Meilisearch. | high |
| `meili-curl-delete-batch` | curl -X POST to /documents/delete-batch deletes documents in bulk. | high |
| `meili-curl-delete-key` | curl -X DELETE against /keys removes a Meilisearch API key. | high |
| `meili-curl-delete-index` | curl -X DELETE against /indexes/{uid} deletes a Meilisearch index. | high |
| `meili-http-delete-document` | http DELETE against /documents/{id} removes a document from Meilisearch. | high |
| `meili-http-delete-documents` | http DELETE against /documents removes documents from Meilisearch. | high |
| `meili-http-delete-batch` | http POST to /documents/delete-batch deletes documents in bulk. | high |
| `meili-http-delete-key` | http DELETE against /keys removes a Meilisearch API key. | high |
| `meili-http-delete-index` | http DELETE against /indexes/{uid} deletes a Meilisearch index. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "search.meilisearch:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "search.meilisearch:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/secrets.md
================================================
# Secrets Management Packs

This document describes packs in the `secrets` category.

## Packs in this Category

- [HashiCorp Vault](#secretsvault)
- [AWS Secrets Manager](#secretsaws_secrets)
- [1Password CLI](#secretsonepassword)
- [Doppler CLI](#secretsdoppler)

---

## HashiCorp Vault

**Pack ID:** `secrets.vault`

Protects against destructive Vault CLI operations like deleting secrets, disabling auth/secret engines, revoking leases/tokens, and deleting policies.

### Keywords

Commands containing these keywords are checked against this pack:

- `vault`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `vault-status` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+status\b` |
| `vault-version` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+version\b` |
| `vault-read` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+read\b` |
| `vault-kv-get` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+kv\s+get\b` |
| `vault-kv-list` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+kv\s+list\b` |
| `vault-secrets-list` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+secrets\s+list\b` |
| `vault-policy-list` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+policy\s+list\b` |
| `vault-token-lookup` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+token\s+lookup\b` |
| `vault-auth-list` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+auth\s+list\b` |
| `vault-audit-list` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+audit\s+list\b` |
| `vault-lease-lookup` | `vault(?:\s+--?\S+(?:\s+\S+)?)*\s+lease\s+lookup\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `vault-secrets-disable` | vault secrets disable disables a secrets engine, causing data loss. | high |
| `vault-kv-destroy` | vault kv destroy permanently deletes secret versions. | high |
| `vault-kv-metadata-delete` | vault kv metadata delete removes all versions and metadata for a secret. | high |
| `vault-kv-delete` | vault kv delete removes the latest secret version. | high |
| `vault-delete` | vault delete removes secrets at a path. | high |
| `vault-policy-delete` | vault policy delete removes access policies. | high |
| `vault-auth-disable` | vault auth disable disables an auth method. | high |
| `vault-token-revoke` | vault token revoke invalidates tokens and can disrupt access. | high |
| `vault-lease-revoke` | vault lease revoke invalidates leases and can disrupt access. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "secrets.vault:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "secrets.vault:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## AWS Secrets Manager

**Pack ID:** `secrets.aws_secrets`

Protects against destructive AWS Secrets Manager and SSM Parameter Store operations like delete-secret and delete-parameter.

### Keywords

Commands containing these keywords are checked against this pack:

- `aws`
- `secretsmanager`
- `ssm`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `aws-secretsmanager-list` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+list-secrets\b` |
| `aws-secretsmanager-describe` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+describe-secret\b` |
| `aws-secretsmanager-get` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+get-secret-value\b` |
| `aws-secretsmanager-list-versions` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+list-secret-version-ids\b` |
| `aws-secretsmanager-get-resource-policy` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+get-resource-policy\b` |
| `aws-secretsmanager-get-random-password` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+secretsmanager\s+get-random-password\b` |
| `aws-ssm-get-parameter` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+ssm\s+get-parameter\b` |
| `aws-ssm-get-parameters` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+ssm\s+get-parameters\b` |
| `aws-ssm-describe-parameters` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+ssm\s+describe-parameters\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `aws-secretsmanager-delete-secret` | aws secretsmanager delete-secret removes secrets and may cause data loss. | high |
| `aws-secretsmanager-delete-resource-policy` | aws secretsmanager delete-resource-policy removes access controls. | high |
| `aws-secretsmanager-remove-regions` | aws secretsmanager remove-regions-from-replication can reduce availability. | high |
| `aws-secretsmanager-update-secret` | aws secretsmanager update-secret overwrites secret metadata or value. | high |
| `aws-secretsmanager-put-secret-value` | aws secretsmanager put-secret-value creates a new secret version and can break clients. | high |
| `aws-ssm-delete-parameter` | aws ssm delete-parameter removes a parameter and can break deployments. | high |
| `aws-ssm-delete-parameters` | aws ssm delete-parameters removes parameters and can break deployments. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "secrets.aws_secrets:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "secrets.aws_secrets:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## 1Password CLI

**Pack ID:** `secrets.onepassword`

Protects against destructive 1Password CLI operations like deleting items, documents, users, groups, and vaults.

### Keywords

Commands containing these keywords are checked against this pack:

- `op`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `op-whoami` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+whoami\b` |
| `op-account-get` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+account\s+get\b` |
| `op-read` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+read\b` |
| `op-item-get` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+item\s+get\b` |
| `op-item-list` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+item\s+list\b` |
| `op-document-get` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+document\s+get\b` |
| `op-vault-list` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+vault\s+list\b` |
| `op-vault-get` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+vault\s+get\b` |
| `op-user-list` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+user\s+list\b` |
| `op-group-list` | `op(?:\s+--?\S+(?:\s+\S+)?)*\s+group\s+list\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `op-item-delete` | op item delete removes secret items (including archive operations). | high |
| `op-document-delete` | op document delete removes secure documents (including archive operations). | high |
| `op-vault-delete` | op vault delete removes an entire vault. | high |
| `op-user-delete` | op user delete removes a user from 1Password. | high |
| `op-group-delete` | op group delete removes a group. | high |
| `op-connect-token-delete` | op connect token delete revokes access tokens. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "secrets.onepassword:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "secrets.onepassword:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Doppler CLI

**Pack ID:** `secrets.doppler`

Protects against destructive Doppler CLI operations like deleting secrets, configs, environments, or projects.

### Keywords

Commands containing these keywords are checked against this pack:

- `doppler`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `doppler-secrets-get` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+secrets\s+get\b` |
| `doppler-secrets-list` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+secrets\s+list\b` |
| `doppler-run` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+run\b` |
| `doppler-configure` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+configure\b` |
| `doppler-setup` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+setup\b` |
| `doppler-projects-list` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+projects\s+list\b` |
| `doppler-environments-list` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+environments\s+list\b` |
| `doppler-configs-list` | `doppler(?:\s+--?\S+(?:\s+\S+)?)*\s+configs\s+list\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `doppler-secrets-delete` | doppler secrets delete removes secrets. | high |
| `doppler-projects-delete` | doppler projects delete removes a project. | high |
| `doppler-environments-delete` | doppler environments delete removes an environment. | high |
| `doppler-configs-delete` | doppler configs delete removes a config. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "secrets.doppler:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "secrets.doppler:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/storage.md
================================================
# Storage Packs

This document describes packs in the `storage` category.

## Packs in this Category

- [AWS S3](#storages3)
- [Google Cloud Storage](#storagegcs)
- [MinIO](#storageminio)
- [Azure Blob Storage](#storageazure_blob)

---

## AWS S3

**Pack ID:** `storage.s3`

Protects against destructive S3 operations like bucket removal, recursive deletes, and sync --delete.

### Keywords

Commands containing these keywords are checked against this pack:

- `s3`
- `s3api`
- `rb`
- `delete-bucket`
- `delete-object`
- `delete-objects`
- `--delete`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `s3-list` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3\s+ls\b` |
| `s3-copy` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3\s+cp\b` |
| `s3-presign` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3\s+presign\b` |
| `s3-mb` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3\s+mb\b` |
| `s3api-list-objects` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3api\s+list-objects(?:-v2)?\b` |
| `s3api-get-object` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3api\s+get-object\b` |
| `s3api-head-object` | `aws(?:\s+--?\S+(?:\s+\S+)?)*\s+s3api\s+head-object\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `s3-rb` | aws s3 rb removes an S3 bucket and is destructive. | high |
| `s3-rm` | aws s3 rm deletes S3 objects and is destructive. | high |
| `s3-sync-delete` | aws s3 sync --delete removes destination objects not in source. | high |
| `s3api-delete-bucket` | aws s3api delete-bucket permanently deletes a bucket. | high |
| `s3api-delete-object` | aws s3api delete-object permanently deletes an object. | high |
| `s3api-delete-objects` | aws s3api delete-objects permanently deletes multiple objects. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "storage.s3:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "storage.s3:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Google Cloud Storage

**Pack ID:** `storage.gcs`

Protects against destructive GCS operations like bucket removal, object deletion, and recursive deletes.

### Keywords

Commands containing these keywords are checked against this pack:

- `gsutil`
- `gcloud storage`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `gsutil-ls` | `gsutil\s+(?:-[a-zA-Z]+\s+)*ls\b` |
| `gsutil-cat` | `gsutil\s+(?:-[a-zA-Z]+\s+)*cat\b` |
| `gsutil-stat` | `gsutil\s+(?:-[a-zA-Z]+\s+)*stat\b` |
| `gsutil-du` | `gsutil\s+(?:-[a-zA-Z]+\s+)*du\b` |
| `gsutil-hash` | `gsutil\s+(?:-[a-zA-Z]+\s+)*hash\b` |
| `gsutil-version` | `gsutil\s+(?:-[a-zA-Z]+\s+)*version\b` |
| `gsutil-help` | `gsutil\s+(?:-[a-zA-Z]+\s+)*help\b` |
| `gsutil-cp` | `gsutil\s+(?:-[a-zA-Z]+\s+)*cp\b` |
| `gcloud-storage-buckets-list` | `gcloud\s+storage\s+buckets\s+list\b` |
| `gcloud-storage-buckets-describe` | `gcloud\s+storage\s+buckets\s+describe\b` |
| `gcloud-storage-objects-list` | `gcloud\s+storage\s+objects\s+list\b` |
| `gcloud-storage-objects-describe` | `gcloud\s+storage\s+objects\s+describe\b` |
| `gcloud-storage-ls` | `gcloud\s+storage\s+ls\b` |
| `gcloud-storage-cat` | `gcloud\s+storage\s+cat\b` |
| `gcloud-storage-cp` | `gcloud\s+storage\s+cp\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `gsutil-rb` | gsutil rb removes a GCS bucket. | high |
| `gsutil-rm` | gsutil rm deletes objects from GCS. | high |
| `gsutil-rsync-delete` | gsutil rsync -d deletes destination objects not in source. | high |
| `gcloud-storage-buckets-delete` | gcloud storage buckets delete removes a GCS bucket. | high |
| `gcloud-storage-objects-delete` | gcloud storage objects delete removes objects from GCS. | high |
| `gcloud-storage-rm` | gcloud storage rm removes objects from GCS. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "storage.gcs:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "storage.gcs:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## MinIO

**Pack ID:** `storage.minio`

Protects against destructive MinIO Client (mc) operations like bucket removal, object deletion, and admin operations.

### Keywords

Commands containing these keywords are checked against this pack:

- `mc`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `mc-ls` | `\bmc\s+(?:--\S+\s+)*ls\b` |
| `mc-cat` | `\bmc\s+(?:--\S+\s+)*cat\b` |
| `mc-head` | `\bmc\s+(?:--\S+\s+)*head\b` |
| `mc-stat` | `\bmc\s+(?:--\S+\s+)*stat\b` |
| `mc-cp` | `\bmc\s+(?:--\S+\s+)*cp\b` |
| `mc-diff` | `\bmc\s+(?:--\S+\s+)*diff\b` |
| `mc-find` | `\bmc\s+(?:--\S+\s+)*find\b` |
| `mc-du` | `\bmc\s+(?:--\S+\s+)*du\b` |
| `mc-version` | `\bmc\s+(?:--\S+\s+)*version\b` |
| `mc-help` | `\bmc\s+(?:--\S+\s+)*(?:--help\|-h)\b` |
| `mc-admin-info` | `\bmc\s+(?:--\S+\s+)*admin\s+info\b` |
| `mc-admin-user-list` | `\bmc\s+(?:--\S+\s+)*admin\s+user\s+list\b` |
| `mc-admin-policy-list` | `\bmc\s+(?:--\S+\s+)*admin\s+policy\s+list\b` |
| `mc-alias-list` | `\bmc\s+(?:--\S+\s+)*alias\s+list\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `mc-rb` | mc rb removes a MinIO bucket. | high |
| `mc-rm` | mc rm deletes objects from MinIO. | high |
| `mc-admin-bucket-delete` | mc admin bucket delete removes a bucket via admin API. | high |
| `mc-mirror-remove` | mc mirror --remove deletes destination objects not in source. | high |
| `mc-admin-user-remove` | mc admin user remove/disable affects user access. | high |
| `mc-admin-policy-remove` | mc admin policy remove/unset modifies access policies. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "storage.minio:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "storage.minio:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Azure Blob Storage

**Pack ID:** `storage.azure_blob`

Protects against destructive Azure Blob Storage operations like container deletion, blob deletion, and azcopy remove.

### Keywords

Commands containing these keywords are checked against this pack:

- `az storage`
- `azcopy`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `az-storage-container-list` | `\baz\s+storage\s+container\s+list\b` |
| `az-storage-container-show` | `\baz\s+storage\s+container\s+show\b` |
| `az-storage-container-exists` | `\baz\s+storage\s+container\s+exists\b` |
| `az-storage-blob-list` | `\baz\s+storage\s+blob\s+list\b` |
| `az-storage-blob-show` | `\baz\s+storage\s+blob\s+show\b` |
| `az-storage-blob-exists` | `\baz\s+storage\s+blob\s+exists\b` |
| `az-storage-blob-download` | `\baz\s+storage\s+blob\s+download\b` |
| `az-storage-blob-download-batch` | `\baz\s+storage\s+blob\s+download-batch\b` |
| `az-storage-blob-url` | `\baz\s+storage\s+blob\s+url\b` |
| `az-storage-blob-metadata-show` | `\baz\s+storage\s+blob\s+metadata\s+show\b` |
| `az-storage-account-list` | `\baz\s+storage\s+account\s+list\b` |
| `az-storage-account-show` | `\baz\s+storage\s+account\s+show\b` |
| `az-storage-account-keys-list` | `\baz\s+storage\s+account\s+keys\s+list\b` |
| `azcopy-list` | `\bazcopy\s+(?:--\S+\s+)*list\b` |
| `azcopy-copy` | `\bazcopy\s+(?:--\S+\s+)*copy\b` |
| `azcopy-jobs-list` | `\bazcopy\s+(?:--\S+\s+)*jobs\s+list\b` |
| `azcopy-jobs-show` | `\bazcopy\s+(?:--\S+\s+)*jobs\s+show\b` |
| `azcopy-login` | `\bazcopy\s+(?:--\S+\s+)*login\b` |
| `azcopy-env` | `\bazcopy\s+(?:--\S+\s+)*env\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `az-storage-container-delete` | az storage container delete removes an Azure storage container. | high |
| `az-storage-blob-delete-batch` | az storage blob delete-batch removes multiple blobs from Azure storage. | high |
| `az-storage-blob-delete` | az storage blob delete removes a blob from Azure storage. | high |
| `az-storage-account-delete` | az storage account delete removes an entire Azure storage account. | high |
| `azcopy-remove` | azcopy remove deletes files from Azure storage. | high |
| `azcopy-sync-delete` | azcopy sync --delete-destination removes destination files not in source. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "storage.azure_blob:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "storage.azure_blob:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/strict_git.md
================================================
# Strict Git Packs

This document describes packs in the `strict_git` category.

## Packs in this Category

- [Strict Git](#strict_git)

---

## Strict Git

**Pack ID:** `strict_git`

Stricter git protections: blocks all force pushes, rebases, and history rewriting operations

### Keywords

Commands containing these keywords are checked against this pack:

- `git`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `git-status` | `git\s+status` |
| `git-log` | `git\s+log` |
| `git-diff` | `git\s+diff` |
| `git-show` | `git\s+show` |
| `git-branch-list` | `git\s+branch\s*$\\|git\s+branch\s+-[alv]` |
| `git-remote-v` | `git\s+remote\s+-v` |
| `git-fetch` | `git\s+fetch` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `push-force-any` | Force push (even with --force-with-lease) can rewrite remote history. Disabled in strict mode. | high |
| `rebase` | git rebase rewrites commit history. Disabled in strict mode. | high |
| `commit-amend` | git commit --amend rewrites the last commit. Disabled in strict mode. | high |
| `cherry-pick` | git cherry-pick can introduce duplicate commits. Review carefully. | high |
| `filter-branch` | git filter-branch rewrites entire repository history. Extremely dangerous! | high |
| `filter-repo` | git filter-repo rewrites repository history. Review carefully. | high |
| `reflog-expire` | git reflog expire removes reflog entries needed for recovery. | high |
| `gc-aggressive` | git gc with aggressive/prune options can remove recoverable objects. | high |
| `worktree-remove` | git worktree remove deletes a linked working tree. | high |
| `submodule-deinit` | git submodule deinit removes submodule configuration. | high |
| `push-master` | Direct push to master is blocked. Use a Pull Request. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "strict_git:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "strict_git:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/packs/system.md
================================================
# System Packs

This document describes packs in the `system` category.

## Packs in this Category

- [Disk Operations](#systemdisk)
- [Permissions](#systempermissions)
- [Services](#systemservices)

---

## Disk Operations

**Pack ID:** `system.disk`

Protects against destructive disk operations including dd to devices, mkfs, partition table modifications, RAID management (mdadm), btrfs filesystem operations, device-mapper (dmsetup), network block devices (nbd-client), and LVM commands.

### Keywords

Commands containing these keywords are checked against this pack:

- `dd`
- `fdisk`
- `mkfs`
- `parted`
- `mount`
- `wipefs`
- `/dev/`
- `mdadm`
- `btrfs`
- `dmsetup`
- `nbd-client`
- `pvremove`
- `vgremove`
- `lvremove`
- `vgreduce`
- `lvreduce`
- `lvresize`
- `pvmove`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern | Description |
|--------------|----------|-------------|
| `dd-file-out` | `dd\s+.*of=[^/\s]+\.` | dd to regular files |
| `dd-discard` | `dd\s+.*of=/dev/(?:null\|zero\|full)(?:\s\|$)` | dd to /dev/null (discard output) |
| `lsblk` | `\blsblk\b` | List block devices (read-only) |
| `fdisk-list` | `fdisk\s+-l` | fdisk -l to list partitions |
| `parted-print` | `parted\s+.*print` | parted print (read-only) |
| `blkid` | `\bblkid\b` | Show filesystem UUIDs (read-only) |
| `df` | `\bdf\b` | Show disk free space (read-only) |
| `mount-list` | `\bmount\s*$` | List mounted filesystems |
| `mdadm-detail` | `mdadm\s+--detail\b` | mdadm --detail (read-only inspection) |
| `mdadm-examine` | `mdadm\s+--examine\b` | mdadm --examine (read-only superblock inspection) |
| `mdadm-query` | `mdadm\s+--query\b` | mdadm --query (read-only query) |
| `mdadm-query-short` | `mdadm\s+-Q\b` | mdadm -Q (short form of --query) |
| `mdadm-scan` | `mdadm\s+--scan\b` | mdadm --scan (scan for arrays) |
| `btrfs-subvolume-list` | `btrfs\s+subvolume\s+list\b` | btrfs subvolume list (read-only) |
| `btrfs-subvolume-show` | `btrfs\s+subvolume\s+show\b` | btrfs subvolume show (read-only) |
| `btrfs-filesystem-show` | `btrfs\s+filesystem\s+show\b` | btrfs filesystem show (read-only) |
| `btrfs-filesystem-df` | `btrfs\s+filesystem\s+df\b` | btrfs filesystem df (read-only) |
| `btrfs-filesystem-usage` | `btrfs\s+filesystem\s+usage\b` | btrfs filesystem usage (read-only) |
| `btrfs-device-stats` | `btrfs\s+device\s+stats\b` | btrfs device stats (read-only) |
| `btrfs-property-get` | `btrfs\s+property\s+(?:get\|list)\b` | btrfs property get/list (read-only) |
| `btrfs-scrub-status` | `btrfs\s+scrub\s+status\b` | btrfs scrub status (read-only) |
| `dmsetup-ls` | `dmsetup\s+ls\b` | dmsetup ls (list devices) |
| `dmsetup-status` | `dmsetup\s+status\b` | dmsetup status (show status) |
| `dmsetup-info` | `dmsetup\s+info\b` | dmsetup info (show info) |
| `dmsetup-table` | `dmsetup\s+table\b` | dmsetup table (show mapping table) |
| `dmsetup-deps` | `dmsetup\s+deps\b` | dmsetup deps (show dependencies) |
| `nbd-client-list` | `nbd-client\s+-l\b` | nbd-client -l (list exports) |
| `nbd-client-check` | `nbd-client\s+.*-check\b` | nbd-client -check (check connection) |
| `lvm-list` | `\b(?:lvs\|vgs\|pvs)\b` | LVM list commands (read-only) |
| `lvm-display` | `\b(?:lvdisplay\|vgdisplay\|pvdisplay)\b` | LVM display commands (read-only) |
| `lvm-scan` | `\b(?:lvscan\|vgscan\|pvscan)\b` | LVM scan commands (read-only) |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `dd-device` | dd to a block device will OVERWRITE all data on that device. Extremely dangerous! | high |
| `dd-wipe` | dd from /dev/zero or /dev/urandom to a device will WIPE all data! | high |
| `fdisk-edit` | fdisk can modify partition tables and cause data loss. | high |
| `parted-modify` | parted can modify partition tables and cause data loss. | high |
| `mkfs` | mkfs formats a partition/device and ERASES all existing data. | high |
| `wipefs` | wipefs removes filesystem signatures. Use with extreme caution. | high |
| `mount-bind-root` | mount --bind to root directory can have system-wide effects. | high |
| `umount-force` | umount -f force unmounts which may cause data loss if device is in use. | high |
| `losetup-device` | losetup modifies loop device associations. Verify before proceeding. | high |
| `mdadm-stop` | mdadm --stop shuts down a RAID array. Data may become inaccessible. | high |
| `mdadm-remove` | mdadm --remove removes a drive from a RAID array. May cause data loss if redundancy is lost. | high |
| `mdadm-fail` | mdadm --fail marks a device as failed. Use only for intentional drive replacement. | high |
| `mdadm-zero-superblock` | mdadm --zero-superblock PERMANENTLY erases RAID metadata. Array cannot be reassembled. | high |
| `mdadm-create` | mdadm --create initializes a new RAID array, ERASING existing data on member devices. | high |
| `mdadm-grow` | mdadm --grow reshapes a RAID array. Interruption can cause data loss. Backup first. | high |
| `btrfs-subvolume-delete` | btrfs subvolume delete PERMANENTLY removes a subvolume and all its data. | high |
| `btrfs-device-remove` | btrfs device remove redistributes data off a device. Interruption causes data loss. | high |
| `btrfs-device-add` | btrfs device add incorporates a device into the filesystem. Verify the device is correct. | high |
| `btrfs-balance` | btrfs balance redistributes data across devices. Can be slow and disruptive. | high |
| `btrfs-check-repair` | btrfs check --repair is DANGEROUS and can cause data loss. Backup first! | high |
| `btrfs-rescue` | btrfs rescue operations modify filesystem metadata. Use only as last resort. | high |
| `btrfs-filesystem-resize` | btrfs filesystem resize can shrink a filesystem. Data loss if size is too small. | high |
| `dmsetup-remove` | dmsetup remove detaches a device-mapper device. May cause data loss if in use. | high |
| `dmsetup-remove-all` | dmsetup remove_all removes ALL device-mapper devices. Extremely dangerous! | high |
| `dmsetup-wipe-table` | dmsetup wipe_table replaces the device table, causing all I/O to fail. | high |
| `dmsetup-clear` | dmsetup clear removes the mapping table from a device. | high |
| `dmsetup-load` | dmsetup load changes device mapping. Verify the new table is correct. | high |
| `dmsetup-create` | dmsetup create sets up a new device-mapper device. Verify parameters carefully. | high |
| `nbd-client-disconnect` | nbd-client -d disconnects a network block device. Data loss if not properly unmounted. | high |
| `nbd-client-connect` | nbd-client connecting a device can expose or overwrite data. Verify server and device. | high |
| `pvremove` | pvremove ERASES LVM metadata from a physical volume. Data becomes inaccessible. | high |
| `vgremove` | vgremove DELETES a volume group and all logical volumes within it. | high |
| `lvremove` | lvremove PERMANENTLY deletes a logical volume and ALL its data. | high |
| `vgreduce` | vgreduce removes a physical volume from a volume group. Data may be lost. | high |
| `lvreduce` | lvreduce SHRINKS a logical volume. Data loss if filesystem isn't resized first! | high |
| `lvresize-shrink` | lvresize with negative size SHRINKS the volume. Resize filesystem first or lose data! | high |
| `pvmove` | pvmove migrates data between physical volumes. Do NOT interrupt or data may be lost. | high |
| `lvconvert-merge` | lvconvert --merge reverts LV to snapshot state, discarding changes since snapshot. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "system.disk:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "system.disk:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Permissions

**Pack ID:** `system.permissions`

Protects against dangerous permission changes like chmod 777, recursive chmod/chown on system directories

### Keywords

Commands containing these keywords are checked against this pack:

- `chmod`
- `chown`
- `chgrp`
- `setfacl`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `chmod-non-recursive` | `chmod\s+(?!-[rR])(?:\d{3,4}\|[ugoa][+-][rwxXst]+)\s+[^/]` |
| `stat` | `\bstat\b` |
| `ls-perms` | `ls\s+.*-[a-zA-Z]*l` |
| `getfacl` | `\bgetfacl\b` |
| `namei` | `\bnamei\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `chmod-777` | chmod 777 makes files world-writable. This is a security risk. | high |
| `chmod-recursive-root` | chmod -R on system directories can break system permissions. | high |
| `chown-recursive-root` | chown -R on system directories can break system ownership. | high |
| `chmod-setuid` | Setting setuid bit (chmod u+s) is a security-sensitive operation. | high |
| `chmod-setgid` | Setting setgid bit (chmod g+s) is a security-sensitive operation. | high |
| `chown-to-root` | Changing ownership to root should be done carefully. | high |
| `setfacl-all` | setfacl -R on system directories can modify access control across the filesystem. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "system.permissions:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "system.permissions:*"
reason = "Your reason here"
risk_acknowledged = true
```

---

## Services

**Pack ID:** `system.services`

Protects against dangerous service operations like stopping critical services and modifying init configuration

### Keywords

Commands containing these keywords are checked against this pack:

- `systemctl`
- `service`
- `init`
- `upstart`
- `shutdown`
- `reboot`

### Safe Patterns (Allowed)

These patterns match safe commands that are always allowed:

| Pattern Name | Pattern |
|--------------|----------|
| `systemctl-status` | `systemctl\s+status` |
| `service-status` | `service\s+\S+\s+status` |
| `systemctl-list` | `systemctl\s+list-(?:units\|unit-files\|sockets\|timers)` |
| `systemctl-show` | `systemctl\s+show` |
| `systemctl-is` | `systemctl\s+is-(?:active\|enabled\|failed)` |
| `systemctl-reload` | `systemctl\s+daemon-reload` |
| `systemctl-cat` | `systemctl\s+cat` |
| `journalctl` | `\bjournalctl\b` |

### Destructive Patterns (Blocked)

These patterns match potentially destructive commands:

| Pattern Name | Reason | Severity |
|--------------|--------|----------|
| `systemctl-stop-critical` | Stopping/disabling critical services can cause system access loss or outage. | high |
| `systemctl-stop` | systemctl stop/disable/mask affects service availability. Verify service name. | high |
| `service-stop-critical` | Stopping critical services can cause system access loss. | high |
| `systemctl-isolate` | systemctl isolate changes the system state significantly. | high |
| `systemctl-power` | systemctl poweroff/reboot/halt will shut down or restart the system. | high |
| `shutdown` | shutdown will power off or restart the system. | high |
| `reboot` | reboot will restart the system. | high |
| `init-level` | init 0 shuts down, init 6 reboots the system. | high |

### Allowlist Guidance

To allowlist a specific rule from this pack, add to your allowlist:

```toml
[[allow]]
rule = "system.services:<pattern-name>"
reason = "Your reason here"
```

To allowlist all rules from this pack (use with caution):

```toml
[[allow]]
rule = "system.services:*"
reason = "Your reason here"
risk_acknowledged = true
```

---




================================================
FILE: docs/scan/dockerfile-extractor-v1-spec.md
================================================
# Dockerfile Extractor v1 Syntax Coverage

> Specification for `dcg scan` Dockerfile extractor. Version 1.0.
>
> This document defines the syntax coverage for the first-pass Dockerfile extractor,
> ensuring explicit scope and serving as a test checklist for implementation.

---

## Overview

The Dockerfile extractor analyzes `RUN` instructions in Dockerfiles to extract
executable shell commands for security scanning. It operates conservatively:
**prefer silence over false positives**.

**Extractor IDs:**
- `dockerfile.run` â€” Shell-form RUN commands
- `dockerfile.run.exec` â€” Exec-form (JSON array) RUN commands

---

## File Detection

### Supported File Patterns

| Pattern | Example | Notes |
|---------|---------|-------|
| `Dockerfile` | `Dockerfile` | Case-insensitive |
| `*.dockerfile` | `app.dockerfile`, `build.dockerfile` | Suffix match |
| `Dockerfile.*` | `Dockerfile.dev`, `Dockerfile.prod` | Prefix match |

### Not Matched

| Pattern | Reason |
|---------|--------|
| `Dockerfile-backup` | Hyphen separator not recognized |
| `my-dockerfile` | Must end with `.dockerfile` suffix |
| `Containerfile` | Podman format (future work) |

---

## Supported RUN Forms

### 1. Shell Form (Single-Line)

**Syntax:** `RUN <command>`

```dockerfile
RUN apt-get update
RUN rm -rf /tmp/cache
RUN pip install requests
```

**Behavior:**
- Extracts the command portion after `RUN ` (space or tab delimiter)
- Strips trailing inline comments (e.g., `# comment`)
- Preserves internal command structure

**Test Cases:**
- [x] `RUN apt-get update` â†’ extracts `apt-get update`
- [x] `RUN\tapt-get update` â†’ extracts `apt-get update` (tab delimiter)
- [x] `RUN rm -rf ./tmp # cleanup` â†’ extracts `rm -rf ./tmp`
- [x] `RUN echo "# not a comment"` â†’ extracts `echo "# not a comment"`

### 2. Shell Form (Multiline with Backslash)

**Syntax:** `RUN <command> \` (continuation)

```dockerfile
RUN apt-get update \
    && apt-get install -y \
        curl \
        wget \
    && rm -rf /var/lib/apt/lists/*
```

**Behavior:**
- Joins lines ending with `\` (backslash continuation)
- Inserts single space between joined segments
- Respects limits: MAX_CONTINUATION_LINES=50, MAX_JOINED_CHARS=32KB
- Reports line number of first line (where RUN appears)

**Test Cases:**
- [x] Two-line continuation joins correctly with space
- [x] Deep nesting (10+ lines) joins correctly
- [x] Continuation within string quotes preserved
- [x] Bare `RUN` followed by continuation-only line

### 3. Exec Form (JSON Array)

**Syntax:** `RUN ["executable", "param1", "param2"]`

```dockerfile
RUN ["apt-get", "update"]
RUN ["sh", "-c", "echo hello && rm -rf /tmp"]
RUN ["/bin/bash", "-c", "complex command here"]
```

**Behavior:**
- Parses JSON array using `serde_json`
- Joins array elements with spaces for scanning
- Invalid JSON silently skipped (conservative)
- Extractor ID: `dockerfile.run.exec`

**Test Cases:**
- [x] `RUN ["apt-get", "update"]` â†’ extracts `apt-get update`
- [x] `RUN ["sh", "-c", "rm -rf /tmp"]` â†’ extracts `sh -c rm -rf /tmp`
- [x] Exec form with continuation across lines
- [x] Malformed JSON (missing bracket) â†’ skipped, no error

### 4. Exec Form with Continuation

**Syntax:** JSON array spanning multiple lines

```dockerfile
RUN ["sh", "-c", \
  "rm -rf /tmp"]
```

**Behavior:**
- Joins continuation lines before JSON parsing
- Handles whitespace within JSON strings

**Test Cases:**
- [x] Split JSON array joins and parses correctly
- [x] Whitespace within quoted strings preserved

---

## Quoting and Escape Handling

### Shell Inline Comments

| Input | Extracted |
|-------|-----------|
| `rm -rf /tmp # cleanup` | `rm -rf /tmp` |
| `echo "# not a comment"` | `echo "# not a comment"` |
| `echo '# also not'` | `echo '# also not'` |

**Behavior:**
- `#` outside quotes treated as comment start
- Single and double quotes protect `#` characters
- Comment stripping uses quote-aware scanner

### Quoting Preservation

| Input | Extracted |
|-------|-----------|
| `echo "hello world"` | `echo "hello world"` (quotes preserved) |
| `bash -c 'rm -rf /tmp'` | `bash -c 'rm -rf /tmp'` |
| `FOO="value" cmd` | `FOO="value" cmd` |

**Behavior:**
- Quotes are preserved in extracted command
- Internal quote parsing for comment detection only
- No shell expansion or variable substitution

### Backslash Continuations

| Input | Extracted |
|-------|-----------|
| `apt-get update \`<br>`&& apt-get install` | `apt-get update && apt-get install` |
| `echo "line1\`<br>`line2"` | `echo "line1 line2"` |

**Behavior:**
- Trailing `\` triggers line continuation
- Joined with single space
- Backslash within quotes: **not currently special-cased** (v1 limitation)

---

## Instructions Not Extracted

The v1 extractor only processes `RUN` instructions. The following are explicitly
**not extracted** and will not trigger security scan matches:

### Dockerfile Instructions (Skipped)

| Instruction | Reason |
|-------------|--------|
| `FROM` | Base image, not executable |
| `COPY` | File copy, not shell command |
| `ADD` | File/URL add, not shell command |
| `ENV` | Environment variable, data context |
| `ARG` | Build argument, data context |
| `LABEL` | Metadata, not executable |
| `EXPOSE` | Port declaration, not executable |
| `WORKDIR` | Directory change, not shell command |
| `USER` | User switch, not shell command |
| `VOLUME` | Volume mount, not executable |
| `HEALTHCHECK` | Future work: contains CMD |
| `CMD` | Future work: container entry point |
| `ENTRYPOINT` | Future work: container entry point |
| `SHELL` | Future work: affects RUN behavior |
| `ONBUILD` | Future work: trigger instruction |
| `STOPSIGNAL` | Signal, not executable |
| `MAINTAINER` | Deprecated metadata |

### Comments

```dockerfile
# This is a comment, never extracted
# rm -rf / is safe in a comment
```

**Test Cases:**
- [x] `# rm -rf /` â†’ not extracted
- [x] Comment after RUN stripped correctly
- [x] Inline comment with # in quotes preserved

---

## Unsupported Constructs (v1 Limitations)

The following are known limitations in v1. They may produce unexpected behavior
and should be addressed in future versions.

### 1. Heredocs in RUN (Docker BuildKit)

**Not Supported:**

```dockerfile
RUN <<EOF
apt-get update
apt-get install -y curl
rm -rf /tmp/cache
EOF
```

**Current Behavior:** Heredoc marker not recognized; subsequent lines not joined.

**Workaround:** Use continuation syntax or split into multiple RUN commands.

### 2. Variable Expansion

**Not Supported:**

```dockerfile
ARG CLEANUP_CMD="rm -rf /tmp"
RUN $CLEANUP_CMD
```

**Current Behavior:** Extracts literal `$CLEANUP_CMD`, not the expanded value.

**Impact:** Commands hidden behind variables won't trigger pattern matches.

### 3. SHELL Instruction Effects

**Not Supported:**

```dockerfile
SHELL ["/bin/bash", "-c"]
RUN echo hello
```

**Current Behavior:** SHELL instruction ignored; RUN parsing unchanged.

**Impact:** Non-default shells may affect command interpretation.

### 4. Escape Directive

**Not Supported:**

```dockerfile
# escape=`
RUN echo hello `
    && echo world
```

**Current Behavior:** Backtick escape not recognized; only `\` continuation.

**Impact:** Windows-style Dockerfiles with backtick escapes may not parse correctly.

### 5. Multi-Stage Build Awareness

**Limited:**

```dockerfile
FROM builder as build
RUN dangerous-command-here

FROM runtime
# No dangerous RUN here
```

**Current Behavior:** All stages scanned equally; no stage filtering.

**Impact:** Build-only dangerous commands flagged same as production images.

### 6. Nested Quotes in Exec Form

**Limited:**

```dockerfile
RUN ["sh", "-c", "echo \"nested quotes\" && rm -rf /tmp"]
```

**Current Behavior:** JSON parsing handles standard escapes; complex nesting untested.

---

## Implementation Limits

| Constant | Value | Purpose |
|----------|-------|---------|
| `MAX_CONTINUATION_LINES` | 50 | Limit runaway continuation |
| `MAX_JOINED_CHARS` | 32,768 | Limit memory for joined command |

**Behavior when exceeded:**
- Stop joining at limit
- Return partial command up to limit
- No error; fail-open design

---

## Test Checklist

Use this checklist to verify implementation correctness:

### Path Detection
- [ ] `Dockerfile` matches (lowercase)
- [ ] `dockerfile` matches (case-insensitive)
- [ ] `Dockerfile.dev` matches (prefix variant)
- [ ] `app.dockerfile` matches (suffix variant)
- [ ] `Dockerfile-backup` does NOT match
- [ ] `Containerfile` does NOT match

### Shell Form
- [ ] Single-line RUN extracts command
- [ ] Tab delimiter (`RUN\tcmd`) works
- [ ] Inline comment stripped
- [ ] Comment with # in quotes preserved
- [ ] Empty RUN (just whitespace) skipped

### Continuation
- [ ] Two-line continuation joins
- [ ] Multi-line (5+) continuation joins
- [ ] Continuation limit (50 lines) stops
- [ ] Character limit (32KB) stops

### Exec Form
- [ ] Simple JSON array extracts
- [ ] JSON with spaces in args extracts
- [ ] Malformed JSON skipped silently
- [ ] Exec form with continuation

### Non-RUN Instructions
- [ ] FROM not extracted
- [ ] COPY not extracted
- [ ] ENV value not extracted (even if looks like command)
- [ ] LABEL not extracted
- [ ] Comments not extracted

### Edge Cases
- [ ] Empty file returns no commands
- [ ] File with only comments returns no commands
- [ ] Keyword filter: only extracts if keyword present
- [ ] Unicode in commands preserved

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-16 | Initial specification |

---

## Related Tasks

- **Blocks:** `git_safety_guard-0fv0` (Implement Dockerfile RUN command extractor)
- **Blocks:** `git_safety_guard-5rbb.6` (Unit tests for Dockerfile extractor)
- **Parent:** `git_safety_guard-5rbb` (Scan Mode Extractors for CI/DevOps Files)



================================================
FILE: docs/scan/github-actions-extractor-v1-spec.md
================================================
# GitHub Actions Extractor v1 Syntax Coverage

> Specification for `dcg scan` GitHub Actions workflow extractor. Version 1.0.
>
> This document defines the syntax coverage for the first-pass GitHub Actions extractor,
> ensuring explicit scope and serving as a test checklist for implementation.

---

## Overview

The GitHub Actions extractor analyzes workflow files to extract shell commands from
`run:` blocks within `steps:` arrays for security scanning. It operates conservatively:
**prefer silence over false positives**.

**Extractor ID:**
- `github_actions.steps.run` â€” Shell commands in `run:` steps

---

## File Detection

### Supported File Patterns

| Pattern | Example | Notes |
|---------|---------|-------|
| `.github/workflows/*.yml` | `.github/workflows/ci.yml` | Primary pattern |
| `.github/workflows/*.yaml` | `.github/workflows/deploy.yaml` | Alternate extension |
| `.github/workflows/**/*.yml` | `.github/workflows/sub/ci.yml` | Nested directories |

**Requirements:**
1. Path must contain `.github/workflows/` directory structure
2. File extension must be `.yml` or `.yaml` (case-insensitive)

### Not Matched

| Pattern | Reason |
|---------|--------|
| `workflows/ci.yml` | Missing `.github/` parent |
| `.github/workflow/ci.yml` | Wrong directory name (singular) |
| `.github/workflows/ci.json` | Wrong extension |
| `action.yml` | Composite action file (different structure) |
| `.github/actions/my-action/action.yml` | Composite action |

---

## GitHub Actions Workflow Structure

For context, a workflow file structure:

```yaml
name: CI
on: [push, pull_request]    # Triggers (not extracted)

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4       # uses: (not extracted)
      - name: Build                      # name: (not extracted)
        run: npm run build               # run: (EXTRACTED)
      - run: |                           # Block scalar (EXTRACTED)
          npm test
          npm run lint
```

**Key insight:** Only `run:` values within `steps:` arrays are extracted as shell commands.

---

## Supported Run Block Forms

### 1. Single-Line Run (Flow Scalar)

**Syntax:** `run: <command>`

```yaml
steps:
  - run: echo "Hello, World!"
  - run: npm install
  - run: git status
```

**Behavior:**
- Extracts the command text after `run:`
- Handles YAML quoting (double, single, unquoted)
- Strips leading/trailing whitespace

**Test Cases:**
- [x] `run: echo hello` â†’ extracts `echo hello`
- [x] `run: "echo \"quoted\""` â†’ extracts `echo "quoted"` (escape handling)
- [x] `run: 'rm -rf ./build'` â†’ extracts `rm -rf ./build` (single quotes)
- [x] `- run: cmd` (list item with run) â†’ extracts `cmd`

### 2. Block Scalar Run (Literal Block `|`)

**Syntax:** `run: |` followed by indented content

```yaml
steps:
  - run: |
      echo "First line"
      echo "Second line"
      npm run build
```

**Behavior:**
- Recognizes `|` (literal block scalar indicator)
- Captures all indented lines below as shell script
- Preserves newlines between commands
- Uses shell script extractor for command parsing

**Test Cases:**
- [x] Multi-line literal block extracts all commands
- [x] Comments within block handled by shell extractor
- [x] Empty lines within block preserved
- [x] Block ends when indentation returns to run: level

### 3. Block Scalar Run (Folded Block `>`)

**Syntax:** `run: >` followed by indented content

```yaml
steps:
  - run: >
      echo "This is a very long command
      that spans multiple lines
      and gets folded into one"
```

**Behavior:**
- Recognizes `>` (folded block scalar indicator)
- Newlines converted to spaces (standard YAML folding)
- Processes as single long command

**Test Cases:**
- [x] Folded block with `>` recognized
- [x] Line folding applied correctly

### 4. Quoted Scalars

**Syntax:** `run: "command"` or `run: 'command'`

```yaml
steps:
  - run: "echo \"nested quotes\""
  - run: 'single quoted: no escapes except '''
```

**Behavior:**
- Double quotes: handle `\n`, `\t`, `\"`, `\\` escapes
- Single quotes: only `''` escapes to single `'`
- Unquoted: used as-is after trimming

**Test Cases:**
- [x] Double-quoted with `\n` â†’ newline in command
- [x] Double-quoted with `\"` â†’ literal double quote
- [x] Single-quoted with `''` â†’ single quote
- [x] Unquoted value extracted directly

---

## Context-Aware Extraction

### Steps Array Detection

The extractor tracks the `steps:` context:

```yaml
jobs:
  test:
    steps:           # <-- Enter steps context
      - run: cmd1    # Extracted
      - run: cmd2    # Extracted
    outputs:         # <-- Exit steps context
      result: ...
```

**Behavior:**
- Only `run:` within active `steps:` blocks are extracted
- `run:` at document root or outside `steps:` is ignored
- Indentation tracking determines context boundaries

### Skipped Blocks

Certain step properties are explicitly skipped:

| Property | Reason |
|----------|--------|
| `env:` | Environment variables (data, not commands) |
| `with:` | Action inputs (data, not commands) |
| `secrets:` | Sensitive data (never extract) |

```yaml
steps:
  - run: actual-command      # Extracted
    env:
      FOO: "rm -rf /"        # Skipped (data context)
    with:
      script: "rm -rf /"     # Skipped (action input)
```

**Test Cases:**
- [x] `env:` block values not extracted
- [x] `with:` block values not extracted
- [x] `secrets:` block values not extracted

---

## Lines Not Extracted

### Step Properties (Not Commands)

| Property | Example | Reason |
|----------|---------|--------|
| `name:` | `name: "rm -rf /"` | Display name, not command |
| `uses:` | `uses: actions/checkout@v4` | Action reference |
| `id:` | `id: build-step` | Step identifier |
| `if:` | `if: github.event_name == 'push'` | Condition expression |
| `working-directory:` | `working-directory: ./app` | Directory path |
| `continue-on-error:` | `continue-on-error: true` | Boolean flag |
| `timeout-minutes:` | `timeout-minutes: 10` | Numeric setting |

### Workflow Metadata

| Section | Reason |
|---------|--------|
| `name:` (workflow) | Display name |
| `on:` | Trigger configuration |
| `permissions:` | Permission settings |
| `concurrency:` | Concurrency settings |
| `defaults:` | Default settings |
| `env:` (workflow/job level) | Environment variables |

---

## Shell Override Handling

### v1 Behavior: Shell Agnostic

GitHub Actions supports `shell:` to specify command interpreter:

```yaml
steps:
  - run: Write-Host "Hello"
    shell: pwsh
  - run: python -c "print('hi')"
    shell: python
```

**Current Behavior:** The `shell:` property is NOT parsed. All `run:` blocks
are assumed to be shell (bash) commands.

**Implications:**
- PowerShell scripts extracted as if they were bash
- Python inline scripts extracted as shell commands
- May produce false positives for non-bash shells

**Test Cases:**
- [x] `run:` with `shell: bash` extracted normally
- [x] `run:` with `shell: pwsh` still extracted (v1 limitation)
- [x] `run:` with `shell: python` still extracted (v1 limitation)

---

## Unsupported Constructs (v1 Limitations)

The following are known limitations in v1. They may produce unexpected behavior
and should be addressed in future versions.

### 1. Reusable Workflows (`workflow_call`)

**Not Supported:**

```yaml
# .github/workflows/reusable.yml
on:
  workflow_call:
    inputs:
      command:
        type: string

jobs:
  build:
    steps:
      - run: ${{ inputs.command }}
```

**Current Behavior:** Template expressions (`${{ }}`) extracted literally.

**Impact:** Dynamic command values from workflow inputs won't be expanded.

### 2. Composite Actions

**Not Supported:**

```yaml
# action.yml (composite action)
runs:
  using: composite
  steps:
    - run: dangerous-command
      shell: bash
```

**Current Behavior:** Files named `action.yml` not matched by file detection.

**Impact:** Commands in composite actions not scanned.

### 3. Expression Substitution

**Not Supported:**

```yaml
steps:
  - run: ${{ github.event.inputs.command }}
  - run: echo "${{ secrets.SCRIPT }}"
```

**Current Behavior:** Expressions extracted literally as `${{ ... }}`.

**Impact:** Commands from inputs, secrets, or context not expanded.

### 4. Matrix Strategies

**Partially Supported:**

```yaml
jobs:
  test:
    strategy:
      matrix:
        cmd: ['cmd1', 'cmd2']
    steps:
      - run: ${{ matrix.cmd }}
```

**Current Behavior:** `run: ${{ matrix.cmd }}` extracted literally.

**Impact:** Matrix-expanded commands not individually scanned.

### 5. Shell Override Interpretation

**Not Supported:**

```yaml
steps:
  - run: |
      import os
      os.remove('/tmp/file')
    shell: python
```

**Current Behavior:** Python code extracted and scanned as bash.

**Impact:** Python-specific patterns (like `os.remove`) not matched by bash patterns.

### 6. Conditional Run Blocks

**Partially Supported:**

```yaml
steps:
  - run: dangerous-command
    if: github.ref == 'refs/heads/main'
```

**Current Behavior:** Command extracted regardless of `if:` condition.

**Impact:** Conditionally-skipped commands still flagged.

### 7. Multi-Job Workflows

**Supported:**

```yaml
jobs:
  job1:
    steps:
      - run: cmd1
  job2:
    steps:
      - run: cmd2
```

**Current Behavior:** All jobs' steps scanned.

**Note:** This is working correctly in v1.

---

## Implementation Details

### Steps Context Tracking

```
1. Find `steps:` key at job level
2. Track indentation of `steps:` line
3. Within steps block:
   - Look for list items (`- `) at appropriate indent
   - Check for `run:` key in each item
   - Skip `env:`, `with:`, `secrets:` sub-blocks
4. Exit steps context when indentation decreases
```

### Block Scalar Extraction

For `run: |` or `run: >`:

1. Note the indent level of `run:` line
2. Collect all following lines with greater indentation
3. Pass block to shell script extractor
4. Shell extractor handles comment stripping, etc.

### YAML Scalar Unquoting

```
Input: run: "echo \"hello\""
After unquoting: echo "hello"

Input: run: 'echo ''quoted'''
After unquoting: echo 'quoted'

Input: run: echo plain
After unquoting: echo plain
```

---

## Test Checklist

Use this checklist to verify implementation correctness:

### Path Detection
- [ ] `.github/workflows/ci.yml` matches
- [ ] `.github/workflows/ci.yaml` matches
- [ ] `.github/workflows/sub/ci.yml` matches (nested)
- [ ] `.GITHUB/WORKFLOWS/CI.YML` matches (case-insensitive)
- [ ] `.github/workflows/ci.json` does NOT match
- [ ] `workflows/ci.yml` does NOT match (missing .github)
- [ ] `.github/workflow/ci.yml` does NOT match (singular)
- [ ] `action.yml` does NOT match

### Single-Line Run
- [ ] `run: echo hello` extracts command
- [ ] `run: "quoted command"` handles double quotes
- [ ] `run: 'single quoted'` handles single quotes
- [ ] `- run: cmd` (list item) works
- [ ] Inline comment after run value (if any)

### Block Scalar Run
- [ ] `run: |` literal block extracts all lines
- [ ] `run: >` folded block recognized
- [ ] Multi-line content joined correctly
- [ ] Block ends at appropriate indentation

### Context Awareness
- [ ] `run:` inside `steps:` extracted
- [ ] `run:` outside `steps:` NOT extracted
- [ ] Multiple jobs' steps all scanned
- [ ] `env:` block values skipped
- [ ] `with:` block values skipped
- [ ] `secrets:` block values skipped

### Non-Run Properties
- [ ] `name: "cmd"` NOT extracted
- [ ] `uses: action@v1` NOT extracted
- [ ] `if: condition` NOT extracted
- [ ] `id: step-id` NOT extracted

### Quoting
- [ ] Double quotes with escape sequences
- [ ] Single quotes with `''` escape
- [ ] Unquoted values work

### Edge Cases
- [ ] Empty workflow returns no commands
- [ ] Workflow with only `uses:` steps returns no commands
- [ ] Keyword filter limits extraction
- [ ] Comments in block scalar handled

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-16 | Initial specification |

---

## Related Tasks

- **Blocks:** `git_safety_guard-0t5u` (Implement GitHub Actions workflow extractor)
- **Blocks:** `git_safety_guard-5rbb.8` (Unit tests for GitHub Actions extractor)
- **Parent:** `git_safety_guard-5rbb` (Scan Mode Extractors for CI/DevOps Files)



================================================
FILE: docs/scan/makefile-extractor-v1-spec.md
================================================
# Makefile Extractor v1 Syntax Coverage

> Specification for `dcg scan` Makefile extractor. Version 1.0.
>
> This document defines the syntax coverage for the first-pass Makefile extractor,
> ensuring explicit scope and serving as a test checklist for implementation.

---

## Overview

The Makefile extractor analyzes recipe lines (shell commands) in Makefiles to extract
executable commands for security scanning. It operates conservatively:
**prefer silence over false positives**.

**Extractor ID:**
- `makefile.recipe` â€” Recipe line commands

---

## File Detection

### Supported File Patterns

| Pattern | Example | Notes |
|---------|---------|-------|
| `Makefile` | `Makefile` | Case-insensitive |
| `makefile` | `makefile` | Lowercase variant |
| `MAKEFILE` | `MAKEFILE` | All-caps variant |

### Not Matched

| Pattern | Reason |
|---------|--------|
| `Makefile.backup` | Not exact filename |
| `build.mk` | `.mk` include files not yet supported |
| `GNUmakefile` | GNU variant not yet supported |
| `makefile.in` | Autoconf templates not supported |
| `Makefile.am` | Automake files not supported |

---

## Makefile Syntax Primer

For context, a Makefile consists of:

```makefile
# Comment
VARIABLE = value         # Variable assignment

target: prerequisites    # Rule definition
	command1             # Recipe line (starts with TAB)
	command2             # Another recipe line
```

**Key insight:** Only lines starting with a **literal TAB character** are recipe lines
containing shell commands to execute.

---

## Supported Recipe Formats

### 1. Simple Recipe Lines

**Syntax:** TAB followed by shell command

```makefile
all:
	echo "Building..."
	rm -rf ./build
	mkdir build
```

**Behavior:**
- Lines starting with `\t` (TAB character) are recipe lines
- Command is everything after the leading TAB
- Comments handled by shell script extractor (see below)

**Test Cases:**
- [x] `\tgit status` â†’ extracts `git status`
- [x] `\trm -rf ./build` â†’ extracts `rm -rf ./build`
- [x] Multiple recipe lines in same target extracted individually

### 2. Recipe Block Extraction

**Syntax:** Consecutive TAB-prefixed lines form a recipe block

```makefile
clean:
	rm -rf build
	rm -rf dist
	echo "Clean complete"

test:
	cargo test
```

**Behavior:**
- Recipe lines are grouped by consecutive TAB-prefixed lines
- Each target's recipe is processed as a shell script block
- Empty lines within recipes do NOT break the block (if continuation)
- Lines without TAB prefix (except continuations) end the block

**Test Cases:**
- [x] Consecutive recipe lines grouped correctly
- [x] Target boundary ends recipe block
- [x] Empty line without continuation ends block

### 3. Backslash Line Continuation

**Syntax:** Recipe line ending with `\` continues to next line

```makefile
build:
	gcc -Wall -Werror \
	    -O2 -g \
	    -o main main.c

deploy:
	rsync -avz \
		--exclude node_modules \
		--exclude .git \
		./ server:/app/
```

**Behavior:**
- Line ending with `\` (backslash) continues to next line
- Continuation line does NOT require leading TAB
- Lines are joined for command extraction
- Backslash and newline replaced with joining

**Test Cases:**
- [x] Two-line continuation joins correctly
- [x] Multi-line continuation (3+) joins correctly
- [x] Continuation without TAB on continuation line works
- [x] Nested continuation within quotes

### 4. Shell Comments in Recipes

**Syntax:** `#` in recipe line starts shell comment

```makefile
clean:
	rm -rf ./build   # Remove build directory
	# This entire line is a comment
	git status       # Check status
```

**Behavior:**
- Comments handled by underlying shell script extractor
- `#` outside quotes starts comment
- Comment portion stripped before pattern matching
- Entire comment-only lines produce no extraction

**Test Cases:**
- [x] Inline comment stripped: `rm -rf /tmp # cleanup` â†’ `rm -rf /tmp`
- [x] Full comment line not extracted
- [x] `#` in quotes preserved: `echo "# header"` â†’ `echo "# header"`

---

## Recipe vs Non-Recipe Lines

### Lines Extracted (Recipe Lines)

Lines starting with TAB that contain shell commands:

```makefile
all:
	@echo "Building"    # @ prefix still extracted as "echo Building"
	-rm -rf build       # - prefix still extracted as "rm -rf build"
	+make subdir        # + prefix still extracted as "make subdir"
```

**Recipe Line Prefixes:**
| Prefix | Meaning | Extraction Behavior |
|--------|---------|---------------------|
| (none) | Normal | Extract as-is |
| `@` | Silent (no echo) | Extract command after `@` |
| `-` | Ignore errors | Extract command after `-` |
| `+` | Run even in dry-run | Extract command after `+` |

**Note:** Prefix handling is delegated to shell script extractor.

### Lines Not Extracted

| Line Type | Example | Reason |
|-----------|---------|--------|
| Variable assignment | `CC = gcc` | Not executable context |
| Target definition | `all: build test` | Rule declaration, not command |
| Directive | `.PHONY: all clean` | Make directive, not command |
| Include | `include config.mk` | Make directive |
| Comment | `# Build configuration` | Not executable |
| Conditional | `ifeq ($(DEBUG),1)` | Make syntax, not shell |
| Blank line | (empty) | Nothing to extract |

---

## Variable Handling

### Variable Syntax in Make

Make variables can appear in recipes:

```makefile
CLEAN_CMD = rm -rf ./build

clean:
	$(CLEAN_CMD)
	${CLEAN_CMD}
	$$HOME/cleanup.sh    # Shell variable (doubled $$)
```

### v1 Behavior: No Substitution

**The v1 extractor does NOT expand variables.**

| Input | Extracted | Note |
|-------|-----------|------|
| `$(CC) -o main main.c` | `$(CC) -o main main.c` | Literal `$(CC)` |
| `${RM} -rf build` | `${RM} -rf build` | Literal `${RM}` |
| `$$HOME/script.sh` | `$$HOME/script.sh` | Literal `$$HOME` |
| `$(shell rm -rf /)` | `$(shell rm -rf /)` | Literal, not executed |

**Implications:**
- Patterns must match against literal variable syntax
- Dangerous commands hidden behind variables won't trigger
- This is a known v1 limitation (conservative approach)

**Test Cases:**
- [x] `$(VAR)` syntax preserved literally
- [x] `${VAR}` syntax preserved literally
- [x] `$$var` (shell variable) preserved literally
- [x] `$(shell cmd)` function not evaluated

---

## Unsupported Constructs (v1 Limitations)

The following are known limitations in v1. They may produce unexpected behavior
and should be addressed in future versions.

### 1. Variable Expansion

**Not Supported:**

```makefile
DANGER = rm -rf /
clean:
	$(DANGER)
```

**Current Behavior:** Extracts literal `$(DANGER)`, not the expanded value.

**Impact:** Commands hidden behind variables won't trigger pattern matches.

### 2. Make Functions

**Not Supported:**

```makefile
FILES := $(wildcard *.c)
clean:
	$(foreach f,$(FILES),rm $(f);)
	$(shell dangerous-command)
```

**Current Behavior:** Functions extracted literally, not evaluated.

**Impact:** Commands inside `$(shell ...)` won't be scanned as shell commands.

### 3. Conditional Directives

**Not Supported:**

```makefile
ifeq ($(DEBUG),1)
clean:
	rm -rf ./debug
else
clean:
	rm -rf ./release
endif
```

**Current Behavior:** `ifeq`/`else`/`endif` lines not parsed as directives;
recipe lines within conditionals ARE extracted.

**Impact:** Both branches' recipes may be extracted regardless of condition.

### 4. Pattern Rules

**Partially Supported:**

```makefile
%.o: %.c
	$(CC) -c $< -o $@
```

**Current Behavior:** Recipe lines extracted with literal `$<`, `$@`.

**Impact:** Automatic variables (`$@`, `$<`, `$^`, etc.) not expanded.

### 5. Include Directives

**Not Supported:**

```makefile
include common.mk
-include optional.mk
```

**Current Behavior:** Include files not followed or scanned.

**Impact:** Commands in included files not analyzed.

### 6. Multi-Line Variable Definitions

**Not Supported:**

```makefile
define SCRIPT
rm -rf /tmp
git reset --hard
endef

clean:
	$(SCRIPT)
```

**Current Behavior:** `define`/`endef` blocks not parsed; `$(SCRIPT)` extracted literally.

**Impact:** Multi-line variable content not scanned.

### 7. Alternative File Names

**Not Supported:**

| File Name | Status |
|-----------|--------|
| `GNUmakefile` | Not matched (future work) |
| `*.mk` | Not matched (include files) |
| `makefile.in` | Not matched (autoconf) |
| `Makefile.am` | Not matched (automake) |

---

## Implementation Details

### Recipe Block Processing

1. Scan for lines starting with TAB
2. Collect consecutive recipe lines into a block
3. Handle backslash continuations within block
4. Pass block to shell script extractor for command parsing
5. Return extracted commands with `makefile.recipe` extractor ID

### Shell Script Extractor Reuse

The Makefile extractor delegates to `extract_shell_script_with_offset_and_id()`:

- Comment stripping (`#` outside quotes)
- Quote-aware parsing
- Backslash continuation handling
- Keyword filtering

This ensures consistent behavior between `.sh` files and Makefile recipes.

---

## Test Checklist

Use this checklist to verify implementation correctness:

### Path Detection
- [ ] `Makefile` matches
- [ ] `makefile` matches (case-insensitive)
- [ ] `MAKEFILE` matches (case-insensitive)
- [ ] `Makefile.backup` does NOT match
- [ ] `build.mk` does NOT match
- [ ] `GNUmakefile` does NOT match

### Recipe Extraction
- [ ] TAB-prefixed line extracts command
- [ ] Non-TAB line not extracted
- [ ] Consecutive recipe lines form block
- [ ] Target definition line not extracted
- [ ] Variable assignment not extracted

### Backslash Continuation
- [ ] Two-line continuation joins correctly
- [ ] Multi-line continuation joins correctly
- [ ] Continuation line without TAB works
- [ ] Backslash at end of recipe line triggers continuation

### Comments
- [ ] Recipe line with `# comment` strips comment
- [ ] Full comment recipe line not extracted
- [ ] `#` in quotes preserved

### Variables
- [ ] `$(VAR)` syntax preserved literally
- [ ] `${VAR}` syntax preserved literally
- [ ] `$$var` shell variable preserved
- [ ] `$(shell ...)` not evaluated

### Recipe Prefixes
- [ ] `@echo hello` extracts (with or without `@`)
- [ ] `-rm -rf x` extracts (with or without `-`)
- [ ] `+make sub` extracts (with or without `+`)

### Edge Cases
- [ ] Empty Makefile returns no commands
- [ ] File with only variables returns no commands
- [ ] File with only comments returns no commands
- [ ] Keyword filter limits extraction

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-16 | Initial specification |

---

## Related Tasks

- **Blocks:** `git_safety_guard-dclh` (Implement Makefile recipe extractor)
- **Blocks:** `git_safety_guard-5rbb.7` (Unit tests for Makefile extractor)
- **Parent:** `git_safety_guard-5rbb` (Scan Mode Extractors for CI/DevOps Files)


